{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Choose a plugin type on the left to see its documentation.","title":"Home"},{"location":"AbstractTask/","text":"Cost-adapted task # A cost-adapting transformation of the root task. adapt_costs(cost_type=NORMAL) cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. no_transform # no_transform()","title":"AbstractTask"},{"location":"AbstractTask/#cost-adapted_task","text":"A cost-adapting transformation of the root task. adapt_costs(cost_type=NORMAL) cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both.","title":"Cost-adapted task"},{"location":"AbstractTask/#no_transform","text":"no_transform()","title":"no_transform"},{"location":"AbstractionGenerator/","text":"Cartesian abstraction generator # cartesian(subtasks=[landmarks(order=random), goals(order=random)], max_states=infinity, max_transitions=1M, max_time=infinity, pick_flawed_abstract_state=BATCH_MIN_H, pick_split=MAX_COVER, tiebreak_split=MAX_REFINED, search_strategy=INCREMENTAL, memory_padding=500, dot_graph_verbosity=SILENT, random_seed=-1, max_concrete_states_per_abstract_state=infinity, max_state_expansions=1M, verbosity=normal) subtasks (list of SubtaskGenerator ): subtask generators max_states (int [1, infinity]): maximum sum of abstract states over all abstractions max_transitions (int [0, infinity]): maximum sum of state-changing transitions (excluding self-loops) over all abstractions max_time (double [0.0, infinity]): maximum time in seconds for building abstractions pick_flawed_abstract_state ({FIRST, FIRST_ON_SHORTEST_PATH, RANDOM, MIN_H, MAX_H, BATCH_MIN_H}): flaw-selection strategy pick_split ({RANDOM, MIN_UNWANTED, MAX_UNWANTED, MIN_REFINED, MAX_REFINED, MIN_HADD, MAX_HADD, MIN_CG, MAX_CG, MAX_COVER}): split-selection strategy tiebreak_split ({RANDOM, MIN_UNWANTED, MAX_UNWANTED, MIN_REFINED, MAX_REFINED, MIN_HADD, MAX_HADD, MIN_CG, MAX_CG, MAX_COVER}): split-selection strategy for breaking ties search_strategy ({ASTAR, INCREMENTAL}): strategy for computing abstract plans memory_padding (int [0, infinity]): amount of extra memory in MB to reserve for recovering from out-of-memory situations gracefully. When the memory runs out, we stop refining and start the search. Due to memory fragmentation, the memory used for building the abstraction (states, transitions, etc.) often can't be reused for things that require big continuous blocks of memory. It is for this reason that we require a rather large amount of memory padding by default. dot_graph_verbosity ({SILENT, WRITE_TO_CONSOLE, WRITE_TO_FILE}): verbosity of printing/writing dot graphs random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. max_concrete_states_per_abstract_state (int [1, infinity]): maximum number of flawed concrete states stored per abstract state max_state_expansions (int [1, infinity]): maximum number of state expansions per flaw search verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Projection generator # projections(patterns=<none>, dominance_pruning=false, combine_labels=true, create_complete_transition_system=false, use_add_after_delete_semantics=false, verbosity=normal) patterns ( PatternCollectionGenerator ): pattern generation method dominance_pruning (bool): prune dominated patterns combine_labels (bool): group labels that only induce parallel transitions create_complete_transition_system (bool): create complete transition system use_add_after_delete_semantics (bool): skip transitions that are invalid according to add-after-delete semantics verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"AbstractionGenerator"},{"location":"AbstractionGenerator/#cartesian_abstraction_generator","text":"cartesian(subtasks=[landmarks(order=random), goals(order=random)], max_states=infinity, max_transitions=1M, max_time=infinity, pick_flawed_abstract_state=BATCH_MIN_H, pick_split=MAX_COVER, tiebreak_split=MAX_REFINED, search_strategy=INCREMENTAL, memory_padding=500, dot_graph_verbosity=SILENT, random_seed=-1, max_concrete_states_per_abstract_state=infinity, max_state_expansions=1M, verbosity=normal) subtasks (list of SubtaskGenerator ): subtask generators max_states (int [1, infinity]): maximum sum of abstract states over all abstractions max_transitions (int [0, infinity]): maximum sum of state-changing transitions (excluding self-loops) over all abstractions max_time (double [0.0, infinity]): maximum time in seconds for building abstractions pick_flawed_abstract_state ({FIRST, FIRST_ON_SHORTEST_PATH, RANDOM, MIN_H, MAX_H, BATCH_MIN_H}): flaw-selection strategy pick_split ({RANDOM, MIN_UNWANTED, MAX_UNWANTED, MIN_REFINED, MAX_REFINED, MIN_HADD, MAX_HADD, MIN_CG, MAX_CG, MAX_COVER}): split-selection strategy tiebreak_split ({RANDOM, MIN_UNWANTED, MAX_UNWANTED, MIN_REFINED, MAX_REFINED, MIN_HADD, MAX_HADD, MIN_CG, MAX_CG, MAX_COVER}): split-selection strategy for breaking ties search_strategy ({ASTAR, INCREMENTAL}): strategy for computing abstract plans memory_padding (int [0, infinity]): amount of extra memory in MB to reserve for recovering from out-of-memory situations gracefully. When the memory runs out, we stop refining and start the search. Due to memory fragmentation, the memory used for building the abstraction (states, transitions, etc.) often can't be reused for things that require big continuous blocks of memory. It is for this reason that we require a rather large amount of memory padding by default. dot_graph_verbosity ({SILENT, WRITE_TO_CONSOLE, WRITE_TO_FILE}): verbosity of printing/writing dot graphs random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. max_concrete_states_per_abstract_state (int [1, infinity]): maximum number of flawed concrete states stored per abstract state max_state_expansions (int [1, infinity]): maximum number of state expansions per flaw search verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Cartesian abstraction generator"},{"location":"AbstractionGenerator/#projection_generator","text":"projections(patterns=<none>, dominance_pruning=false, combine_labels=true, create_complete_transition_system=false, use_add_after_delete_semantics=false, verbosity=normal) patterns ( PatternCollectionGenerator ): pattern generation method dominance_pruning (bool): prune dominated patterns combine_labels (bool): group labels that only induce parallel transitions create_complete_transition_system (bool): create complete transition system use_add_after_delete_semantics (bool): skip transitions that are invalid according to add-after-delete semantics verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Projection generator"},{"location":"ConstraintGenerator/","text":"Delete relaxation constraints # Operator-counting constraints based on the delete relaxation. By default the constraints encode an easy-to-compute relaxation of h^+^. With the right settings, these constraints can be used to compute the optimal delete-relaxation heuristic h^+^ (see example below). For details, see Tatsuya Imai and Alex Fukunaga. On a practical, integer-linear programming model for delete-freetasks and its use as a heuristic for cost-optimal planning . Journal of Artificial Intelligence Research 54:631-677. 2015. delete_relaxation_constraints(use_time_vars=false, use_integer_vars=false) use_time_vars (bool): use variables for time steps. With these additional variables the constraints enforce an order between the selected operators. Leaving this off (default) corresponds to the time relaxation by Imai and Fukunaga. Switching it on, can increase the heuristic value but will increase the size of the constraints which has a strong impact on runtime. Constraints involving time variables use a big-M encoding, so they are more useful if used with integer variables. use_integer_vars (bool): restrict auxiliary variables to integer values. These variables encode whether operators are used, facts are reached, which operator first achieves which fact, and in which order the operators are used. Restricting them to integers generally improves the heuristic value at the cost of increased runtime. Example: To compute the optimal delete-relaxation heuristic h^+^, use operatorcounting([delete_relaxation_constraints(use_time_vars=true, use_integer_vars=true)], use_integer_operator_counts=true)) LM-cut landmark constraints # Computes a set of landmarks in each state using the LM-cut method. For each landmark L the constraint sum_{o in L} Count_o >= 1 is added to the operator-counting LP temporarily. After the heuristic value for the state is computed, all temporary constraints are removed again. For details, see Florian Pommerening, Gabriele Roeger, Malte Helmert and Blai Bonet. LP-based Heuristics for Cost-optimal Planning . In Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS 2014) , pp. 226-234. AAAI Press, 2014. Blai Bonet. An admissible heuristic for SAS+ planning obtained from the state equation . In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI 2013) , pp. 2268-2274. AAAI Press, 2013. lmcut_constraints() (Saturated) posthoc optimization constraints for abstractions # pho_abstraction_constraints(abstractions=<none>, saturated=true) abstractions (list of AbstractionGenerator ): abstraction generation methods saturated (bool): use saturated instead of full operator costs in constraints Posthoc optimization constraints # The generator will compute a PDB for each pattern and add the constraint h(s) <= sum_{o in relevant(h)} Count_o. For details, see Florian Pommerening, Gabriele Roeger and Malte Helmert. Getting the Most Out of Pattern Databases for Classical Planning . In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI 2013) , pp. 2357-2364. AAAI Press, 2013. pho_constraints(patterns=systematic(2)) patterns ( PatternCollectionGenerator ): pattern generation method State equation constraints # For each fact, a permanent constraint is added that considers the net change of the fact, i.e., the total number of times the fact is added minus the total number of times is removed. The bounds of each constraint depend on the current state and the goal state and are updated in each state. For details, see Menkes van den Briel, J. Benton, Subbarao Kambhampati and Thomas Vossen. An LP-based heuristic for optimal planning . In Proceedings of the Thirteenth International Conference on Principles and Practice of Constraint Programming (CP 2007) , pp. 651-665. Springer-Verlag, 2007. Blai Bonet. An admissible heuristic for SAS+ planning obtained from the state equation . In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI 2013) , pp. 2268-2274. AAAI Press, 2013. Florian Pommerening, Gabriele Roeger, Malte Helmert and Blai Bonet. LP-based Heuristics for Cost-optimal Planning . In Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS 2014) , pp. 226-234. AAAI Press, 2014. state_equation_constraints(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"ConstraintGenerator"},{"location":"ConstraintGenerator/#delete_relaxation_constraints","text":"Operator-counting constraints based on the delete relaxation. By default the constraints encode an easy-to-compute relaxation of h^+^. With the right settings, these constraints can be used to compute the optimal delete-relaxation heuristic h^+^ (see example below). For details, see Tatsuya Imai and Alex Fukunaga. On a practical, integer-linear programming model for delete-freetasks and its use as a heuristic for cost-optimal planning . Journal of Artificial Intelligence Research 54:631-677. 2015. delete_relaxation_constraints(use_time_vars=false, use_integer_vars=false) use_time_vars (bool): use variables for time steps. With these additional variables the constraints enforce an order between the selected operators. Leaving this off (default) corresponds to the time relaxation by Imai and Fukunaga. Switching it on, can increase the heuristic value but will increase the size of the constraints which has a strong impact on runtime. Constraints involving time variables use a big-M encoding, so they are more useful if used with integer variables. use_integer_vars (bool): restrict auxiliary variables to integer values. These variables encode whether operators are used, facts are reached, which operator first achieves which fact, and in which order the operators are used. Restricting them to integers generally improves the heuristic value at the cost of increased runtime. Example: To compute the optimal delete-relaxation heuristic h^+^, use operatorcounting([delete_relaxation_constraints(use_time_vars=true, use_integer_vars=true)], use_integer_operator_counts=true))","title":"Delete relaxation constraints"},{"location":"ConstraintGenerator/#lm-cut_landmark_constraints","text":"Computes a set of landmarks in each state using the LM-cut method. For each landmark L the constraint sum_{o in L} Count_o >= 1 is added to the operator-counting LP temporarily. After the heuristic value for the state is computed, all temporary constraints are removed again. For details, see Florian Pommerening, Gabriele Roeger, Malte Helmert and Blai Bonet. LP-based Heuristics for Cost-optimal Planning . In Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS 2014) , pp. 226-234. AAAI Press, 2014. Blai Bonet. An admissible heuristic for SAS+ planning obtained from the state equation . In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI 2013) , pp. 2268-2274. AAAI Press, 2013. lmcut_constraints()","title":"LM-cut landmark constraints"},{"location":"ConstraintGenerator/#saturated_posthoc_optimization_constraints_for_abstractions","text":"pho_abstraction_constraints(abstractions=<none>, saturated=true) abstractions (list of AbstractionGenerator ): abstraction generation methods saturated (bool): use saturated instead of full operator costs in constraints","title":"(Saturated) posthoc optimization constraints for abstractions"},{"location":"ConstraintGenerator/#posthoc_optimization_constraints","text":"The generator will compute a PDB for each pattern and add the constraint h(s) <= sum_{o in relevant(h)} Count_o. For details, see Florian Pommerening, Gabriele Roeger and Malte Helmert. Getting the Most Out of Pattern Databases for Classical Planning . In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI 2013) , pp. 2357-2364. AAAI Press, 2013. pho_constraints(patterns=systematic(2)) patterns ( PatternCollectionGenerator ): pattern generation method","title":"Posthoc optimization constraints"},{"location":"ConstraintGenerator/#state_equation_constraints","text":"For each fact, a permanent constraint is added that considers the net change of the fact, i.e., the total number of times the fact is added minus the total number of times is removed. The bounds of each constraint depend on the current state and the goal state and are updated in each state. For details, see Menkes van den Briel, J. Benton, Subbarao Kambhampati and Thomas Vossen. An LP-based heuristic for optimal planning . In Proceedings of the Thirteenth International Conference on Principles and Practice of Constraint Programming (CP 2007) , pp. 651-665. Springer-Verlag, 2007. Blai Bonet. An admissible heuristic for SAS+ planning obtained from the state equation . In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI 2013) , pp. 2268-2274. AAAI Press, 2013. Florian Pommerening, Gabriele Roeger, Malte Helmert and Blai Bonet. LP-based Heuristics for Cost-optimal Planning . In Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS 2014) , pp. 226-234. AAAI Press, 2014. state_equation_constraints(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"State equation constraints"},{"location":"Evaluator/","text":"An evaluator specification is either a newly created evaluator instance or an evaluator that has been defined previously. This page describes how one can specify a new evaluator instance. For re-using evaluators, see OptionSyntax#Evaluator_Predefinitions. If the evaluator is a heuristic, definitions of properties in the descriptions below: admissible: h(s) <= h*(s) for all states s consistent: h(s) <= c(s, s') + h(s') for all states s connected to states s' by an action with cost c(s, s') safe: h(s) = infinity is only true for states with h*(s) = infinity preferred operators: this heuristic identifies preferred operators This plugin type can be predefined using --evaluator . The old predefinition key --heuristic is still supported but deprecated. Additive heuristic # add(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: supported axioms: supported (in the sense that the planner won't complain -- handling of axioms might be very stupid and even render the heuristic unsafe) Properties: admissible: no consistent: no safe: yes for tasks without axioms preferred operators: yes Blind heuristic # Returns cost of cheapest action for non-goal states, 0 for goal states blind(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: supported axioms: supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no Context-enhanced additive heuristic # cea(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: supported axioms: supported (in the sense that the planner won't complain -- handling of axioms might be very stupid and even render the heuristic unsafe) Properties: admissible: no consistent: no safe: no preferred operators: yes Additive CEGAR heuristic # See the paper introducing Counterexample-guided Abstraction Refinement (CEGAR) for classical planning: Jendrik Seipp and Malte Helmert. Counterexample-guided Cartesian Abstraction Refinement . In Proceedings of the 23rd International Conference on Automated Planning and Scheduling (ICAPS 2013) , pp. 347-351. AAAI Press, 2013. and the paper showing how to make the abstractions additive: Jendrik Seipp and Malte Helmert. Diverse and Additive Cartesian Abstraction Heuristics . In Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS 2014) , pp. 289-297. AAAI Press, 2014. For more details on Cartesian CEGAR and saturated cost partitioning, see the journal paper Jendrik Seipp and Malte Helmert. Counterexample-Guided Cartesian Abstraction Refinement for Classical Planning . Journal of Artificial Intelligence Research 62:535-577. 2018. For a description of the incremental search, see the paper Jendrik Seipp, Samuel von Allmen and Malte Helmert. Incremental Search for Counterexample-Guided Cartesian Abstraction Refinement . In Proceedings of the 30th International Conference on Automated Planning and Scheduling (ICAPS 2020) , pp. 244-248. AAAI Press, 2020. Finally, we describe advanced flaw selection strategies here: David Speck and Jendrik Seipp. New Refinement Strategies for Cartesian Abstractions . In Proceedings of the 32nd International Conference on Automated Planning and Scheduling (ICAPS 2022) , pp. to appear. AAAI Press, 2022. cegar(subtasks=[landmarks(order=random), goals(order=random)], max_states=infinity, max_transitions=1M, max_time=infinity, pick_flawed_abstract_state=BATCH_MIN_H, pick_split=MAX_COVER, tiebreak_split=MAX_REFINED, search_strategy=INCREMENTAL, memory_padding=500, dot_graph_verbosity=SILENT, random_seed=-1, max_concrete_states_per_abstract_state=infinity, max_state_expansions=1M, use_general_costs=true, verbosity=normal, transform=no_transform(), cache_estimates=true) subtasks (list of SubtaskGenerator ): subtask generators max_states (int [1, infinity]): maximum sum of abstract states over all abstractions max_transitions (int [0, infinity]): maximum sum of state-changing transitions (excluding self-loops) over all abstractions max_time (double [0.0, infinity]): maximum time in seconds for building abstractions pick_flawed_abstract_state ({FIRST, FIRST_ON_SHORTEST_PATH, RANDOM, MIN_H, MAX_H, BATCH_MIN_H}): flaw-selection strategy pick_split ({RANDOM, MIN_UNWANTED, MAX_UNWANTED, MIN_REFINED, MAX_REFINED, MIN_HADD, MAX_HADD, MIN_CG, MAX_CG, MAX_COVER}): split-selection strategy tiebreak_split ({RANDOM, MIN_UNWANTED, MAX_UNWANTED, MIN_REFINED, MAX_REFINED, MIN_HADD, MAX_HADD, MIN_CG, MAX_CG, MAX_COVER}): split-selection strategy for breaking ties search_strategy ({ASTAR, INCREMENTAL}): strategy for computing abstract plans memory_padding (int [0, infinity]): amount of extra memory in MB to reserve for recovering from out-of-memory situations gracefully. When the memory runs out, we stop refining and start the search. Due to memory fragmentation, the memory used for building the abstraction (states, transitions, etc.) often can't be reused for things that require big continuous blocks of memory. It is for this reason that we require a rather large amount of memory padding by default. dot_graph_verbosity ({SILENT, WRITE_TO_CONSOLE, WRITE_TO_FILE}): verbosity of printing/writing dot graphs random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. max_concrete_states_per_abstract_state (int [1, infinity]): maximum number of flawed concrete states stored per abstract state max_state_expansions (int [1, infinity]): maximum number of state expansions per flaw search use_general_costs (bool): allow negative costs in cost partitioning verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no Causal graph heuristic # cg(max_cache_size=1000000, verbosity=normal, transform=no_transform(), cache_estimates=true) max_cache_size (int [0, infinity]): maximum number of cached entries per variable (set to 0 to disable cache) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: supported axioms: supported (in the sense that the planner won't complain -- handling of axioms might be very stupid and even render the heuristic unsafe) Properties: admissible: no consistent: no safe: no preferred operators: yes FF heuristic # ff(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: supported axioms: supported (in the sense that the planner won't complain -- handling of axioms might be very stupid and even render the heuristic unsafe) Properties: admissible: no consistent: no safe: yes for tasks without axioms preferred operators: yes Goal count heuristic # goalcount(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: ignored by design conditional effects: supported axioms: supported Properties: admissible: no consistent: no safe: yes preferred operators: no h^m heuristic # hm(m=2, verbosity=normal, transform=no_transform(), cache_estimates=true) m (int [1, infinity]): subset size verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: ignored axioms: ignored Properties: admissible: yes for tasks without conditional effects or axioms consistent: yes for tasks without conditional effects or axioms safe: yes for tasks without conditional effects or axioms preferred operators: no Max heuristic # hmax(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: supported axioms: supported (in the sense that the planner won't complain -- handling of axioms might be very stupid and even render the heuristic unsafe) Properties: admissible: yes for tasks without axioms consistent: yes for tasks without axioms safe: yes for tasks without axioms preferred operators: no Landmark-count heuristic # For the inadmissible variant see the papers Silvia Richter, Malte Helmert and Matthias Westphal. Landmarks Revisited . In Proceedings of the 23rd AAAI Conference on Artificial Intelligence (AAAI 2008) , pp. 975-982. AAAI Press, 2008. and Silvia Richter and Matthias Westphal. The LAMA Planner: Guiding Cost-Based Anytime Planning with Landmarks . Journal of Artificial Intelligence Research 39:127-177. 2010. For the admissible variant see the papers Erez Karpas and Carmel Domshlak. Cost-Optimal Planning with Landmarks . In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI 2009) , pp. 1728-1733. AAAI Press, 2009. and Emil Keyder and Silvia Richter and Malte Helmert. Sound and Complete Landmarks for And/Or Graphs . In Proceedings of the 19th European Conference on Artificial Intelligence (ECAI 2010) , pp. 335-340. IOS Press, 2010. lmcount(lm_factory, admissible=false, cost_partitioning=SUBOPTIMAL, pref=false, alm=true, reuse_costs=false, greedy=false, scoring_function=MAX_HEURISTIC_PER_STOLEN_COSTS, random_seed=-1, lpsolver=CPLEX, verbosity=normal, transform=no_transform(), cache_estimates=true) lm_factory ( LandmarkFactory ): the set of landmarks to use for this heuristic. The set of landmarks can be specified here, or predefined (see LandmarkFactory ). admissible (bool): get admissible estimate cost_partitioning ({OPTIMAL, SUBOPTIMAL, CANONICAL, PHO}): cost partitioning method pref (bool): identify preferred operators (see OptionCaveats#Using_preferred_operators_with_the_lmcount_heuristic) alm (bool): use action landmarks reuse_costs (bool): reuse unused costs greedy (bool): assign costs greedily scoring_function ({MAX_HEURISTIC, MIN_STOLEN_COSTS, MAX_HEURISTIC_PER_STOLEN_COSTS}): scoring function random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Optimal search: When using landmarks for optimal search ( admissible=true ), you probably also want to add this heuristic as a lazy_evaluator in the A* algorithm to improve heuristic estimates. Note: To use optimal=true , you must build the planner with LP support. See LPBuildInstructions. Differences to the literature: This heuristic differs from the description in the literature (see references above) in the set of preferred operators computed. The original implementation described in the literature computes two kinds of preferred operators: If there is an applicable operator that reaches a landmark, all such operators are preferred. If no such operators exist, perform an FF-style relaxed exploration towards the nearest landmarks (according to the landmark orderings) and use the preferred operators of this exploration. Our implementation of the heuristic only considers preferred operators of the first type and does not include the second type. The rationale for this change is that it reduces code complexity and helps more cleanly separate landmark-based and FF-based computations in LAMA-like planner configurations. In our experiments, only considering preferred operators of the first type reduces performance when using the heuristic and its preferred operators in isolation but improves performance when using this heuristic in conjunction with the FF heuristic, as in LAMA-like planner configurations. Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Note on performance for satisficing planning: The cost of a landmark is based on the cost of the operators that achieve it. For satisficing search this can be counterproductive since it is often better to focus on distance from goal (i.e. length of the plan) rather than cost.In experiments we achieved the best performance usingthe option 'transform=adapt_costs(one)' to enforce unit costs. Language features supported: action costs: supported conditional_effects: supported if the LandmarkFactory supports them; otherwise ignored with admissible=false and not allowed with admissible=true axioms: ignored with admissible=false ; not allowed with admissible=true Properties: admissible: yes if admissible=true consistent: complicated; needs further thought safe: yes except on tasks with axioms or on tasks with conditional effects when using a LandmarkFactory not supporting them preferred operators: yes (if enabled; see pref option) Landmark-cut heuristic # lmcut(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: no safe: yes preferred operators: no Merge-and-shrink heuristic # This heuristic implements the algorithm described in the following paper: Silvan Sievers, Martin Wehrle and Malte Helmert. Generalized Label Reduction for Merge-and-Shrink Heuristics . In Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI 2014) , pp. 2358-2366. AAAI Press, 2014. For a more exhaustive description of merge-and-shrink, see the journal paper Silvan Sievers and Malte Helmert. Merge-and-Shrink: A Compositional Theory of Transformations of Factored Transition Systems . Journal of Artificial Intelligence Research 71:781-883. 2021. The following paper describes how to improve the DFP merge strategy with tie-breaking, and presents two new merge strategies (dyn-MIASM and SCC-DFP): Silvan Sievers, Martin Wehrle and Malte Helmert. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics . In Proceedings of the 26th International Conference on Automated Planning and Scheduling (ICAPS 2016) , pp. 294-298. AAAI Press, 2016. Details of the algorithms and the implementation are described in the paper Silvan Sievers. Merge-and-Shrink Heuristics for Classical Planning: Efficient Implementation and Partial Abstractions . In Proceedings of the 11th Annual Symposium on Combinatorial Search (SoCS 2018) , pp. 90-98. AAAI Press, 2018. merge_and_shrink(verbosity=normal, transform=no_transform(), cache_estimates=true, merge_strategy, shrink_strategy, label_reduction=<none>, prune_unreachable_states=true, prune_irrelevant_states=true, max_states=-1, max_states_before_merge=-1, threshold_before_merge=-1, main_loop_max_time=infinity) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates merge_strategy ( MergeStrategy ): See detailed documentation for merge strategies. We currently recommend SCC-DFP, which can be achieved using merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])) shrink_strategy ( ShrinkStrategy ): See detailed documentation for shrink strategies. We currently recommend non-greedy shrink_bisimulation, which can be achieved using shrink_strategy=shrink_bisimulation(greedy=false) label_reduction ( LabelReduction ): See detailed documentation for labels. There is currently only one 'option' to use label_reduction, which is label_reduction=exact Also note the interaction with shrink strategies. prune_unreachable_states (bool): If true, prune abstract states unreachable from the initial state. prune_irrelevant_states (bool): If true, prune abstract states from which no goal state can be reached. max_states (int [-1, infinity]): maximum transition system size allowed at any time point. max_states_before_merge (int [-1, infinity]): maximum transition system size allowed for two transition systems before being merged to form the synchronized product. threshold_before_merge (int [-1, infinity]): If a transition system, before being merged, surpasses this soft transition system size limit, the shrink strategy is called to possibly shrink the transition system. main_loop_max_time (double [0.0, infinity]): A limit in seconds on the runtime of the main loop of the algorithm. If the limit is exceeded, the algorithm terminates, potentially returning a factored transition system with several factors. Also note that the time limit is only checked between transformations of the main loop, but not during, so it can be exceeded if a transformation is runtime-intense. Note: Conditional effects are supported directly. Note, however, that for tasks that are not factored (in the sense of the JACM 2014 merge-and-shrink paper), the atomic transition systems on which merge-and-shrink heuristics are based are nondeterministic, which can lead to poor heuristics even when only perfect shrinking is performed. Note: When pruning unreachable states, admissibility and consistency is only guaranteed for reachable states and transitions between reachable states. While this does not impact regular A* search which will never encounter any unreachable state, it impacts techniques like symmetry-based pruning: a reachable state which is mapped to an unreachable symmetric state (which hence is pruned) would falsely be considered a dead-end and also be pruned, thus violating optimality of the search. Note: When using a time limit on the main loop of the merge-and-shrink algorithm, the heuristic will compute the maximum over all heuristics induced by the remaining factors if terminating the merge-and-shrink algorithm early. Exception: if there is an unsolvable factor, it will be used as the exclusive heuristic since the problem is unsolvable. Note: A currently recommended good configuration uses bisimulation based shrinking, the merge strategy SCC-DFP, and the appropriate label reduction setting (max_states has been altered to be between 10k and 200k in the literature): merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1) Language features supported: action costs: supported conditional effects: supported (but see note) axioms: not supported Properties: admissible: yes (but see note) consistent: yes (but see note) safe: yes preferred operators: no Operator-counting heuristic # An operator-counting heuristic computes a linear program (LP) in each state. The LP has one variable Count_o for each operator o that represents how often the operator is used in a plan. Operator-counting constraints are linear constraints over these varaibles that are guaranteed to have a solution with Count_o = occurrences(o, pi) for every plan pi. Minimizing the total cost of operators subject to some operator-counting constraints is an admissible heuristic. For details, see Florian Pommerening, Gabriele Roeger, Malte Helmert and Blai Bonet. LP-based Heuristics for Cost-optimal Planning . In Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS 2014) , pp. 226-234. AAAI Press, 2014. operatorcounting(constraint_generators, use_integer_operator_counts=false, lpsolver=CPLEX, verbosity=normal, transform=no_transform(), cache_estimates=true) constraint_generators (list of ConstraintGenerator ): methods that generate constraints over operator-counting variables use_integer_operator_counts (bool): restrict operator-counting variables to integer values. Computing the heuristic with integer variables can produce higher values but requires solving a MIP instead of an LP which is generally more computationally expensive. Turning this option on can thus drastically increase the runtime. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented constraint generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented constraint generators do) Properties: admissible: yes consistent: yes, if all constraint generators represent consistent heuristics safe: yes preferred operators: no Basic Evaluators # Constant evaluator # Returns a constant value. const(value=1, verbosity=normal) value (int [0, infinity]): the constant value verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output g-value evaluator # Returns the g-value (path cost) of the search node. g(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Max evaluator # Calculates the maximum of the sub-evaluators. max(evals, verbosity=normal) evals (list of Evaluator ): at least one evaluator verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Preference evaluator # Returns 0 if preferred is true and 1 otherwise. pref(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Sum evaluator # Calculates the sum of the sub-evaluators. sum(evals, verbosity=normal) evals (list of Evaluator ): at least one evaluator verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Weighted evaluator # Multiplies the value of the evaluator with the given weight. weight(eval, weight, verbosity=normal) eval ( Evaluator ): evaluator weight (int): weight verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Cost Partitioning Heuristics # Canonical heuristic over abstractions # canonical_heuristic(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no Greedy zero-one cost partitioning # gzocp(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true, orders=greedy_orders(), max_orders=infinity, max_size=infinity, max_time=200, diversify=true, samples=1000, max_optimization_time=2, random_seed=-1, verbosity=normal, transform=no_transform(), cache_estimates=true) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates orders ( OrderGenerator ): order generator max_orders (int [0, infinity]): maximum number of orders max_size (int [0, infinity]): maximum heuristic size in KiB max_time (double [0, infinity]): maximum time in seconds for finding orders diversify (bool): only keep orders that have a higher heuristic value than all previous orders for any of the samples samples (int [1, infinity]): number of samples for diversification max_optimization_time (double [0, infinity]): maximum time in seconds for optimizing each order with hill climbing random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no Maximum over abstractions # Maximize over a set of abstraction heuristics. maximize(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no Optimal cost partitioning heuristic # ocp(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true, lpsolver=CPLEX, allow_negative_costs=true) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB allow_negative_costs (bool): use general instead of non-negative cost partitioning Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no Post-hoc optimization heuristic # Compute the maximum over multiple PhO heuristics precomputed offline. pho(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true, saturated=true, orders=greedy_orders(), max_orders=infinity, max_size=infinity, max_time=200, diversify=true, samples=1000, max_optimization_time=2, random_seed=-1, lpsolver=CPLEX, verbosity=normal) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates saturated (bool): saturate costs orders ( OrderGenerator ): order generator max_orders (int [0, infinity]): maximum number of orders max_size (int [0, infinity]): maximum heuristic size in KiB max_time (double [0, infinity]): maximum time in seconds for finding orders diversify (bool): only keep orders that have a higher heuristic value than all previous orders for any of the samples samples (int [1, infinity]): number of samples for diversification max_optimization_time (double [0, infinity]): maximum time in seconds for optimizing each order with hill climbing random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no Saturated cost partitioning # Compute the maximum over multiple saturated cost partitioning heuristics using different orders. For details, see Jendrik Seipp, Thomas Keller and Malte Helmert. Saturated Cost Partitioning for Optimal Classical Planning . Journal of Artificial Intelligence Research 67:129-167. 2020. scp(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true, saturator=all, orders=greedy_orders(), max_orders=infinity, max_size=infinity, max_time=200, diversify=true, samples=1000, max_optimization_time=2, random_seed=-1, verbosity=normal, transform=no_transform(), cache_estimates=true) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates saturator ({all, perim, perimstar}): function that computes saturated cost functions all : preserve estimates of all states perim : preserve estimates of states in perimeter around goal perimstar : compute 'perim' first and then 'all' with remaining costs orders ( OrderGenerator ): order generator max_orders (int [0, infinity]): maximum number of orders max_size (int [0, infinity]): maximum heuristic size in KiB max_time (double [0, infinity]): maximum time in seconds for finding orders diversify (bool): only keep orders that have a higher heuristic value than all previous orders for any of the samples samples (int [1, infinity]): number of samples for diversification max_optimization_time (double [0, infinity]): maximum time in seconds for optimizing each order with hill climbing random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Difference to cegar(): The cegar() plugin computes a single saturated cost partitioning over Cartesian abstraction heuristics. In contrast, saturated_cost_partitioning() supports computing the maximum over multiple saturated cost partitionings using different heuristic orders, and it supports both Cartesian abstraction heuristics and pattern database heuristics. While cegar() interleaves abstraction computation with cost partitioning, saturated_cost_partitioning() computes all abstractions using the original costs. Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no Online saturated cost partitioning # Compute the maximum over multiple saturated cost partitioning heuristics diversified during the search. For details, see Jendrik Seipp. Online Saturated Cost Partitioning for Classical Planning . In Proceedings of the 31st International Conference on Automated Planning and Scheduling (ICAPS 2021) , pp. 317-321. AAAI Press, 2021. scp_online(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true, saturator=all, orders=greedy_orders(), max_size=infinity, max_time=200, interval=10K, debug=false, random_seed=-1) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates saturator ({all, perim, perimstar}): function that computes saturated cost functions all : preserve estimates of all states perim : preserve estimates of states in perimeter around goal perimstar : compute 'perim' first and then 'all' with remaining costs orders ( OrderGenerator ): order generator max_size (int [0, infinity]): maximum (estimated) heuristic size in KiB max_time (double [0, infinity]): maximum time in seconds for finding orders interval (int [1, infinity]): select every i-th evaluated state for online diversification debug (bool): print debug output random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: no safe: yes preferred operators: no (Opportunistic) uniform cost partitioning # Jendrik Seipp, Thomas Keller and Malte Helmert. A Comparison of Cost Partitioning Algorithms for Optimal Classical Planning . In Proceedings of the Twenty-Seventh International Conference on Automated Planning and Scheduling (ICAPS 2017) , pp. 259-268. AAAI Press, 2017. ucp(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true, orders=greedy_orders(), max_orders=infinity, max_size=infinity, max_time=200, diversify=true, samples=1000, max_optimization_time=2, random_seed=-1, opportunistic=false, debug=false) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates orders ( OrderGenerator ): order generator max_orders (int [0, infinity]): maximum number of orders max_size (int [0, infinity]): maximum heuristic size in KiB max_time (double [0, infinity]): maximum time in seconds for finding orders diversify (bool): only keep orders that have a higher heuristic value than all previous orders for any of the samples samples (int [1, infinity]): number of samples for diversification max_optimization_time (double [0, infinity]): maximum time in seconds for optimizing each order with hill climbing random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. opportunistic (bool): recalculate uniform cost partitioning after each considered abstraction debug (bool): print debugging messages Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no Pattern Database Heuristics # Canonical PDB # The canonical pattern database heuristic is calculated as follows. For a given pattern collection C, the value of the canonical heuristic function is the maximum over all maximal additive subsets A in C, where the value for one subset S in A is the sum of the heuristic values for all patterns in S for a given state. cpdbs(patterns=systematic(1), max_time_dominance_pruning=infinity, verbosity=normal, transform=no_transform(), cache_estimates=true) patterns ( PatternCollectionGenerator ): pattern generation method max_time_dominance_pruning (double [0.0, infinity]): The maximum time in seconds spent on dominance pruning. Using 0.0 turns off dominance pruning. Dominance pruning excludes patterns and additive subsets that will never contribute to the heuristic value because there are dominating subsets in the collection. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no iPDB # This approach is a combination of using the Canonical PDB heuristic over patterns computed with the Hill climbing algorithm for pattern generation. It is a short-hand for the command-line option cpdbs(hillclimbing()) . Both the heuristic and the pattern generation algorithm are described in the following paper: Patrik Haslum, Adi Botea, Malte Helmert, Blai Bonet and Sven Koenig. Domain-Independent Construction of Pattern Database Heuristics for Cost-Optimal Planning . In Proceedings of the 22nd AAAI Conference on Artificial Intelligence (AAAI 2007) , pp. 1007-1012. AAAI Press, 2007. For implementation notes, see: Silvan Sievers, Manuela Ortlieb and Malte Helmert. Efficient Implementation of Pattern Database Heuristics for Classical Planning . In Proceedings of the Fifth Annual Symposium on Combinatorial Search (SoCS 2012) , pp. 105-111. AAAI Press, 2012. See also Canonical PDB and Hill climbing for more details. ipdb(pdb_max_size=2000000, collection_max_size=20000000, num_samples=1000, min_improvement=10, max_time=infinity, max_generated_patterns=infinity, random_seed=-1, verbosity=normal, max_time_dominance_pruning=infinity, verbosity=normal, transform=no_transform(), cache_estimates=true) pdb_max_size (int [1, infinity]): maximal number of states per pattern database collection_max_size (int [1, infinity]): maximal number of states in the pattern collection num_samples (int [1, infinity]): number of samples (random states) on which to evaluate each candidate pattern collection min_improvement (int [1, infinity]): minimum number of samples on which a candidate pattern collection must improve on the current one to be considered as the next pattern collection max_time (double [0.0, infinity]): maximum time in seconds for improving the initial pattern collection via hill climbing. If set to 0, no hill climbing is performed at all. Note that this limit only affects hill climbing. Use max_time_dominance_pruning to limit the time spent for pruning dominated patterns. max_generated_patterns (int [0, infinity]): maximum number of generated patterns random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output max_time_dominance_pruning (double [0.0, infinity]): The maximum time in seconds spent on dominance pruning. Using 0.0 turns off dominance pruning. Dominance pruning excludes patterns and additive subsets that will never contribute to the heuristic value because there are dominating subsets in the collection. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Note: The pattern collection created by the algorithm will always contain all patterns consisting of a single goal variable, even if this violates the pdb_max_size or collection_max_size limits. Note: This pattern generation method generates patterns optimized for use with the canonical pattern database heuristic. Implementation Notes # The following will very briefly describe the algorithm and explain the differences between the original implementation from 2007 and the new one in Fast Downward. The aim of the algorithm is to output a pattern collection for which the Canonical PDB yields the best heuristic estimates. The algorithm is basically a local search (hill climbing) which searches the \"pattern neighbourhood\" (starting initially with a pattern for each goal variable) for improving the pattern collection. This is done as described in the section \"pattern construction as search\" in the paper, except for the corrected search neighbourhood discussed below. For evaluating the neighbourhood, the \"counting approximation\" as introduced in the paper was implemented. An important difference however consists in the fact that this implementation computes all pattern databases for each candidate pattern rather than using A* search to compute the heuristic values only for the sample states for each pattern. Also the logic for sampling the search space differs a bit from the original implementation. The original implementation uses a random walk of a length which is binomially distributed with the mean at the estimated solution depth (estimation is done with the current pattern collection heuristic). In the Fast Downward implementation, also a random walk is used, where the length is the estimation of the number of solution steps, which is calculated by dividing the current heuristic estimate for the initial state by the average operator costs of the planning task (calculated only once and not updated during sampling!) to take non-unit cost problems into account. This yields a random walk of an expected lenght of np = 2 * estimated number of solution steps. If the random walk gets stuck, it is being restarted from the initial state, exactly as described in the original paper. The section \"avoiding redundant evaluations\" describes how the search neighbourhood of patterns can be restricted to variables that are relevant to the variables already included in the pattern by analyzing causal graphs. There is a mistake in the paper that leads to some relevant neighbouring patterns being ignored. See the errata for details. This mistake has been addressed in this implementation. The second approach described in the paper (statistical confidence interval) is not applicable to this implementation, as it doesn't use A* search but constructs the entire pattern databases for all candidate patterns anyway. The search is ended if there is no more improvement (or the improvement is smaller than the minimal improvement which can be set as an option), however there is no limit of iterations of the local search. This is similar to the techniques used in the original implementation as described in the paper. Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no Pattern database heuristic # TODO pdb(pattern=greedy(), verbosity=normal, transform=no_transform(), cache_estimates=true) pattern ( PatternGenerator ): pattern generation method verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no Zero-One PDB # The zero/one pattern database heuristic is simply the sum of the heuristic values of all patterns in the pattern collection. In contrast to the canonical pattern database heuristic, there is no need to check for additive subsets, because the additivity of the patterns is guaranteed by action cost partitioning. This heuristic uses the most simple form of action cost partitioning, i.e. if an operator affects more than one pattern in the collection, its costs are entirely taken into account for one pattern (the first one which it affects) and set to zero for all other affected patterns. zopdbs(patterns=systematic(1), verbosity=normal, transform=no_transform(), cache_estimates=true) patterns ( PatternCollectionGenerator ): pattern generation method verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no Potential Heuristics # Potential heuristic optimized for all states # The algorithm is based on Jendrik Seipp, Florian Pommerening and Malte Helmert. New Optimization Functions for Potential Heuristics . In Proceedings of the 25th International Conference on Automated Planning and Scheduling (ICAPS 2015) , pp. 193-201. AAAI Press, 2015. all_states_potential(max_potential=1e8, lpsolver=CPLEX, verbosity=normal, transform=no_transform(), cache_estimates=true) max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound infinity disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no Diverse potential heuristics # The algorithm is based on Jendrik Seipp, Florian Pommerening and Malte Helmert. New Optimization Functions for Potential Heuristics . In Proceedings of the 25th International Conference on Automated Planning and Scheduling (ICAPS 2015) , pp. 193-201. AAAI Press, 2015. diverse_potentials(num_samples=1000, max_num_heuristics=infinity, max_potential=1e8, lpsolver=CPLEX, verbosity=normal, transform=no_transform(), cache_estimates=true, random_seed=-1, verbosity=normal) num_samples (int [0, infinity]): Number of states to sample max_num_heuristics (int [0, infinity]): maximum number of potential heuristics max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound infinity disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no Potential heuristic optimized for initial state # The algorithm is based on Jendrik Seipp, Florian Pommerening and Malte Helmert. New Optimization Functions for Potential Heuristics . In Proceedings of the 25th International Conference on Automated Planning and Scheduling (ICAPS 2015) , pp. 193-201. AAAI Press, 2015. initial_state_potential(max_potential=1e8, lpsolver=CPLEX, verbosity=normal, transform=no_transform(), cache_estimates=true) max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound infinity disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no Sample-based potential heuristics # Maximum over multiple potential heuristics optimized for samples. The algorithm is based on Jendrik Seipp, Florian Pommerening and Malte Helmert. New Optimization Functions for Potential Heuristics . In Proceedings of the 25th International Conference on Automated Planning and Scheduling (ICAPS 2015) , pp. 193-201. AAAI Press, 2015. sample_based_potentials(num_heuristics=1, num_samples=1000, max_potential=1e8, lpsolver=CPLEX, verbosity=normal, transform=no_transform(), cache_estimates=true, random_seed=-1) num_heuristics (int [0, infinity]): number of potential heuristics num_samples (int [0, infinity]): Number of states to sample max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound infinity disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Evaluator"},{"location":"Evaluator/#additive_heuristic","text":"add(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: supported axioms: supported (in the sense that the planner won't complain -- handling of axioms might be very stupid and even render the heuristic unsafe) Properties: admissible: no consistent: no safe: yes for tasks without axioms preferred operators: yes","title":"Additive heuristic"},{"location":"Evaluator/#blind_heuristic","text":"Returns cost of cheapest action for non-goal states, 0 for goal states blind(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: supported axioms: supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Blind heuristic"},{"location":"Evaluator/#context-enhanced_additive_heuristic","text":"cea(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: supported axioms: supported (in the sense that the planner won't complain -- handling of axioms might be very stupid and even render the heuristic unsafe) Properties: admissible: no consistent: no safe: no preferred operators: yes","title":"Context-enhanced additive heuristic"},{"location":"Evaluator/#additive_cegar_heuristic","text":"See the paper introducing Counterexample-guided Abstraction Refinement (CEGAR) for classical planning: Jendrik Seipp and Malte Helmert. Counterexample-guided Cartesian Abstraction Refinement . In Proceedings of the 23rd International Conference on Automated Planning and Scheduling (ICAPS 2013) , pp. 347-351. AAAI Press, 2013. and the paper showing how to make the abstractions additive: Jendrik Seipp and Malte Helmert. Diverse and Additive Cartesian Abstraction Heuristics . In Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS 2014) , pp. 289-297. AAAI Press, 2014. For more details on Cartesian CEGAR and saturated cost partitioning, see the journal paper Jendrik Seipp and Malte Helmert. Counterexample-Guided Cartesian Abstraction Refinement for Classical Planning . Journal of Artificial Intelligence Research 62:535-577. 2018. For a description of the incremental search, see the paper Jendrik Seipp, Samuel von Allmen and Malte Helmert. Incremental Search for Counterexample-Guided Cartesian Abstraction Refinement . In Proceedings of the 30th International Conference on Automated Planning and Scheduling (ICAPS 2020) , pp. 244-248. AAAI Press, 2020. Finally, we describe advanced flaw selection strategies here: David Speck and Jendrik Seipp. New Refinement Strategies for Cartesian Abstractions . In Proceedings of the 32nd International Conference on Automated Planning and Scheduling (ICAPS 2022) , pp. to appear. AAAI Press, 2022. cegar(subtasks=[landmarks(order=random), goals(order=random)], max_states=infinity, max_transitions=1M, max_time=infinity, pick_flawed_abstract_state=BATCH_MIN_H, pick_split=MAX_COVER, tiebreak_split=MAX_REFINED, search_strategy=INCREMENTAL, memory_padding=500, dot_graph_verbosity=SILENT, random_seed=-1, max_concrete_states_per_abstract_state=infinity, max_state_expansions=1M, use_general_costs=true, verbosity=normal, transform=no_transform(), cache_estimates=true) subtasks (list of SubtaskGenerator ): subtask generators max_states (int [1, infinity]): maximum sum of abstract states over all abstractions max_transitions (int [0, infinity]): maximum sum of state-changing transitions (excluding self-loops) over all abstractions max_time (double [0.0, infinity]): maximum time in seconds for building abstractions pick_flawed_abstract_state ({FIRST, FIRST_ON_SHORTEST_PATH, RANDOM, MIN_H, MAX_H, BATCH_MIN_H}): flaw-selection strategy pick_split ({RANDOM, MIN_UNWANTED, MAX_UNWANTED, MIN_REFINED, MAX_REFINED, MIN_HADD, MAX_HADD, MIN_CG, MAX_CG, MAX_COVER}): split-selection strategy tiebreak_split ({RANDOM, MIN_UNWANTED, MAX_UNWANTED, MIN_REFINED, MAX_REFINED, MIN_HADD, MAX_HADD, MIN_CG, MAX_CG, MAX_COVER}): split-selection strategy for breaking ties search_strategy ({ASTAR, INCREMENTAL}): strategy for computing abstract plans memory_padding (int [0, infinity]): amount of extra memory in MB to reserve for recovering from out-of-memory situations gracefully. When the memory runs out, we stop refining and start the search. Due to memory fragmentation, the memory used for building the abstraction (states, transitions, etc.) often can't be reused for things that require big continuous blocks of memory. It is for this reason that we require a rather large amount of memory padding by default. dot_graph_verbosity ({SILENT, WRITE_TO_CONSOLE, WRITE_TO_FILE}): verbosity of printing/writing dot graphs random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. max_concrete_states_per_abstract_state (int [1, infinity]): maximum number of flawed concrete states stored per abstract state max_state_expansions (int [1, infinity]): maximum number of state expansions per flaw search use_general_costs (bool): allow negative costs in cost partitioning verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Additive CEGAR heuristic"},{"location":"Evaluator/#causal_graph_heuristic","text":"cg(max_cache_size=1000000, verbosity=normal, transform=no_transform(), cache_estimates=true) max_cache_size (int [0, infinity]): maximum number of cached entries per variable (set to 0 to disable cache) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: supported axioms: supported (in the sense that the planner won't complain -- handling of axioms might be very stupid and even render the heuristic unsafe) Properties: admissible: no consistent: no safe: no preferred operators: yes","title":"Causal graph heuristic"},{"location":"Evaluator/#ff_heuristic","text":"ff(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: supported axioms: supported (in the sense that the planner won't complain -- handling of axioms might be very stupid and even render the heuristic unsafe) Properties: admissible: no consistent: no safe: yes for tasks without axioms preferred operators: yes","title":"FF heuristic"},{"location":"Evaluator/#goal_count_heuristic","text":"goalcount(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: ignored by design conditional effects: supported axioms: supported Properties: admissible: no consistent: no safe: yes preferred operators: no","title":"Goal count heuristic"},{"location":"Evaluator/#hm_heuristic","text":"hm(m=2, verbosity=normal, transform=no_transform(), cache_estimates=true) m (int [1, infinity]): subset size verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: ignored axioms: ignored Properties: admissible: yes for tasks without conditional effects or axioms consistent: yes for tasks without conditional effects or axioms safe: yes for tasks without conditional effects or axioms preferred operators: no","title":"h^m heuristic"},{"location":"Evaluator/#max_heuristic","text":"hmax(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: supported axioms: supported (in the sense that the planner won't complain -- handling of axioms might be very stupid and even render the heuristic unsafe) Properties: admissible: yes for tasks without axioms consistent: yes for tasks without axioms safe: yes for tasks without axioms preferred operators: no","title":"Max heuristic"},{"location":"Evaluator/#landmark-count_heuristic","text":"For the inadmissible variant see the papers Silvia Richter, Malte Helmert and Matthias Westphal. Landmarks Revisited . In Proceedings of the 23rd AAAI Conference on Artificial Intelligence (AAAI 2008) , pp. 975-982. AAAI Press, 2008. and Silvia Richter and Matthias Westphal. The LAMA Planner: Guiding Cost-Based Anytime Planning with Landmarks . Journal of Artificial Intelligence Research 39:127-177. 2010. For the admissible variant see the papers Erez Karpas and Carmel Domshlak. Cost-Optimal Planning with Landmarks . In Proceedings of the 21st International Joint Conference on Artificial Intelligence (IJCAI 2009) , pp. 1728-1733. AAAI Press, 2009. and Emil Keyder and Silvia Richter and Malte Helmert. Sound and Complete Landmarks for And/Or Graphs . In Proceedings of the 19th European Conference on Artificial Intelligence (ECAI 2010) , pp. 335-340. IOS Press, 2010. lmcount(lm_factory, admissible=false, cost_partitioning=SUBOPTIMAL, pref=false, alm=true, reuse_costs=false, greedy=false, scoring_function=MAX_HEURISTIC_PER_STOLEN_COSTS, random_seed=-1, lpsolver=CPLEX, verbosity=normal, transform=no_transform(), cache_estimates=true) lm_factory ( LandmarkFactory ): the set of landmarks to use for this heuristic. The set of landmarks can be specified here, or predefined (see LandmarkFactory ). admissible (bool): get admissible estimate cost_partitioning ({OPTIMAL, SUBOPTIMAL, CANONICAL, PHO}): cost partitioning method pref (bool): identify preferred operators (see OptionCaveats#Using_preferred_operators_with_the_lmcount_heuristic) alm (bool): use action landmarks reuse_costs (bool): reuse unused costs greedy (bool): assign costs greedily scoring_function ({MAX_HEURISTIC, MIN_STOLEN_COSTS, MAX_HEURISTIC_PER_STOLEN_COSTS}): scoring function random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Optimal search: When using landmarks for optimal search ( admissible=true ), you probably also want to add this heuristic as a lazy_evaluator in the A* algorithm to improve heuristic estimates. Note: To use optimal=true , you must build the planner with LP support. See LPBuildInstructions. Differences to the literature: This heuristic differs from the description in the literature (see references above) in the set of preferred operators computed. The original implementation described in the literature computes two kinds of preferred operators: If there is an applicable operator that reaches a landmark, all such operators are preferred. If no such operators exist, perform an FF-style relaxed exploration towards the nearest landmarks (according to the landmark orderings) and use the preferred operators of this exploration. Our implementation of the heuristic only considers preferred operators of the first type and does not include the second type. The rationale for this change is that it reduces code complexity and helps more cleanly separate landmark-based and FF-based computations in LAMA-like planner configurations. In our experiments, only considering preferred operators of the first type reduces performance when using the heuristic and its preferred operators in isolation but improves performance when using this heuristic in conjunction with the FF heuristic, as in LAMA-like planner configurations. Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Note on performance for satisficing planning: The cost of a landmark is based on the cost of the operators that achieve it. For satisficing search this can be counterproductive since it is often better to focus on distance from goal (i.e. length of the plan) rather than cost.In experiments we achieved the best performance usingthe option 'transform=adapt_costs(one)' to enforce unit costs. Language features supported: action costs: supported conditional_effects: supported if the LandmarkFactory supports them; otherwise ignored with admissible=false and not allowed with admissible=true axioms: ignored with admissible=false ; not allowed with admissible=true Properties: admissible: yes if admissible=true consistent: complicated; needs further thought safe: yes except on tasks with axioms or on tasks with conditional effects when using a LandmarkFactory not supporting them preferred operators: yes (if enabled; see pref option)","title":"Landmark-count heuristic"},{"location":"Evaluator/#landmark-cut_heuristic","text":"lmcut(verbosity=normal, transform=no_transform(), cache_estimates=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: no safe: yes preferred operators: no","title":"Landmark-cut heuristic"},{"location":"Evaluator/#merge-and-shrink_heuristic","text":"This heuristic implements the algorithm described in the following paper: Silvan Sievers, Martin Wehrle and Malte Helmert. Generalized Label Reduction for Merge-and-Shrink Heuristics . In Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI 2014) , pp. 2358-2366. AAAI Press, 2014. For a more exhaustive description of merge-and-shrink, see the journal paper Silvan Sievers and Malte Helmert. Merge-and-Shrink: A Compositional Theory of Transformations of Factored Transition Systems . Journal of Artificial Intelligence Research 71:781-883. 2021. The following paper describes how to improve the DFP merge strategy with tie-breaking, and presents two new merge strategies (dyn-MIASM and SCC-DFP): Silvan Sievers, Martin Wehrle and Malte Helmert. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics . In Proceedings of the 26th International Conference on Automated Planning and Scheduling (ICAPS 2016) , pp. 294-298. AAAI Press, 2016. Details of the algorithms and the implementation are described in the paper Silvan Sievers. Merge-and-Shrink Heuristics for Classical Planning: Efficient Implementation and Partial Abstractions . In Proceedings of the 11th Annual Symposium on Combinatorial Search (SoCS 2018) , pp. 90-98. AAAI Press, 2018. merge_and_shrink(verbosity=normal, transform=no_transform(), cache_estimates=true, merge_strategy, shrink_strategy, label_reduction=<none>, prune_unreachable_states=true, prune_irrelevant_states=true, max_states=-1, max_states_before_merge=-1, threshold_before_merge=-1, main_loop_max_time=infinity) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates merge_strategy ( MergeStrategy ): See detailed documentation for merge strategies. We currently recommend SCC-DFP, which can be achieved using merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])) shrink_strategy ( ShrinkStrategy ): See detailed documentation for shrink strategies. We currently recommend non-greedy shrink_bisimulation, which can be achieved using shrink_strategy=shrink_bisimulation(greedy=false) label_reduction ( LabelReduction ): See detailed documentation for labels. There is currently only one 'option' to use label_reduction, which is label_reduction=exact Also note the interaction with shrink strategies. prune_unreachable_states (bool): If true, prune abstract states unreachable from the initial state. prune_irrelevant_states (bool): If true, prune abstract states from which no goal state can be reached. max_states (int [-1, infinity]): maximum transition system size allowed at any time point. max_states_before_merge (int [-1, infinity]): maximum transition system size allowed for two transition systems before being merged to form the synchronized product. threshold_before_merge (int [-1, infinity]): If a transition system, before being merged, surpasses this soft transition system size limit, the shrink strategy is called to possibly shrink the transition system. main_loop_max_time (double [0.0, infinity]): A limit in seconds on the runtime of the main loop of the algorithm. If the limit is exceeded, the algorithm terminates, potentially returning a factored transition system with several factors. Also note that the time limit is only checked between transformations of the main loop, but not during, so it can be exceeded if a transformation is runtime-intense. Note: Conditional effects are supported directly. Note, however, that for tasks that are not factored (in the sense of the JACM 2014 merge-and-shrink paper), the atomic transition systems on which merge-and-shrink heuristics are based are nondeterministic, which can lead to poor heuristics even when only perfect shrinking is performed. Note: When pruning unreachable states, admissibility and consistency is only guaranteed for reachable states and transitions between reachable states. While this does not impact regular A* search which will never encounter any unreachable state, it impacts techniques like symmetry-based pruning: a reachable state which is mapped to an unreachable symmetric state (which hence is pruned) would falsely be considered a dead-end and also be pruned, thus violating optimality of the search. Note: When using a time limit on the main loop of the merge-and-shrink algorithm, the heuristic will compute the maximum over all heuristics induced by the remaining factors if terminating the merge-and-shrink algorithm early. Exception: if there is an unsolvable factor, it will be used as the exclusive heuristic since the problem is unsolvable. Note: A currently recommended good configuration uses bisimulation based shrinking, the merge strategy SCC-DFP, and the appropriate label reduction setting (max_states has been altered to be between 10k and 200k in the literature): merge_and_shrink(shrink_strategy=shrink_bisimulation(greedy=false),merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order])),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50k,threshold_before_merge=1) Language features supported: action costs: supported conditional effects: supported (but see note) axioms: not supported Properties: admissible: yes (but see note) consistent: yes (but see note) safe: yes preferred operators: no","title":"Merge-and-shrink heuristic"},{"location":"Evaluator/#operator-counting_heuristic","text":"An operator-counting heuristic computes a linear program (LP) in each state. The LP has one variable Count_o for each operator o that represents how often the operator is used in a plan. Operator-counting constraints are linear constraints over these varaibles that are guaranteed to have a solution with Count_o = occurrences(o, pi) for every plan pi. Minimizing the total cost of operators subject to some operator-counting constraints is an admissible heuristic. For details, see Florian Pommerening, Gabriele Roeger, Malte Helmert and Blai Bonet. LP-based Heuristics for Cost-optimal Planning . In Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS 2014) , pp. 226-234. AAAI Press, 2014. operatorcounting(constraint_generators, use_integer_operator_counts=false, lpsolver=CPLEX, verbosity=normal, transform=no_transform(), cache_estimates=true) constraint_generators (list of ConstraintGenerator ): methods that generate constraints over operator-counting variables use_integer_operator_counts (bool): restrict operator-counting variables to integer values. Computing the heuristic with integer variables can produce higher values but requires solving a MIP instead of an LP which is generally more computationally expensive. Turning this option on can thus drastically increase the runtime. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented constraint generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented constraint generators do) Properties: admissible: yes consistent: yes, if all constraint generators represent consistent heuristics safe: yes preferred operators: no","title":"Operator-counting heuristic"},{"location":"Evaluator/#basic_evaluators","text":"","title":"Basic Evaluators"},{"location":"Evaluator/#constant_evaluator","text":"Returns a constant value. const(value=1, verbosity=normal) value (int [0, infinity]): the constant value verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Constant evaluator"},{"location":"Evaluator/#g-value_evaluator","text":"Returns the g-value (path cost) of the search node. g(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"g-value evaluator"},{"location":"Evaluator/#max_evaluator","text":"Calculates the maximum of the sub-evaluators. max(evals, verbosity=normal) evals (list of Evaluator ): at least one evaluator verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Max evaluator"},{"location":"Evaluator/#preference_evaluator","text":"Returns 0 if preferred is true and 1 otherwise. pref(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Preference evaluator"},{"location":"Evaluator/#sum_evaluator","text":"Calculates the sum of the sub-evaluators. sum(evals, verbosity=normal) evals (list of Evaluator ): at least one evaluator verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Sum evaluator"},{"location":"Evaluator/#weighted_evaluator","text":"Multiplies the value of the evaluator with the given weight. weight(eval, weight, verbosity=normal) eval ( Evaluator ): evaluator weight (int): weight verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Weighted evaluator"},{"location":"Evaluator/#cost_partitioning_heuristics","text":"","title":"Cost Partitioning Heuristics"},{"location":"Evaluator/#canonical_heuristic_over_abstractions","text":"canonical_heuristic(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Canonical heuristic over abstractions"},{"location":"Evaluator/#greedy_zero-one_cost_partitioning","text":"gzocp(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true, orders=greedy_orders(), max_orders=infinity, max_size=infinity, max_time=200, diversify=true, samples=1000, max_optimization_time=2, random_seed=-1, verbosity=normal, transform=no_transform(), cache_estimates=true) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates orders ( OrderGenerator ): order generator max_orders (int [0, infinity]): maximum number of orders max_size (int [0, infinity]): maximum heuristic size in KiB max_time (double [0, infinity]): maximum time in seconds for finding orders diversify (bool): only keep orders that have a higher heuristic value than all previous orders for any of the samples samples (int [1, infinity]): number of samples for diversification max_optimization_time (double [0, infinity]): maximum time in seconds for optimizing each order with hill climbing random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Greedy zero-one cost partitioning"},{"location":"Evaluator/#maximum_over_abstractions","text":"Maximize over a set of abstraction heuristics. maximize(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Maximum over abstractions"},{"location":"Evaluator/#optimal_cost_partitioning_heuristic","text":"ocp(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true, lpsolver=CPLEX, allow_negative_costs=true) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB allow_negative_costs (bool): use general instead of non-negative cost partitioning Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Optimal cost partitioning heuristic"},{"location":"Evaluator/#post-hoc_optimization_heuristic","text":"Compute the maximum over multiple PhO heuristics precomputed offline. pho(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true, saturated=true, orders=greedy_orders(), max_orders=infinity, max_size=infinity, max_time=200, diversify=true, samples=1000, max_optimization_time=2, random_seed=-1, lpsolver=CPLEX, verbosity=normal) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates saturated (bool): saturate costs orders ( OrderGenerator ): order generator max_orders (int [0, infinity]): maximum number of orders max_size (int [0, infinity]): maximum heuristic size in KiB max_time (double [0, infinity]): maximum time in seconds for finding orders diversify (bool): only keep orders that have a higher heuristic value than all previous orders for any of the samples samples (int [1, infinity]): number of samples for diversification max_optimization_time (double [0, infinity]): maximum time in seconds for optimizing each order with hill climbing random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Post-hoc optimization heuristic"},{"location":"Evaluator/#saturated_cost_partitioning","text":"Compute the maximum over multiple saturated cost partitioning heuristics using different orders. For details, see Jendrik Seipp, Thomas Keller and Malte Helmert. Saturated Cost Partitioning for Optimal Classical Planning . Journal of Artificial Intelligence Research 67:129-167. 2020. scp(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true, saturator=all, orders=greedy_orders(), max_orders=infinity, max_size=infinity, max_time=200, diversify=true, samples=1000, max_optimization_time=2, random_seed=-1, verbosity=normal, transform=no_transform(), cache_estimates=true) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates saturator ({all, perim, perimstar}): function that computes saturated cost functions all : preserve estimates of all states perim : preserve estimates of states in perimeter around goal perimstar : compute 'perim' first and then 'all' with remaining costs orders ( OrderGenerator ): order generator max_orders (int [0, infinity]): maximum number of orders max_size (int [0, infinity]): maximum heuristic size in KiB max_time (double [0, infinity]): maximum time in seconds for finding orders diversify (bool): only keep orders that have a higher heuristic value than all previous orders for any of the samples samples (int [1, infinity]): number of samples for diversification max_optimization_time (double [0, infinity]): maximum time in seconds for optimizing each order with hill climbing random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Difference to cegar(): The cegar() plugin computes a single saturated cost partitioning over Cartesian abstraction heuristics. In contrast, saturated_cost_partitioning() supports computing the maximum over multiple saturated cost partitionings using different heuristic orders, and it supports both Cartesian abstraction heuristics and pattern database heuristics. While cegar() interleaves abstraction computation with cost partitioning, saturated_cost_partitioning() computes all abstractions using the original costs. Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Saturated cost partitioning"},{"location":"Evaluator/#online_saturated_cost_partitioning","text":"Compute the maximum over multiple saturated cost partitioning heuristics diversified during the search. For details, see Jendrik Seipp. Online Saturated Cost Partitioning for Classical Planning . In Proceedings of the 31st International Conference on Automated Planning and Scheduling (ICAPS 2021) , pp. 317-321. AAAI Press, 2021. scp_online(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true, saturator=all, orders=greedy_orders(), max_size=infinity, max_time=200, interval=10K, debug=false, random_seed=-1) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates saturator ({all, perim, perimstar}): function that computes saturated cost functions all : preserve estimates of all states perim : preserve estimates of states in perimeter around goal perimstar : compute 'perim' first and then 'all' with remaining costs orders ( OrderGenerator ): order generator max_size (int [0, infinity]): maximum (estimated) heuristic size in KiB max_time (double [0, infinity]): maximum time in seconds for finding orders interval (int [1, infinity]): select every i-th evaluated state for online diversification debug (bool): print debug output random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: no safe: yes preferred operators: no","title":"Online saturated cost partitioning"},{"location":"Evaluator/#opportunistic_uniform_cost_partitioning","text":"Jendrik Seipp, Thomas Keller and Malte Helmert. A Comparison of Cost Partitioning Algorithms for Optimal Classical Planning . In Proceedings of the Twenty-Seventh International Conference on Automated Planning and Scheduling (ICAPS 2017) , pp. 259-268. AAAI Press, 2017. ucp(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], verbosity=normal, transform=no_transform(), cache_estimates=true, orders=greedy_orders(), max_orders=infinity, max_size=infinity, max_time=200, diversify=true, samples=1000, max_optimization_time=2, random_seed=-1, opportunistic=false, debug=false) abstractions (list of AbstractionGenerator ): abstraction generators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates orders ( OrderGenerator ): order generator max_orders (int [0, infinity]): maximum number of orders max_size (int [0, infinity]): maximum heuristic size in KiB max_time (double [0, infinity]): maximum time in seconds for finding orders diversify (bool): only keep orders that have a higher heuristic value than all previous orders for any of the samples samples (int [1, infinity]): number of samples for diversification max_optimization_time (double [0, infinity]): maximum time in seconds for optimizing each order with hill climbing random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. opportunistic (bool): recalculate uniform cost partitioning after each considered abstraction debug (bool): print debugging messages Language features supported: action costs: supported conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do) Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"(Opportunistic) uniform cost partitioning"},{"location":"Evaluator/#pattern_database_heuristics","text":"","title":"Pattern Database Heuristics"},{"location":"Evaluator/#canonical_pdb","text":"The canonical pattern database heuristic is calculated as follows. For a given pattern collection C, the value of the canonical heuristic function is the maximum over all maximal additive subsets A in C, where the value for one subset S in A is the sum of the heuristic values for all patterns in S for a given state. cpdbs(patterns=systematic(1), max_time_dominance_pruning=infinity, verbosity=normal, transform=no_transform(), cache_estimates=true) patterns ( PatternCollectionGenerator ): pattern generation method max_time_dominance_pruning (double [0.0, infinity]): The maximum time in seconds spent on dominance pruning. Using 0.0 turns off dominance pruning. Dominance pruning excludes patterns and additive subsets that will never contribute to the heuristic value because there are dominating subsets in the collection. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Canonical PDB"},{"location":"Evaluator/#ipdb","text":"This approach is a combination of using the Canonical PDB heuristic over patterns computed with the Hill climbing algorithm for pattern generation. It is a short-hand for the command-line option cpdbs(hillclimbing()) . Both the heuristic and the pattern generation algorithm are described in the following paper: Patrik Haslum, Adi Botea, Malte Helmert, Blai Bonet and Sven Koenig. Domain-Independent Construction of Pattern Database Heuristics for Cost-Optimal Planning . In Proceedings of the 22nd AAAI Conference on Artificial Intelligence (AAAI 2007) , pp. 1007-1012. AAAI Press, 2007. For implementation notes, see: Silvan Sievers, Manuela Ortlieb and Malte Helmert. Efficient Implementation of Pattern Database Heuristics for Classical Planning . In Proceedings of the Fifth Annual Symposium on Combinatorial Search (SoCS 2012) , pp. 105-111. AAAI Press, 2012. See also Canonical PDB and Hill climbing for more details. ipdb(pdb_max_size=2000000, collection_max_size=20000000, num_samples=1000, min_improvement=10, max_time=infinity, max_generated_patterns=infinity, random_seed=-1, verbosity=normal, max_time_dominance_pruning=infinity, verbosity=normal, transform=no_transform(), cache_estimates=true) pdb_max_size (int [1, infinity]): maximal number of states per pattern database collection_max_size (int [1, infinity]): maximal number of states in the pattern collection num_samples (int [1, infinity]): number of samples (random states) on which to evaluate each candidate pattern collection min_improvement (int [1, infinity]): minimum number of samples on which a candidate pattern collection must improve on the current one to be considered as the next pattern collection max_time (double [0.0, infinity]): maximum time in seconds for improving the initial pattern collection via hill climbing. If set to 0, no hill climbing is performed at all. Note that this limit only affects hill climbing. Use max_time_dominance_pruning to limit the time spent for pruning dominated patterns. max_generated_patterns (int [0, infinity]): maximum number of generated patterns random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output max_time_dominance_pruning (double [0.0, infinity]): The maximum time in seconds spent on dominance pruning. Using 0.0 turns off dominance pruning. Dominance pruning excludes patterns and additive subsets that will never contribute to the heuristic value because there are dominating subsets in the collection. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Note: The pattern collection created by the algorithm will always contain all patterns consisting of a single goal variable, even if this violates the pdb_max_size or collection_max_size limits. Note: This pattern generation method generates patterns optimized for use with the canonical pattern database heuristic.","title":"iPDB"},{"location":"Evaluator/#implementation_notes","text":"The following will very briefly describe the algorithm and explain the differences between the original implementation from 2007 and the new one in Fast Downward. The aim of the algorithm is to output a pattern collection for which the Canonical PDB yields the best heuristic estimates. The algorithm is basically a local search (hill climbing) which searches the \"pattern neighbourhood\" (starting initially with a pattern for each goal variable) for improving the pattern collection. This is done as described in the section \"pattern construction as search\" in the paper, except for the corrected search neighbourhood discussed below. For evaluating the neighbourhood, the \"counting approximation\" as introduced in the paper was implemented. An important difference however consists in the fact that this implementation computes all pattern databases for each candidate pattern rather than using A* search to compute the heuristic values only for the sample states for each pattern. Also the logic for sampling the search space differs a bit from the original implementation. The original implementation uses a random walk of a length which is binomially distributed with the mean at the estimated solution depth (estimation is done with the current pattern collection heuristic). In the Fast Downward implementation, also a random walk is used, where the length is the estimation of the number of solution steps, which is calculated by dividing the current heuristic estimate for the initial state by the average operator costs of the planning task (calculated only once and not updated during sampling!) to take non-unit cost problems into account. This yields a random walk of an expected lenght of np = 2 * estimated number of solution steps. If the random walk gets stuck, it is being restarted from the initial state, exactly as described in the original paper. The section \"avoiding redundant evaluations\" describes how the search neighbourhood of patterns can be restricted to variables that are relevant to the variables already included in the pattern by analyzing causal graphs. There is a mistake in the paper that leads to some relevant neighbouring patterns being ignored. See the errata for details. This mistake has been addressed in this implementation. The second approach described in the paper (statistical confidence interval) is not applicable to this implementation, as it doesn't use A* search but constructs the entire pattern databases for all candidate patterns anyway. The search is ended if there is no more improvement (or the improvement is smaller than the minimal improvement which can be set as an option), however there is no limit of iterations of the local search. This is similar to the techniques used in the original implementation as described in the paper. Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Implementation Notes"},{"location":"Evaluator/#pattern_database_heuristic","text":"TODO pdb(pattern=greedy(), verbosity=normal, transform=no_transform(), cache_estimates=true) pattern ( PatternGenerator ): pattern generation method verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Pattern database heuristic"},{"location":"Evaluator/#zero-one_pdb","text":"The zero/one pattern database heuristic is simply the sum of the heuristic values of all patterns in the pattern collection. In contrast to the canonical pattern database heuristic, there is no need to check for additive subsets, because the additivity of the patterns is guaranteed by action cost partitioning. This heuristic uses the most simple form of action cost partitioning, i.e. if an operator affects more than one pattern in the collection, its costs are entirely taken into account for one pattern (the first one which it affects) and set to zero for all other affected patterns. zopdbs(patterns=systematic(1), verbosity=normal, transform=no_transform(), cache_estimates=true) patterns ( PatternCollectionGenerator ): pattern generation method verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Zero-One PDB"},{"location":"Evaluator/#potential_heuristics","text":"","title":"Potential Heuristics"},{"location":"Evaluator/#potential_heuristic_optimized_for_all_states","text":"The algorithm is based on Jendrik Seipp, Florian Pommerening and Malte Helmert. New Optimization Functions for Potential Heuristics . In Proceedings of the 25th International Conference on Automated Planning and Scheduling (ICAPS 2015) , pp. 193-201. AAAI Press, 2015. all_states_potential(max_potential=1e8, lpsolver=CPLEX, verbosity=normal, transform=no_transform(), cache_estimates=true) max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound infinity disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Potential heuristic optimized for all states"},{"location":"Evaluator/#diverse_potential_heuristics","text":"The algorithm is based on Jendrik Seipp, Florian Pommerening and Malte Helmert. New Optimization Functions for Potential Heuristics . In Proceedings of the 25th International Conference on Automated Planning and Scheduling (ICAPS 2015) , pp. 193-201. AAAI Press, 2015. diverse_potentials(num_samples=1000, max_num_heuristics=infinity, max_potential=1e8, lpsolver=CPLEX, verbosity=normal, transform=no_transform(), cache_estimates=true, random_seed=-1, verbosity=normal) num_samples (int [0, infinity]): Number of states to sample max_num_heuristics (int [0, infinity]): maximum number of potential heuristics max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound infinity disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Diverse potential heuristics"},{"location":"Evaluator/#potential_heuristic_optimized_for_initial_state","text":"The algorithm is based on Jendrik Seipp, Florian Pommerening and Malte Helmert. New Optimization Functions for Potential Heuristics . In Proceedings of the 25th International Conference on Automated Planning and Scheduling (ICAPS 2015) , pp. 193-201. AAAI Press, 2015. initial_state_potential(max_potential=1e8, lpsolver=CPLEX, verbosity=normal, transform=no_transform(), cache_estimates=true) max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound infinity disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Potential heuristic optimized for initial state"},{"location":"Evaluator/#sample-based_potential_heuristics","text":"Maximum over multiple potential heuristics optimized for samples. The algorithm is based on Jendrik Seipp, Florian Pommerening and Malte Helmert. New Optimization Functions for Potential Heuristics . In Proceedings of the 25th International Conference on Automated Planning and Scheduling (ICAPS 2015) , pp. 193-201. AAAI Press, 2015. sample_based_potentials(num_heuristics=1, num_samples=1000, max_potential=1e8, lpsolver=CPLEX, verbosity=normal, transform=no_transform(), cache_estimates=true, random_seed=-1) num_heuristics (int [0, infinity]): number of potential heuristics num_samples (int [0, infinity]): Number of states to sample max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound infinity disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above. lpsolver ({CLP, CPLEX, GUROBI, SOPLEX}): external solver that should be used to solve linear programs CLP : default LP solver shipped with the COIN library CPLEX : commercial solver by IBM GUROBI : commercial solver SOPLEX : open source solver by ZIB verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output transform ( AbstractTask ): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available. cache_estimates (bool): cache heuristic estimates random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. Note: to use an LP solver, you must build the planner with LP support. See LPBuildInstructions. Language features supported: action costs: supported conditional effects: not supported axioms: not supported Properties: admissible: yes consistent: yes safe: yes preferred operators: no","title":"Sample-based potential heuristics"},{"location":"LabelReduction/","text":"This page describes the current single 'option' for label reduction. Exact generalized label reduction # This class implements the exact generalized label reduction described in the following paper: Silvan Sievers, Martin Wehrle and Malte Helmert. Generalized Label Reduction for Merge-and-Shrink Heuristics . In Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI 2014) , pp. 2358-2366. AAAI Press, 2014. exact(before_shrinking, before_merging, method=ALL_TRANSITION_SYSTEMS_WITH_FIXPOINT, system_order=RANDOM, random_seed=-1) before_shrinking (bool): apply label reduction before shrinking before_merging (bool): apply label reduction before merging method ({TWO_TRANSITION_SYSTEMS, ALL_TRANSITION_SYSTEMS, ALL_TRANSITION_SYSTEMS_WITH_FIXPOINT}): Label reduction method. See the AAAI14 paper by Sievers et al. for explanation of the default label reduction method and the 'combinable relation' .Also note that you must set at least one of the options reduce_labels_before_shrinking or reduce_labels_before_merging in order to use the chosen label reduction configuration. TWO_TRANSITION_SYSTEMS : compute the 'combinable relation' only for the two transition systems being merged next ALL_TRANSITION_SYSTEMS : compute the 'combinable relation' for labels once for every transition system and reduce labels ALL_TRANSITION_SYSTEMS_WITH_FIXPOINT : keep computing the 'combinable relation' for labels iteratively for all transition systems until no more labels can be reduced system_order ({REGULAR, REVERSE, RANDOM}): Order of transition systems for the label reduction methods that iterate over the set of all transition systems. Only useful for the choices all_transition_systems and all_transition_systems_with_fixpoint for the option label_reduction_method. REGULAR : transition systems are considered in the order given in the planner input if atomic and in the order of their creation if composite. REVERSE : inverse of REGULAR RANDOM : random order random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"LabelReduction"},{"location":"LabelReduction/#exact_generalized_label_reduction","text":"This class implements the exact generalized label reduction described in the following paper: Silvan Sievers, Martin Wehrle and Malte Helmert. Generalized Label Reduction for Merge-and-Shrink Heuristics . In Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI 2014) , pp. 2358-2366. AAAI Press, 2014. exact(before_shrinking, before_merging, method=ALL_TRANSITION_SYSTEMS_WITH_FIXPOINT, system_order=RANDOM, random_seed=-1) before_shrinking (bool): apply label reduction before shrinking before_merging (bool): apply label reduction before merging method ({TWO_TRANSITION_SYSTEMS, ALL_TRANSITION_SYSTEMS, ALL_TRANSITION_SYSTEMS_WITH_FIXPOINT}): Label reduction method. See the AAAI14 paper by Sievers et al. for explanation of the default label reduction method and the 'combinable relation' .Also note that you must set at least one of the options reduce_labels_before_shrinking or reduce_labels_before_merging in order to use the chosen label reduction configuration. TWO_TRANSITION_SYSTEMS : compute the 'combinable relation' only for the two transition systems being merged next ALL_TRANSITION_SYSTEMS : compute the 'combinable relation' for labels once for every transition system and reduce labels ALL_TRANSITION_SYSTEMS_WITH_FIXPOINT : keep computing the 'combinable relation' for labels iteratively for all transition systems until no more labels can be reduced system_order ({REGULAR, REVERSE, RANDOM}): Order of transition systems for the label reduction methods that iterate over the set of all transition systems. Only useful for the choices all_transition_systems and all_transition_systems_with_fixpoint for the option label_reduction_method. REGULAR : transition systems are considered in the order given in the planner input if atomic and in the order of their creation if composite. REVERSE : inverse of REGULAR RANDOM : random order random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"Exact generalized label reduction"},{"location":"LandmarkFactory/","text":"A landmark factory specification is either a newly created instance or a landmark factory that has been defined previously. This page describes how one can specify a new landmark factory instance. For re-using landmark factories, see OptionSyntax#Landmark_Predefinitions. This plugin type can be predefined using --landmarks . Exhaustive Landmarks # Exhaustively checks for each fact if it is a landmark.This check is done using relaxed planning. lm_exhaust(verbosity=normal, only_causal_landmarks=false) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output only_causal_landmarks (bool): keep only causal landmarks Language features supported: conditional_effects: ignored, i.e. not supported h^m Landmarks # The landmark generation method introduced by Keyder, Richter & Helmert (ECAI 2010). lm_hm(m=2, conjunctive_landmarks=true, verbosity=normal, use_orders=true) m (int): subset size (if unsure, use the default of 2) conjunctive_landmarks (bool): keep conjunctive landmarks verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output use_orders (bool): use orders between landmarks Merged Landmarks # Merges the landmarks and orderings from the parameter landmarks lm_merged(lm_factories, verbosity=normal) lm_factories (list of LandmarkFactory ): verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Precedence: Fact landmarks take precedence over disjunctive landmarks, orderings take precedence in the usual manner (gn > nat > reas > o_reas). Note: Does not currently support conjunctive landmarks Language features supported: conditional_effects: supported if all components support them HPS Orders # Adds reasonable orders and obedient reasonable orders described in the following paper J\u00f6rg Hoffmann, Julie Porteous and Laura Sebastia. Ordered Landmarks in Planning . Journal of Artificial Intelligence Research 22:215-278. 2004. lm_reasonable_orders_hps(lm_factory, verbosity=normal) lm_factory ( LandmarkFactory ): verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Language features supported: conditional_effects: supported if subcomponent supports them RHW Landmarks # The landmark generation method introduced by Richter, Helmert and Westphal (AAAI 2008). lm_rhw(disjunctive_landmarks=true, verbosity=normal, use_orders=true, only_causal_landmarks=false) disjunctive_landmarks (bool): keep disjunctive landmarks verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output use_orders (bool): use orders between landmarks only_causal_landmarks (bool): keep only causal landmarks Language features supported: conditional_effects: supported Zhu/Givan Landmarks # The landmark generation method introduced by Zhu & Givan (ICAPS 2003 Doctoral Consortium). lm_zg(verbosity=normal, use_orders=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output use_orders (bool): use orders between landmarks Language features supported: conditional_effects: We think they are supported, but this is not 100% sure.","title":"LandmarkFactory"},{"location":"LandmarkFactory/#exhaustive_landmarks","text":"Exhaustively checks for each fact if it is a landmark.This check is done using relaxed planning. lm_exhaust(verbosity=normal, only_causal_landmarks=false) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output only_causal_landmarks (bool): keep only causal landmarks Language features supported: conditional_effects: ignored, i.e. not supported","title":"Exhaustive Landmarks"},{"location":"LandmarkFactory/#hm_landmarks","text":"The landmark generation method introduced by Keyder, Richter & Helmert (ECAI 2010). lm_hm(m=2, conjunctive_landmarks=true, verbosity=normal, use_orders=true) m (int): subset size (if unsure, use the default of 2) conjunctive_landmarks (bool): keep conjunctive landmarks verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output use_orders (bool): use orders between landmarks","title":"h^m Landmarks"},{"location":"LandmarkFactory/#merged_landmarks","text":"Merges the landmarks and orderings from the parameter landmarks lm_merged(lm_factories, verbosity=normal) lm_factories (list of LandmarkFactory ): verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Precedence: Fact landmarks take precedence over disjunctive landmarks, orderings take precedence in the usual manner (gn > nat > reas > o_reas). Note: Does not currently support conjunctive landmarks Language features supported: conditional_effects: supported if all components support them","title":"Merged Landmarks"},{"location":"LandmarkFactory/#hps_orders","text":"Adds reasonable orders and obedient reasonable orders described in the following paper J\u00f6rg Hoffmann, Julie Porteous and Laura Sebastia. Ordered Landmarks in Planning . Journal of Artificial Intelligence Research 22:215-278. 2004. lm_reasonable_orders_hps(lm_factory, verbosity=normal) lm_factory ( LandmarkFactory ): verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Language features supported: conditional_effects: supported if subcomponent supports them","title":"HPS Orders"},{"location":"LandmarkFactory/#rhw_landmarks","text":"The landmark generation method introduced by Richter, Helmert and Westphal (AAAI 2008). lm_rhw(disjunctive_landmarks=true, verbosity=normal, use_orders=true, only_causal_landmarks=false) disjunctive_landmarks (bool): keep disjunctive landmarks verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output use_orders (bool): use orders between landmarks only_causal_landmarks (bool): keep only causal landmarks Language features supported: conditional_effects: supported","title":"RHW Landmarks"},{"location":"LandmarkFactory/#zhugivan_landmarks","text":"The landmark generation method introduced by Zhu & Givan (ICAPS 2003 Doctoral Consortium). lm_zg(verbosity=normal, use_orders=true) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output use_orders (bool): use orders between landmarks Language features supported: conditional_effects: We think they are supported, but this is not 100% sure.","title":"Zhu/Givan Landmarks"},{"location":"MergeScoringFunction/","text":"This page describes various merge scoring functions. A scoring function, given a list of merge candidates and a factored transition system, computes a score for each candidate based on this information and potentially some chosen options. Minimal scores are considered best. Scoring functions are currently only used within the score based filtering merge selector. DFP scoring # This scoring function computes the 'DFP' score as descrdibed in the paper \"Directed model checking with distance-preserving abstractions\" by Draeger, Finkbeiner and Podelski (SPIN 2006), adapted to planning in the following paper: Silvan Sievers, Martin Wehrle and Malte Helmert. Generalized Label Reduction for Merge-and-Shrink Heuristics . In Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI 2014) , pp. 2358-2366. AAAI Press, 2014. dfp() Note: To obtain the configurations called DFP-B-50K described in the paper, use the following configuration of the merge-and-shrink heuristic and adapt the tie-breaking criteria of total_order as desired: merge_and_shrink(merge_strategy=merge_stateless(merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order(atomic_ts_order=reverse_level,product_ts_order=new_to_old,atomic_before_product=true)])),shrink_strategy=shrink_bisimulation(greedy=false),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50000,threshold_before_merge=1) Goal relevance scoring # This scoring function assigns a merge candidate a value of 0 iff at least one of the two transition systems of the merge candidate is goal relevant in the sense that there is an abstract non-goal state. All other candidates get a score of positive infinity. goal_relevance() MIASM # This scoring function favors merging transition systems such that in their product, there are many dead states, which can then be pruned without sacrificing information. In particular, the score it assigns to a product is the ratio of alive states to the total number of states. To compute this score, this class thus computes the product of all pairs of transition systems, potentially copying and shrinking the transition systems before if otherwise their product would exceed the specified size limits. A stateless merge strategy using this scoring function is called dyn-MIASM (nowadays also called sbMIASM for score-based MIASM) and is described in the following paper: Silvan Sievers, Martin Wehrle and Malte Helmert. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics . In Proceedings of the 26th International Conference on Planning and Scheduling (ICAPS 2016) , pp. 2358-2366. AAAI Press, 2016. sf_miasm(shrink_strategy, max_states=-1, max_states_before_merge=-1, threshold_before_merge=-1, verbosity=normal) shrink_strategy ( ShrinkStrategy ): We recommend setting this to match the shrink strategy configuration given to merge_and_shrink , see note below. max_states (int [-1, infinity]): maximum transition system size allowed at any time point. max_states_before_merge (int [-1, infinity]): maximum transition system size allowed for two transition systems before being merged to form the synchronized product. threshold_before_merge (int [-1, infinity]): If a transition system, before being merged, surpasses this soft transition system size limit, the shrink strategy is called to possibly shrink the transition system. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: To obtain the configurations called dyn-MIASM described in the paper, use the following configuration of the merge-and-shrink heuristic and adapt the tie-breaking criteria of total_order as desired: merge_and_shrink(merge_strategy=merge_stateless(merge_selector=score_based_filtering(scoring_functions=[sf_miasm(shrink_strategy=shrink_bisimulation(greedy=false),max_states=50000,threshold_before_merge=1),total_order(atomic_ts_order=reverse_level,product_ts_order=new_to_old,atomic_before_product=true)])),shrink_strategy=shrink_bisimulation(greedy=false),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50000,threshold_before_merge=1) Note: Unless you know what you are doing, we recommend using the same options related to shrinking for sf_miasm as for merge_and_shrink , i.e. the options shrink_strategy , max_states , and threshold_before_merge should be set identically. Furthermore, as this scoring function maximizes the amount of possible pruning, merge-and-shrink should be configured to use full pruning, i.e. prune_unreachable_states=true and prune_irrelevant_states=true (the default). Single random # This scoring function assigns exactly one merge candidate a score of 0, chosen randomly, and infinity to all others. single_random(random_seed=-1) random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. Total order # This scoring function computes a total order on the merge candidates, based on the specified options. The score for each merge candidate correponds to its position in the order. This scoring function is mainly intended as tie-breaking, and has been introduced in the following paper: Silvan Sievers, Martin Wehrle and Malte Helmert. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics . In Proceedings of the 26th International Conference on Automated Planning and Scheduling (ICAPS 2016) , pp. 294-298. AAAI Press, 2016. Furthermore, using the atomic_ts_order option, this scoring function, if used alone in a score based filtering merge selector, can be used to emulate the corresponding (precomputed) linear merge strategies reverse level/level (independently of the other options). total_order(atomic_ts_order=reverse_level, product_ts_order=new_to_old, atomic_before_product=false, random_seed=-1) atomic_ts_order ({reverse_level, level, random}): The order in which atomic transition systems are considered when considering pairs of potential merges. reverse_level : the variable order of Fast Downward level : opposite of reverse_level random : a randomized order product_ts_order ({old_to_new, new_to_old, random}): The order in which product transition systems are considered when considering pairs of potential merges. old_to_new : consider composite transition systems from most recent to oldest, that is in decreasing index order new_to_old : opposite of old_to_new random : a randomized order atomic_before_product (bool): Consider atomic transition systems before composite ones iff true. random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"MergeScoringFunction"},{"location":"MergeScoringFunction/#dfp_scoring","text":"This scoring function computes the 'DFP' score as descrdibed in the paper \"Directed model checking with distance-preserving abstractions\" by Draeger, Finkbeiner and Podelski (SPIN 2006), adapted to planning in the following paper: Silvan Sievers, Martin Wehrle and Malte Helmert. Generalized Label Reduction for Merge-and-Shrink Heuristics . In Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI 2014) , pp. 2358-2366. AAAI Press, 2014. dfp() Note: To obtain the configurations called DFP-B-50K described in the paper, use the following configuration of the merge-and-shrink heuristic and adapt the tie-breaking criteria of total_order as desired: merge_and_shrink(merge_strategy=merge_stateless(merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order(atomic_ts_order=reverse_level,product_ts_order=new_to_old,atomic_before_product=true)])),shrink_strategy=shrink_bisimulation(greedy=false),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50000,threshold_before_merge=1)","title":"DFP scoring"},{"location":"MergeScoringFunction/#goal_relevance_scoring","text":"This scoring function assigns a merge candidate a value of 0 iff at least one of the two transition systems of the merge candidate is goal relevant in the sense that there is an abstract non-goal state. All other candidates get a score of positive infinity. goal_relevance()","title":"Goal relevance scoring"},{"location":"MergeScoringFunction/#miasm","text":"This scoring function favors merging transition systems such that in their product, there are many dead states, which can then be pruned without sacrificing information. In particular, the score it assigns to a product is the ratio of alive states to the total number of states. To compute this score, this class thus computes the product of all pairs of transition systems, potentially copying and shrinking the transition systems before if otherwise their product would exceed the specified size limits. A stateless merge strategy using this scoring function is called dyn-MIASM (nowadays also called sbMIASM for score-based MIASM) and is described in the following paper: Silvan Sievers, Martin Wehrle and Malte Helmert. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics . In Proceedings of the 26th International Conference on Planning and Scheduling (ICAPS 2016) , pp. 2358-2366. AAAI Press, 2016. sf_miasm(shrink_strategy, max_states=-1, max_states_before_merge=-1, threshold_before_merge=-1, verbosity=normal) shrink_strategy ( ShrinkStrategy ): We recommend setting this to match the shrink strategy configuration given to merge_and_shrink , see note below. max_states (int [-1, infinity]): maximum transition system size allowed at any time point. max_states_before_merge (int [-1, infinity]): maximum transition system size allowed for two transition systems before being merged to form the synchronized product. threshold_before_merge (int [-1, infinity]): If a transition system, before being merged, surpasses this soft transition system size limit, the shrink strategy is called to possibly shrink the transition system. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: To obtain the configurations called dyn-MIASM described in the paper, use the following configuration of the merge-and-shrink heuristic and adapt the tie-breaking criteria of total_order as desired: merge_and_shrink(merge_strategy=merge_stateless(merge_selector=score_based_filtering(scoring_functions=[sf_miasm(shrink_strategy=shrink_bisimulation(greedy=false),max_states=50000,threshold_before_merge=1),total_order(atomic_ts_order=reverse_level,product_ts_order=new_to_old,atomic_before_product=true)])),shrink_strategy=shrink_bisimulation(greedy=false),label_reduction=exact(before_shrinking=true,before_merging=false),max_states=50000,threshold_before_merge=1) Note: Unless you know what you are doing, we recommend using the same options related to shrinking for sf_miasm as for merge_and_shrink , i.e. the options shrink_strategy , max_states , and threshold_before_merge should be set identically. Furthermore, as this scoring function maximizes the amount of possible pruning, merge-and-shrink should be configured to use full pruning, i.e. prune_unreachable_states=true and prune_irrelevant_states=true (the default).","title":"MIASM"},{"location":"MergeScoringFunction/#single_random","text":"This scoring function assigns exactly one merge candidate a score of 0, chosen randomly, and infinity to all others. single_random(random_seed=-1) random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"Single random"},{"location":"MergeScoringFunction/#total_order","text":"This scoring function computes a total order on the merge candidates, based on the specified options. The score for each merge candidate correponds to its position in the order. This scoring function is mainly intended as tie-breaking, and has been introduced in the following paper: Silvan Sievers, Martin Wehrle and Malte Helmert. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics . In Proceedings of the 26th International Conference on Automated Planning and Scheduling (ICAPS 2016) , pp. 294-298. AAAI Press, 2016. Furthermore, using the atomic_ts_order option, this scoring function, if used alone in a score based filtering merge selector, can be used to emulate the corresponding (precomputed) linear merge strategies reverse level/level (independently of the other options). total_order(atomic_ts_order=reverse_level, product_ts_order=new_to_old, atomic_before_product=false, random_seed=-1) atomic_ts_order ({reverse_level, level, random}): The order in which atomic transition systems are considered when considering pairs of potential merges. reverse_level : the variable order of Fast Downward level : opposite of reverse_level random : a randomized order product_ts_order ({old_to_new, new_to_old, random}): The order in which product transition systems are considered when considering pairs of potential merges. old_to_new : consider composite transition systems from most recent to oldest, that is in decreasing index order new_to_old : opposite of old_to_new random : a randomized order atomic_before_product (bool): Consider atomic transition systems before composite ones iff true. random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"Total order"},{"location":"MergeSelector/","text":"This page describes the available merge selectors. They are used to compute the next merge purely based on the state of the given factored transition system. They are used in the merge strategy of type 'stateless', but they can also easily be used in different 'combined' merged strategies. Score based filtering merge selector # This merge selector has a list of scoring functions, which are used iteratively to compute scores for merge candidates, keeping the best ones (with minimal scores) until only one is left. score_based_filtering(scoring_functions) scoring_functions (list of MergeScoringFunction ): The list of scoring functions used to compute scores for candidates.","title":"MergeSelector"},{"location":"MergeSelector/#score_based_filtering_merge_selector","text":"This merge selector has a list of scoring functions, which are used iteratively to compute scores for merge candidates, keeping the best ones (with minimal scores) until only one is left. score_based_filtering(scoring_functions) scoring_functions (list of MergeScoringFunction ): The list of scoring functions used to compute scores for candidates.","title":"Score based filtering merge selector"},{"location":"MergeStrategy/","text":"This page describes the various merge strategies supported by the planner. Precomputed merge strategy # This merge strategy has a precomputed merge tree. Note that this merge strategy does not take into account the current state of the factored transition system. This also means that this merge strategy relies on the factored transition system being synchronized with this merge tree, i.e. all merges are performed exactly as given by the merge tree. merge_precomputed(merge_tree, verbosity=normal) merge_tree ( MergeTree ): The precomputed merge tree. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: An example of a precomputed merge startegy is a linear merge strategy, which can be obtained using: merge_strategy=merge_precomputed(merge_tree=linear(<variable_order>)) Merge strategy SSCs # This merge strategy implements the algorithm described in the paper Silvan Sievers, Martin Wehrle and Malte Helmert. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics . In Proceedings of the 26th International Conference on Planning and Scheduling (ICAPS 2016) , pp. 2358-2366. AAAI Press, 2016. In a nutshell, it computes the maximal SCCs of the causal graph, obtaining a partitioning of the task's variables. Every such partition is then merged individually, using the specified fallback merge strategy, considering the SCCs in a configurable order. Afterwards, all resulting composite abstractions are merged to form the final abstraction, again using the specified fallback merge strategy and the configurable order of the SCCs. merge_sccs(order_of_sccs=topological, merge_tree=<none>, merge_selector=<none>, verbosity=normal) order_of_sccs ({topological, reverse_topological, decreasing, increasing}): choose an ordering of the SCCs: topological/reverse_topological or decreasing/increasing in the size of the SCCs. The former two options refer to the directed graph where each obtained SCC is a 'supervertex'. For the latter two options, the tie-breaking is to use the topological order according to that same graph of SCC supervertices. merge_tree ( MergeTree ): the fallback merge strategy to use if a precomputed strategy should be used. merge_selector ( MergeSelector ): the fallback merge strategy to use if a stateless strategy should be used. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Stateless merge strategy # This merge strategy has a merge selector, which computes the next merge only depending on the current state of the factored transition system, not requiring any additional information. merge_stateless(merge_selector, verbosity=normal) merge_selector ( MergeSelector ): The merge selector to be used. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: Examples include the DFP merge strategy, which can be obtained using: merge_strategy=merge_stateless(merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order(<order_option>))])) and the (dynamic/score-based) MIASM strategy, which can be obtained using: merge_strategy=merge_stateless(merge_selector=score_based_filtering(scoring_functions=[sf_miasm(<shrinking_options>),total_order(<order_option>)]","title":"MergeStrategy"},{"location":"MergeStrategy/#precomputed_merge_strategy","text":"This merge strategy has a precomputed merge tree. Note that this merge strategy does not take into account the current state of the factored transition system. This also means that this merge strategy relies on the factored transition system being synchronized with this merge tree, i.e. all merges are performed exactly as given by the merge tree. merge_precomputed(merge_tree, verbosity=normal) merge_tree ( MergeTree ): The precomputed merge tree. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: An example of a precomputed merge startegy is a linear merge strategy, which can be obtained using: merge_strategy=merge_precomputed(merge_tree=linear(<variable_order>))","title":"Precomputed merge strategy"},{"location":"MergeStrategy/#merge_strategy_sscs","text":"This merge strategy implements the algorithm described in the paper Silvan Sievers, Martin Wehrle and Malte Helmert. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics . In Proceedings of the 26th International Conference on Planning and Scheduling (ICAPS 2016) , pp. 2358-2366. AAAI Press, 2016. In a nutshell, it computes the maximal SCCs of the causal graph, obtaining a partitioning of the task's variables. Every such partition is then merged individually, using the specified fallback merge strategy, considering the SCCs in a configurable order. Afterwards, all resulting composite abstractions are merged to form the final abstraction, again using the specified fallback merge strategy and the configurable order of the SCCs. merge_sccs(order_of_sccs=topological, merge_tree=<none>, merge_selector=<none>, verbosity=normal) order_of_sccs ({topological, reverse_topological, decreasing, increasing}): choose an ordering of the SCCs: topological/reverse_topological or decreasing/increasing in the size of the SCCs. The former two options refer to the directed graph where each obtained SCC is a 'supervertex'. For the latter two options, the tie-breaking is to use the topological order according to that same graph of SCC supervertices. merge_tree ( MergeTree ): the fallback merge strategy to use if a precomputed strategy should be used. merge_selector ( MergeSelector ): the fallback merge strategy to use if a stateless strategy should be used. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Merge strategy SSCs"},{"location":"MergeStrategy/#stateless_merge_strategy","text":"This merge strategy has a merge selector, which computes the next merge only depending on the current state of the factored transition system, not requiring any additional information. merge_stateless(merge_selector, verbosity=normal) merge_selector ( MergeSelector ): The merge selector to be used. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: Examples include the DFP merge strategy, which can be obtained using: merge_strategy=merge_stateless(merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order(<order_option>))])) and the (dynamic/score-based) MIASM strategy, which can be obtained using: merge_strategy=merge_stateless(merge_selector=score_based_filtering(scoring_functions=[sf_miasm(<shrinking_options>),total_order(<order_option>)]","title":"Stateless merge strategy"},{"location":"MergeTree/","text":"This page describes the available merge trees that can be used to precompute a merge strategy, either for the entire task or a given subset of transition systems of a given factored transition system. Merge trees are typically used in the merge strategy of type 'precomputed', but they can also be used as fallback merge strategies in 'combined' merge strategies. Linear merge trees # These merge trees implement several linear merge orders, which are described in the paper: Malte Helmert, Patrik Haslum and Joerg Hoffmann. Flexible Abstraction Heuristics for Optimal Sequential Planning . In Proceedings of the Seventeenth International Conference on Automated Planning and Scheduling (ICAPS 2007) , pp. 176-183. AAAI Press, 2007. linear(random_seed=-1, update_option=use_random, variable_order=CG_GOAL_LEVEL) random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. update_option ({use_first, use_second, use_random}): When the merge tree is used within another merge strategy, how should it be updated when a merge different to a merge from the tree is performed: choose among use_first, use_second, and use_random to choose which node of the tree should survive and represent the new merged index. Specify use_first (use_second) to let the node represententing the index that would have been merged earlier (later) survive. use_random chooses a random node. variable_order ({CG_GOAL_LEVEL, CG_GOAL_RANDOM, GOAL_CG_LEVEL, RANDOM, LEVEL, REVERSE_LEVEL}): the order in which atomic transition systems are merged","title":"MergeTree"},{"location":"MergeTree/#linear_merge_trees","text":"These merge trees implement several linear merge orders, which are described in the paper: Malte Helmert, Patrik Haslum and Joerg Hoffmann. Flexible Abstraction Heuristics for Optimal Sequential Planning . In Proceedings of the Seventeenth International Conference on Automated Planning and Scheduling (ICAPS 2007) , pp. 176-183. AAAI Press, 2007. linear(random_seed=-1, update_option=use_random, variable_order=CG_GOAL_LEVEL) random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. update_option ({use_first, use_second, use_random}): When the merge tree is used within another merge strategy, how should it be updated when a merge different to a merge from the tree is performed: choose among use_first, use_second, and use_random to choose which node of the tree should survive and represent the new merged index. Specify use_first (use_second) to let the node represententing the index that would have been merged earlier (later) survive. use_random chooses a random node. variable_order ({CG_GOAL_LEVEL, CG_GOAL_RANDOM, GOAL_CG_LEVEL, RANDOM, LEVEL, REVERSE_LEVEL}): the order in which atomic transition systems are merged","title":"Linear merge trees"},{"location":"OpenList/","text":"Alternation open list # alternates between several open lists. alt(sublists, boost=0) sublists (list of OpenList ): open lists between which this one alternates boost (int): boost value for contained open lists that are restricted to preferred successors Epsilon-greedy open list # Chooses an entry uniformly randomly with probability 'epsilon', otherwise it returns the minimum entry. The algorithm is based on Richard Valenzano, Nathan R. Sturtevant, Jonathan Schaeffer and Fan Xie. A Comparison of Knowledge-Based GBFS Enhancements and Knowledge-Free Exploration . In Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS 2014) , pp. 375-379. AAAI Press, 2014. epsilon_greedy(eval, pref_only=false, epsilon=0.2, random_seed=-1) eval ( Evaluator ): evaluator pref_only (bool): insert only nodes generated by preferred operators epsilon (double [0.0, 1.0]): probability for choosing the next entry randomly random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. Pareto open list # Selects one of the Pareto-optimal (regarding the sub-evaluators) entries for removal. pareto(evals, pref_only=false, state_uniform_selection=false, random_seed=-1) evals (list of Evaluator ): evaluators pref_only (bool): insert only nodes generated by preferred operators state_uniform_selection (bool): When removing an entry, we select a non-dominated bucket and return its oldest entry. If this option is false, we select uniformly from the non-dominated buckets; if the option is true, we weight the buckets with the number of entries. random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. Best-first open list # Open list that uses a single evaluator and FIFO tiebreaking. single(eval, pref_only=false) eval ( Evaluator ): evaluator pref_only (bool): insert only nodes generated by preferred operators Implementation Notes: Elements with the same evaluator value are stored in double-ended queues, called \"buckets\". The open list stores a map from evaluator values to buckets. Pushing and popping from a bucket runs in constant time. Therefore, inserting and removing an entry from the open list takes time O(log(n)), where n is the number of buckets. Tie-breaking open list # tiebreaking(evals, pref_only=false, unsafe_pruning=true) evals (list of Evaluator ): evaluators pref_only (bool): insert only nodes generated by preferred operators unsafe_pruning (bool): allow unsafe pruning when the main evaluator regards a state a dead end Type-based open list # Uses multiple evaluators to assign entries to buckets. All entries in a bucket have the same evaluator values. When retrieving an entry, a bucket is chosen uniformly at random and one of the contained entries is selected uniformly randomly. The algorithm is based on Fan Xie, Martin Mueller, Robert Holte and Tatsuya Imai. Type-Based Exploration with Multiple Search Queues for Satisficing Planning . In Proceedings of the Twenty-Eigth AAAI Conference Conference on Artificial Intelligence (AAAI 2014) , pp. 2395-2401. AAAI Press, 2014. type_based(evaluators, random_seed=-1) evaluators (list of Evaluator ): Evaluators used to determine the bucket for each entry. random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"OpenList"},{"location":"OpenList/#alternation_open_list","text":"alternates between several open lists. alt(sublists, boost=0) sublists (list of OpenList ): open lists between which this one alternates boost (int): boost value for contained open lists that are restricted to preferred successors","title":"Alternation open list"},{"location":"OpenList/#epsilon-greedy_open_list","text":"Chooses an entry uniformly randomly with probability 'epsilon', otherwise it returns the minimum entry. The algorithm is based on Richard Valenzano, Nathan R. Sturtevant, Jonathan Schaeffer and Fan Xie. A Comparison of Knowledge-Based GBFS Enhancements and Knowledge-Free Exploration . In Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS 2014) , pp. 375-379. AAAI Press, 2014. epsilon_greedy(eval, pref_only=false, epsilon=0.2, random_seed=-1) eval ( Evaluator ): evaluator pref_only (bool): insert only nodes generated by preferred operators epsilon (double [0.0, 1.0]): probability for choosing the next entry randomly random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"Epsilon-greedy open list"},{"location":"OpenList/#pareto_open_list","text":"Selects one of the Pareto-optimal (regarding the sub-evaluators) entries for removal. pareto(evals, pref_only=false, state_uniform_selection=false, random_seed=-1) evals (list of Evaluator ): evaluators pref_only (bool): insert only nodes generated by preferred operators state_uniform_selection (bool): When removing an entry, we select a non-dominated bucket and return its oldest entry. If this option is false, we select uniformly from the non-dominated buckets; if the option is true, we weight the buckets with the number of entries. random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"Pareto open list"},{"location":"OpenList/#best-first_open_list","text":"Open list that uses a single evaluator and FIFO tiebreaking. single(eval, pref_only=false) eval ( Evaluator ): evaluator pref_only (bool): insert only nodes generated by preferred operators Implementation Notes: Elements with the same evaluator value are stored in double-ended queues, called \"buckets\". The open list stores a map from evaluator values to buckets. Pushing and popping from a bucket runs in constant time. Therefore, inserting and removing an entry from the open list takes time O(log(n)), where n is the number of buckets.","title":"Best-first open list"},{"location":"OpenList/#tie-breaking_open_list","text":"tiebreaking(evals, pref_only=false, unsafe_pruning=true) evals (list of Evaluator ): evaluators pref_only (bool): insert only nodes generated by preferred operators unsafe_pruning (bool): allow unsafe pruning when the main evaluator regards a state a dead end","title":"Tie-breaking open list"},{"location":"OpenList/#type-based_open_list","text":"Uses multiple evaluators to assign entries to buckets. All entries in a bucket have the same evaluator values. When retrieving an entry, a bucket is chosen uniformly at random and one of the contained entries is selected uniformly randomly. The algorithm is based on Fan Xie, Martin Mueller, Robert Holte and Tatsuya Imai. Type-Based Exploration with Multiple Search Queues for Satisficing Planning . In Proceedings of the Twenty-Eigth AAAI Conference Conference on Artificial Intelligence (AAAI 2014) , pp. 2395-2401. AAAI Press, 2014. type_based(evaluators, random_seed=-1) evaluators (list of Evaluator ): Evaluators used to determine the bucket for each entry. random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"Type-based open list"},{"location":"OrderGenerator/","text":"Order abstractions for saturated cost partitioning. dynamic_greedy_orders # dynamic_greedy_orders(scoring_function=MAX_HEURISTIC_PER_STOLEN_COSTS, random_seed=-1) scoring_function ({MAX_HEURISTIC, MIN_STOLEN_COSTS, MAX_HEURISTIC_PER_STOLEN_COSTS}): scoring function random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. Greedy orders # Order abstractions greedily by a given scoring function. greedy_orders(scoring_function=MAX_HEURISTIC_PER_STOLEN_COSTS, random_seed=-1) scoring_function ({MAX_HEURISTIC, MIN_STOLEN_COSTS, MAX_HEURISTIC_PER_STOLEN_COSTS}): scoring function random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. Random orders # Shuffle abstractions randomly. random_orders(random_seed=-1) random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"OrderGenerator"},{"location":"OrderGenerator/#dynamic_greedy_orders","text":"dynamic_greedy_orders(scoring_function=MAX_HEURISTIC_PER_STOLEN_COSTS, random_seed=-1) scoring_function ({MAX_HEURISTIC, MIN_STOLEN_COSTS, MAX_HEURISTIC_PER_STOLEN_COSTS}): scoring function random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"dynamic_greedy_orders"},{"location":"OrderGenerator/#greedy_orders","text":"Order abstractions greedily by a given scoring function. greedy_orders(scoring_function=MAX_HEURISTIC_PER_STOLEN_COSTS, random_seed=-1) scoring_function ({MAX_HEURISTIC, MIN_STOLEN_COSTS, MAX_HEURISTIC_PER_STOLEN_COSTS}): scoring function random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"Greedy orders"},{"location":"OrderGenerator/#random_orders","text":"Shuffle abstractions randomly. random_orders(random_seed=-1) random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"Random orders"},{"location":"PatternCollectionGenerator/","text":"Factory for pattern collections combo # combo(max_states=1000000, verbosity=normal) max_states (int [1, infinity]): maximum abstraction size for combo strategy verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Disjoint CEGAR # This pattern collection generator uses the CEGAR algorithm to compute a pattern for the planning task. See below for a description of the algorithm and some implementation notes. The original algorithm (called single CEGAR) is described in the paper Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning . In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019) , pp. 362-367. AAAI Press, 2019. disjoint_cegar(max_pdb_size=1000000, max_collection_size=10000000, max_time=infinity, use_wildcard_plans=true, verbosity=normal, random_seed=-1) max_pdb_size (int [1, infinity]): maximum number of states per pattern database (ignored for the initial collection consisting of a singleton pattern for each goal variable) max_collection_size (int [1, infinity]): maximum number of states in the pattern collection (ignored for the initial collection consisting of a singleton pattern for each goal variable) max_time (double [0.0, infinity]): maximum time in seconds for this pattern collection generator (ignored for computing the initial collection consisting of a singleton pattern for each goal variable) use_wildcard_plans (bool): if true, compute wildcard plans which are sequences of sets of operators that induce the same transition; otherwise compute regular plans which are sequences of single operators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. Short description of the CEGAR algorithm # The CEGAR algorithm computes a pattern collection for a given planning task and a given (sub)set of its goals in a randomized order as follows. Starting from the pattern collection consisting of a singleton pattern for each goal variable, it repeatedly attempts to execute an optimal plan of each pattern in the concrete task, collects reasons why this is not possible (so-called flaws) and refines the pattern in question by adding a variable to it. Further parameters allow blacklisting a (sub)set of the non-goal variables which are then never added to the collection, limiting PDB and collection size, setting a time limit and switching between computing regular or wildcard plans, where the latter are sequences of parallel operators inducing the same abstract transition. Implementation notes about the CEGAR algorithm # The following describes differences of the implementation to the original implementation used and described in the paper. Conceptually, there is one larger difference which concerns the computation of (regular or wildcard) plans for PDBs. The original implementation used an enforced hill-climbing (EHC) search with the PDB as the perfect heuristic, which ensured finding strongly optimal plans, i.e., optimal plans with a minimum number of zero-cost operators, in domains with zero-cost operators. The original implementation also slightly modified EHC to search for a best-improving successor, chosen uniformly at random among all best-improving successors. In contrast, the current implementation computes a plan alongside the computation of the PDB itself. A modification to Dijkstra's algorithm for computing the PDB values stores, for each state, the operator leading to that state (in a regression search). This generating operator is updated only if the algorithm found a cheaper path to the state. After Dijkstra finishes, the plan computation starts at the initial state and iteratively follows the generating operator, computes all operators of the same cost inducing the same transition, until reaching a goal. This constitutes a wildcard plan. It is turned into a regular one by randomly picking a single operator for each transition. Note that this kind of plan extraction does not consider all successors of a state uniformly at random but rather uses the previously deterministically chosen generating operator to settle on one successor state, which is biased by the number of operators leading to the same successor from the given state. Further note that in the presence of zero-cost operators, this procedure does not guarantee that the computed plan is strongly optimal because it does not minimize the number of used zero-cost operators leading to the state when choosing a generating operator. Experiments have shown (issue1007) that this speeds up the computation significantly while not having a strongly negative effect on heuristic quality due to potentially computing worse plans. Two further changes fix bugs of the original implementation to match the description in the paper. The first bug fix is to raise a flaw for all goal variables of the task if the plan for a PDB can be executed on the concrete task but does not lead to a goal state. Previously, such flaws would not have been raised because all goal variables are part of the collection from the start on and therefore not considered. This means that the original implementation accidentally disallowed merging patterns due to goal violation flaws. The second bug fix is to actually randomize the order of parallel operators in wildcard plan steps. Genetic Algorithm Patterns # The following paper describes the automated creation of pattern databases with a genetic algorithm. Pattern collections are initially created with a bin-packing algorithm. The genetic algorithm is used to optimize the pattern collections with an objective function that estimates the mean heuristic value of the the pattern collections. Pattern collections with higher mean heuristic estimates are more likely selected for the next generation. Stefan Edelkamp. Automated Creation of Pattern Database Search Heuristics . In Proceedings of the 4th Workshop on Model Checking and Artificial Intelligence (!MoChArt 2006) , pp. 35-50. AAAI Press, 2007. genetic(pdb_max_size=50000, num_collections=5, num_episodes=30, mutation_probability=0.01, disjoint=false, random_seed=-1, verbosity=normal) pdb_max_size (int [1, infinity]): maximal number of states per pattern database num_collections (int [1, infinity]): number of pattern collections to maintain in the genetic algorithm (population size) num_episodes (int [0, infinity]): number of episodes for the genetic algorithm mutation_probability (double [0.0, 1.0]): probability for flipping a bit in the genetic algorithm disjoint (bool): consider a pattern collection invalid (giving it very low fitness) if its patterns are not disjoint random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: This pattern generation method uses the zero/one pattern database heuristic. Implementation Notes # The standard genetic algorithm procedure as described in the paper is implemented in Fast Downward. The implementation is close to the paper. Initialization In Fast Downward bin-packing with the next-fit strategy is used. A bin corresponds to a pattern which contains variables up to pdb_max_size . With this method each variable occurs exactly in one pattern of a collection. There are num_collections collections created. Mutation With probability mutation_probability a bit is flipped meaning that either a variable is added to a pattern or deleted from a pattern. Recombination Recombination isn't implemented in Fast Downward. In the paper recombination is described but not used. Evaluation For each pattern collection the mean heuristic value is computed. For a single pattern database the mean heuristic value is the sum of all pattern database entries divided through the number of entries. Entries with infinite heuristic values are ignored in this calculation. The sum of these individual mean heuristic values yield the mean heuristic value of the collection. Selection The higher the mean heuristic value of a pattern collection is, the more likely this pattern collection should be selected for the next generation. Therefore the mean heuristic values are normalized and converted into probabilities and Roulette Wheel Selection is used. Language features supported: action costs: supported conditional effects: not supported axioms: not supported Hill climbing # This algorithm uses hill climbing to generate patterns optimized for the Canonical PDB heuristic. It it described in the following paper: Patrik Haslum, Adi Botea, Malte Helmert, Blai Bonet and Sven Koenig. Domain-Independent Construction of Pattern Database Heuristics for Cost-Optimal Planning . In Proceedings of the 22nd AAAI Conference on Artificial Intelligence (AAAI 2007) , pp. 1007-1012. AAAI Press, 2007. For implementation notes, see: Silvan Sievers, Manuela Ortlieb and Malte Helmert. Efficient Implementation of Pattern Database Heuristics for Classical Planning . In Proceedings of the Fifth Annual Symposium on Combinatorial Search (SoCS 2012) , pp. 105-111. AAAI Press, 2012. hillclimbing(pdb_max_size=2000000, collection_max_size=20000000, num_samples=1000, min_improvement=10, max_time=infinity, max_generated_patterns=infinity, random_seed=-1, verbosity=normal) pdb_max_size (int [1, infinity]): maximal number of states per pattern database collection_max_size (int [1, infinity]): maximal number of states in the pattern collection num_samples (int [1, infinity]): number of samples (random states) on which to evaluate each candidate pattern collection min_improvement (int [1, infinity]): minimum number of samples on which a candidate pattern collection must improve on the current one to be considered as the next pattern collection max_time (double [0.0, infinity]): maximum time in seconds for improving the initial pattern collection via hill climbing. If set to 0, no hill climbing is performed at all. Note that this limit only affects hill climbing. Use max_time_dominance_pruning to limit the time spent for pruning dominated patterns. max_generated_patterns (int [0, infinity]): maximum number of generated patterns random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: The pattern collection created by the algorithm will always contain all patterns consisting of a single goal variable, even if this violates the pdb_max_size or collection_max_size limits. Note: This pattern generation method generates patterns optimized for use with the canonical pattern database heuristic. Implementation Notes # The following will very briefly describe the algorithm and explain the differences between the original implementation from 2007 and the new one in Fast Downward. The aim of the algorithm is to output a pattern collection for which the Canonical PDB yields the best heuristic estimates. The algorithm is basically a local search (hill climbing) which searches the \"pattern neighbourhood\" (starting initially with a pattern for each goal variable) for improving the pattern collection. This is done as described in the section \"pattern construction as search\" in the paper, except for the corrected search neighbourhood discussed below. For evaluating the neighbourhood, the \"counting approximation\" as introduced in the paper was implemented. An important difference however consists in the fact that this implementation computes all pattern databases for each candidate pattern rather than using A* search to compute the heuristic values only for the sample states for each pattern. Also the logic for sampling the search space differs a bit from the original implementation. The original implementation uses a random walk of a length which is binomially distributed with the mean at the estimated solution depth (estimation is done with the current pattern collection heuristic). In the Fast Downward implementation, also a random walk is used, where the length is the estimation of the number of solution steps, which is calculated by dividing the current heuristic estimate for the initial state by the average operator costs of the planning task (calculated only once and not updated during sampling!) to take non-unit cost problems into account. This yields a random walk of an expected lenght of np = 2 * estimated number of solution steps. If the random walk gets stuck, it is being restarted from the initial state, exactly as described in the original paper. The section \"avoiding redundant evaluations\" describes how the search neighbourhood of patterns can be restricted to variables that are relevant to the variables already included in the pattern by analyzing causal graphs. There is a mistake in the paper that leads to some relevant neighbouring patterns being ignored. See the errata for details. This mistake has been addressed in this implementation. The second approach described in the paper (statistical confidence interval) is not applicable to this implementation, as it doesn't use A* search but constructs the entire pattern databases for all candidate patterns anyway. The search is ended if there is no more improvement (or the improvement is smaller than the minimal improvement which can be set as an option), however there is no limit of iterations of the local search. This is similar to the techniques used in the original implementation as described in the paper. manual_patterns # manual_patterns(patterns, verbosity=normal) patterns (list of list of int): list of patterns (which are lists of variable numbers of the planning task). verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Multiple CEGAR # This pattern collection generator implements the multiple CEGAR algorithm described in the paper Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning . In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019) , pp. 362-367. AAAI Press, 2019. It is an instantiation of the 'multiple algorithm framework'. To compute a pattern in each iteration, it uses the CEGAR algorithm restricted to a single goal variable. See below for descriptions of the algorithms. multiple_cegar(max_pdb_size=1M, max_collection_size=10M, pattern_generation_max_time=infinity, total_max_time=100.0, stagnation_limit=20.0, blacklist_trigger_percentage=0.75, enable_blacklist_on_stagnation=true, verbosity=normal, random_seed=-1, use_wildcard_plans=true) max_pdb_size (int [1, infinity]): maximum number of states for each pattern database, computed by compute_pattern (possibly ignored by singleton patterns consisting of a goal variable) max_collection_size (int [1, infinity]): maximum number of states in all pattern databases of the collection (possibly ignored, see max_pdb_size) pattern_generation_max_time (double [0.0, infinity]): maximum time in seconds for each call to the algorithm for computing a single pattern total_max_time (double [0.0, infinity]): maximum time in seconds for this pattern collection generator. It will always execute at least one iteration, i.e., call the algorithm for computing a single pattern at least once. stagnation_limit (double [1.0, infinity]): maximum time in seconds this pattern generator is allowed to run without generating a new pattern. It terminates prematurely if this limit is hit unless enable_blacklist_on_stagnation is enabled. blacklist_trigger_percentage (double [0.0, 1.0]): percentage of total_max_time after which blacklisting is enabled enable_blacklist_on_stagnation (bool): if true, blacklisting is enabled when stagnation_limit is hit for the first time (unless it was already enabled due to blacklist_trigger_percentage) and pattern generation is terminated when stagnation_limit is hit for the second time. If false, pattern generation is terminated already the first time stagnation_limit is hit. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. use_wildcard_plans (bool): if true, compute wildcard plans which are sequences of sets of operators that induce the same transition; otherwise compute regular plans which are sequences of single operators Short description of the CEGAR algorithm # The CEGAR algorithm computes a pattern collection for a given planning task and a given (sub)set of its goals in a randomized order as follows. Starting from the pattern collection consisting of a singleton pattern for each goal variable, it repeatedly attempts to execute an optimal plan of each pattern in the concrete task, collects reasons why this is not possible (so-called flaws) and refines the pattern in question by adding a variable to it. Further parameters allow blacklisting a (sub)set of the non-goal variables which are then never added to the collection, limiting PDB and collection size, setting a time limit and switching between computing regular or wildcard plans, where the latter are sequences of parallel operators inducing the same abstract transition. Implementation notes about the CEGAR algorithm # The following describes differences of the implementation to the original implementation used and described in the paper. Conceptually, there is one larger difference which concerns the computation of (regular or wildcard) plans for PDBs. The original implementation used an enforced hill-climbing (EHC) search with the PDB as the perfect heuristic, which ensured finding strongly optimal plans, i.e., optimal plans with a minimum number of zero-cost operators, in domains with zero-cost operators. The original implementation also slightly modified EHC to search for a best-improving successor, chosen uniformly at random among all best-improving successors. In contrast, the current implementation computes a plan alongside the computation of the PDB itself. A modification to Dijkstra's algorithm for computing the PDB values stores, for each state, the operator leading to that state (in a regression search). This generating operator is updated only if the algorithm found a cheaper path to the state. After Dijkstra finishes, the plan computation starts at the initial state and iteratively follows the generating operator, computes all operators of the same cost inducing the same transition, until reaching a goal. This constitutes a wildcard plan. It is turned into a regular one by randomly picking a single operator for each transition. Note that this kind of plan extraction does not consider all successors of a state uniformly at random but rather uses the previously deterministically chosen generating operator to settle on one successor state, which is biased by the number of operators leading to the same successor from the given state. Further note that in the presence of zero-cost operators, this procedure does not guarantee that the computed plan is strongly optimal because it does not minimize the number of used zero-cost operators leading to the state when choosing a generating operator. Experiments have shown (issue1007) that this speeds up the computation significantly while not having a strongly negative effect on heuristic quality due to potentially computing worse plans. Two further changes fix bugs of the original implementation to match the description in the paper. The first bug fix is to raise a flaw for all goal variables of the task if the plan for a PDB can be executed on the concrete task but does not lead to a goal state. Previously, such flaws would not have been raised because all goal variables are part of the collection from the start on and therefore not considered. This means that the original implementation accidentally disallowed merging patterns due to goal violation flaws. The second bug fix is to actually randomize the order of parallel operators in wildcard plan steps. Short description of the 'multiple algorithm framework' # This algorithm is a general framework for computing a pattern collection for a given planning task. It requires as input a method for computing a single pattern for the given task and a single goal of the task. The algorithm works as follows. It first stores the goals of the task in random order. Then, it repeatedly iterates over all goals and for each goal, it uses the given method for computing a single pattern. If the pattern is new (duplicate detection), it is kept for the final collection. The algorithm runs until reaching a given time limit. Another parameter allows exiting early if no new patterns are found for a certain time ('stagnation'). Further parameters allow enabling blacklisting for the given pattern computation method after a certain time to force some diversification or to enable said blacklisting when stagnating. Implementation note about the 'multiple algorithm framework' # A difference compared to the original implementation used in the paper is that the original implementation of stagnation in the multiple CEGAR/RCG algorithms started counting the time towards stagnation only after having generated a duplicate pattern. Now, time towards stagnation starts counting from the start and is reset to the current time only when having found a new pattern or when enabling blacklisting. Multiple Random Patterns # This pattern collection generator implements the 'multiple randomized causal graph' (mRCG) algorithm described in experiments of the paper Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning . In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019) , pp. 362-367. AAAI Press, 2019. It is an instantiation of the 'multiple algorithm framework'. To compute a pattern in each iteration, it uses the random pattern algorithm, called 'single randomized causal graph' (sRCG) in the paper. See below for descriptions of the algorithms. random_patterns(max_pdb_size=1M, max_collection_size=10M, pattern_generation_max_time=infinity, total_max_time=100.0, stagnation_limit=20.0, blacklist_trigger_percentage=0.75, enable_blacklist_on_stagnation=true, verbosity=normal, random_seed=-1, bidirectional=true) max_pdb_size (int [1, infinity]): maximum number of states for each pattern database, computed by compute_pattern (possibly ignored by singleton patterns consisting of a goal variable) max_collection_size (int [1, infinity]): maximum number of states in all pattern databases of the collection (possibly ignored, see max_pdb_size) pattern_generation_max_time (double [0.0, infinity]): maximum time in seconds for each call to the algorithm for computing a single pattern total_max_time (double [0.0, infinity]): maximum time in seconds for this pattern collection generator. It will always execute at least one iteration, i.e., call the algorithm for computing a single pattern at least once. stagnation_limit (double [1.0, infinity]): maximum time in seconds this pattern generator is allowed to run without generating a new pattern. It terminates prematurely if this limit is hit unless enable_blacklist_on_stagnation is enabled. blacklist_trigger_percentage (double [0.0, 1.0]): percentage of total_max_time after which blacklisting is enabled enable_blacklist_on_stagnation (bool): if true, blacklisting is enabled when stagnation_limit is hit for the first time (unless it was already enabled due to blacklist_trigger_percentage) and pattern generation is terminated when stagnation_limit is hit for the second time. If false, pattern generation is terminated already the first time stagnation_limit is hit. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. bidirectional (bool): this option decides if the causal graph is considered to be directed or undirected selecting predecessors of already selected variables. If true (default), it is considered to be undirected (precondition-effect edges are bidirectional). If false, it is considered to be directed (a variable is a neighbor only if it is a predecessor. Short description of the random pattern algorithm # The random pattern algorithm computes a pattern for a given planning task and a single goal of the task as follows. Starting with the given goal variable, the algorithm executes a random walk on the causal graph. In each iteration, it selects a random causal graph neighbor of the current variable. It terminates if no neighbor fits the pattern due to the size limit or if the time limit is reached. Implementation notes about the random pattern algorithm # In the original implementation used in the paper, the algorithm selected a random neighbor and then checked if selecting it would violate the PDB size limit. If so, the algorithm would not select it and terminate. In the current implementation, the algorithm instead loops over all neighbors of the current variable in random order and selects the first one not violating the PDB size limit. If no such neighbor exists, the algorithm terminates. Short description of the 'multiple algorithm framework' # This algorithm is a general framework for computing a pattern collection for a given planning task. It requires as input a method for computing a single pattern for the given task and a single goal of the task. The algorithm works as follows. It first stores the goals of the task in random order. Then, it repeatedly iterates over all goals and for each goal, it uses the given method for computing a single pattern. If the pattern is new (duplicate detection), it is kept for the final collection. The algorithm runs until reaching a given time limit. Another parameter allows exiting early if no new patterns are found for a certain time ('stagnation'). Further parameters allow enabling blacklisting for the given pattern computation method after a certain time to force some diversification or to enable said blacklisting when stagnating. Implementation note about the 'multiple algorithm framework' # A difference compared to the original implementation used in the paper is that the original implementation of stagnation in the multiple CEGAR/RCG algorithms started counting the time towards stagnation only after having generated a duplicate pattern. Now, time towards stagnation starts counting from the start and is reset to the current time only when having found a new pattern or when enabling blacklisting. Sys-SCP patterns # Systematically generate larger (interesting) patterns but only keep a pattern if it's useful under a saturated cost partitioning. For details, see Jendrik Seipp. Pattern Selection for Optimal Classical Planning with Saturated Cost Partitioning . In Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI 2019) , pp. 5621-5627. IJCAI, 2019. sys_scp(max_pattern_size=infinity, max_pdb_size=2M, max_collection_size=20M, max_patterns=infinity, max_time=100, max_time_per_restart=10, max_evaluations_per_restart=infinity, max_total_evaluations=infinity, saturate=true, pattern_type=interesting_non_negative, ignore_useless_patterns=false, store_dead_ends=true, order=CG_DOWN, random_seed=-1, verbosity=normal) max_pattern_size (int [1, infinity]): maximum number of variables per pattern max_pdb_size (int [1, infinity]): maximum number of states in a PDB max_collection_size (int [1, infinity]): maximum number of states in the pattern collection max_patterns (int [1, infinity]): maximum number of patterns max_time (double [0.0, infinity]): maximum time in seconds for generating patterns max_time_per_restart (double [0.0, infinity]): maximum time in seconds for each restart max_evaluations_per_restart (int [0, infinity]): maximum pattern evaluations per the inner loop max_total_evaluations (int [0, infinity]): maximum total pattern evaluations saturate (bool): only select patterns useful in saturated cost partitionings pattern_type ({naive, interesting_general, interesting_non_negative}): type of pattern ignore_useless_patterns (bool): ignore patterns that induce no transitions with positive finite cost store_dead_ends (bool): store dead ends in dead end tree (used to prune the search later) order ({RANDOM, STATES_UP, STATES_DOWN, OPS_UP, OPS_DOWN, CG_UP, CG_DOWN}): order in which to consider patterns of the same size (based on states in projection, active operators or position of the pattern variables in the partial ordering of the causal graph) random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Systematically generated patterns # Generates all (interesting) patterns with up to pattern_max_size variables. For details, see Florian Pommerening, Gabriele Roeger and Malte Helmert. Getting the Most Out of Pattern Databases for Classical Planning . In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI 2013) , pp. 2357-2364. AAAI Press, 2013. The pattern_type=interesting_general setting was introduced in Florian Pommerening, Thomas Keller, Valentina Halasi, Jendrik Seipp, Silvan Sievers and Malte Helmert. Dantzig-Wolfe Decomposition for Cost Partitioning . In Proceedings of the 31st International Conference on Automated Planning and Scheduling (ICAPS 2021) , pp. 271-280. AAAI Press, 2021. systematic(pattern_max_size=1, pattern_type=interesting_non_negative, verbosity=normal) pattern_max_size (int [1, infinity]): max number of variables per pattern pattern_type ({naive, interesting_general, interesting_non_negative}): type of pattern verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"PatternCollectionGenerator"},{"location":"PatternCollectionGenerator/#combo","text":"combo(max_states=1000000, verbosity=normal) max_states (int [1, infinity]): maximum abstraction size for combo strategy verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"combo"},{"location":"PatternCollectionGenerator/#disjoint_cegar","text":"This pattern collection generator uses the CEGAR algorithm to compute a pattern for the planning task. See below for a description of the algorithm and some implementation notes. The original algorithm (called single CEGAR) is described in the paper Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning . In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019) , pp. 362-367. AAAI Press, 2019. disjoint_cegar(max_pdb_size=1000000, max_collection_size=10000000, max_time=infinity, use_wildcard_plans=true, verbosity=normal, random_seed=-1) max_pdb_size (int [1, infinity]): maximum number of states per pattern database (ignored for the initial collection consisting of a singleton pattern for each goal variable) max_collection_size (int [1, infinity]): maximum number of states in the pattern collection (ignored for the initial collection consisting of a singleton pattern for each goal variable) max_time (double [0.0, infinity]): maximum time in seconds for this pattern collection generator (ignored for computing the initial collection consisting of a singleton pattern for each goal variable) use_wildcard_plans (bool): if true, compute wildcard plans which are sequences of sets of operators that induce the same transition; otherwise compute regular plans which are sequences of single operators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"Disjoint CEGAR"},{"location":"PatternCollectionGenerator/#short_description_of_the_cegar_algorithm","text":"The CEGAR algorithm computes a pattern collection for a given planning task and a given (sub)set of its goals in a randomized order as follows. Starting from the pattern collection consisting of a singleton pattern for each goal variable, it repeatedly attempts to execute an optimal plan of each pattern in the concrete task, collects reasons why this is not possible (so-called flaws) and refines the pattern in question by adding a variable to it. Further parameters allow blacklisting a (sub)set of the non-goal variables which are then never added to the collection, limiting PDB and collection size, setting a time limit and switching between computing regular or wildcard plans, where the latter are sequences of parallel operators inducing the same abstract transition.","title":"Short description of the CEGAR algorithm"},{"location":"PatternCollectionGenerator/#implementation_notes_about_the_cegar_algorithm","text":"The following describes differences of the implementation to the original implementation used and described in the paper. Conceptually, there is one larger difference which concerns the computation of (regular or wildcard) plans for PDBs. The original implementation used an enforced hill-climbing (EHC) search with the PDB as the perfect heuristic, which ensured finding strongly optimal plans, i.e., optimal plans with a minimum number of zero-cost operators, in domains with zero-cost operators. The original implementation also slightly modified EHC to search for a best-improving successor, chosen uniformly at random among all best-improving successors. In contrast, the current implementation computes a plan alongside the computation of the PDB itself. A modification to Dijkstra's algorithm for computing the PDB values stores, for each state, the operator leading to that state (in a regression search). This generating operator is updated only if the algorithm found a cheaper path to the state. After Dijkstra finishes, the plan computation starts at the initial state and iteratively follows the generating operator, computes all operators of the same cost inducing the same transition, until reaching a goal. This constitutes a wildcard plan. It is turned into a regular one by randomly picking a single operator for each transition. Note that this kind of plan extraction does not consider all successors of a state uniformly at random but rather uses the previously deterministically chosen generating operator to settle on one successor state, which is biased by the number of operators leading to the same successor from the given state. Further note that in the presence of zero-cost operators, this procedure does not guarantee that the computed plan is strongly optimal because it does not minimize the number of used zero-cost operators leading to the state when choosing a generating operator. Experiments have shown (issue1007) that this speeds up the computation significantly while not having a strongly negative effect on heuristic quality due to potentially computing worse plans. Two further changes fix bugs of the original implementation to match the description in the paper. The first bug fix is to raise a flaw for all goal variables of the task if the plan for a PDB can be executed on the concrete task but does not lead to a goal state. Previously, such flaws would not have been raised because all goal variables are part of the collection from the start on and therefore not considered. This means that the original implementation accidentally disallowed merging patterns due to goal violation flaws. The second bug fix is to actually randomize the order of parallel operators in wildcard plan steps.","title":"Implementation notes about the CEGAR algorithm"},{"location":"PatternCollectionGenerator/#genetic_algorithm_patterns","text":"The following paper describes the automated creation of pattern databases with a genetic algorithm. Pattern collections are initially created with a bin-packing algorithm. The genetic algorithm is used to optimize the pattern collections with an objective function that estimates the mean heuristic value of the the pattern collections. Pattern collections with higher mean heuristic estimates are more likely selected for the next generation. Stefan Edelkamp. Automated Creation of Pattern Database Search Heuristics . In Proceedings of the 4th Workshop on Model Checking and Artificial Intelligence (!MoChArt 2006) , pp. 35-50. AAAI Press, 2007. genetic(pdb_max_size=50000, num_collections=5, num_episodes=30, mutation_probability=0.01, disjoint=false, random_seed=-1, verbosity=normal) pdb_max_size (int [1, infinity]): maximal number of states per pattern database num_collections (int [1, infinity]): number of pattern collections to maintain in the genetic algorithm (population size) num_episodes (int [0, infinity]): number of episodes for the genetic algorithm mutation_probability (double [0.0, 1.0]): probability for flipping a bit in the genetic algorithm disjoint (bool): consider a pattern collection invalid (giving it very low fitness) if its patterns are not disjoint random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: This pattern generation method uses the zero/one pattern database heuristic.","title":"Genetic Algorithm Patterns"},{"location":"PatternCollectionGenerator/#implementation_notes","text":"The standard genetic algorithm procedure as described in the paper is implemented in Fast Downward. The implementation is close to the paper. Initialization In Fast Downward bin-packing with the next-fit strategy is used. A bin corresponds to a pattern which contains variables up to pdb_max_size . With this method each variable occurs exactly in one pattern of a collection. There are num_collections collections created. Mutation With probability mutation_probability a bit is flipped meaning that either a variable is added to a pattern or deleted from a pattern. Recombination Recombination isn't implemented in Fast Downward. In the paper recombination is described but not used. Evaluation For each pattern collection the mean heuristic value is computed. For a single pattern database the mean heuristic value is the sum of all pattern database entries divided through the number of entries. Entries with infinite heuristic values are ignored in this calculation. The sum of these individual mean heuristic values yield the mean heuristic value of the collection. Selection The higher the mean heuristic value of a pattern collection is, the more likely this pattern collection should be selected for the next generation. Therefore the mean heuristic values are normalized and converted into probabilities and Roulette Wheel Selection is used. Language features supported: action costs: supported conditional effects: not supported axioms: not supported","title":"Implementation Notes"},{"location":"PatternCollectionGenerator/#hill_climbing","text":"This algorithm uses hill climbing to generate patterns optimized for the Canonical PDB heuristic. It it described in the following paper: Patrik Haslum, Adi Botea, Malte Helmert, Blai Bonet and Sven Koenig. Domain-Independent Construction of Pattern Database Heuristics for Cost-Optimal Planning . In Proceedings of the 22nd AAAI Conference on Artificial Intelligence (AAAI 2007) , pp. 1007-1012. AAAI Press, 2007. For implementation notes, see: Silvan Sievers, Manuela Ortlieb and Malte Helmert. Efficient Implementation of Pattern Database Heuristics for Classical Planning . In Proceedings of the Fifth Annual Symposium on Combinatorial Search (SoCS 2012) , pp. 105-111. AAAI Press, 2012. hillclimbing(pdb_max_size=2000000, collection_max_size=20000000, num_samples=1000, min_improvement=10, max_time=infinity, max_generated_patterns=infinity, random_seed=-1, verbosity=normal) pdb_max_size (int [1, infinity]): maximal number of states per pattern database collection_max_size (int [1, infinity]): maximal number of states in the pattern collection num_samples (int [1, infinity]): number of samples (random states) on which to evaluate each candidate pattern collection min_improvement (int [1, infinity]): minimum number of samples on which a candidate pattern collection must improve on the current one to be considered as the next pattern collection max_time (double [0.0, infinity]): maximum time in seconds for improving the initial pattern collection via hill climbing. If set to 0, no hill climbing is performed at all. Note that this limit only affects hill climbing. Use max_time_dominance_pruning to limit the time spent for pruning dominated patterns. max_generated_patterns (int [0, infinity]): maximum number of generated patterns random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note: The pattern collection created by the algorithm will always contain all patterns consisting of a single goal variable, even if this violates the pdb_max_size or collection_max_size limits. Note: This pattern generation method generates patterns optimized for use with the canonical pattern database heuristic.","title":"Hill climbing"},{"location":"PatternCollectionGenerator/#implementation_notes_1","text":"The following will very briefly describe the algorithm and explain the differences between the original implementation from 2007 and the new one in Fast Downward. The aim of the algorithm is to output a pattern collection for which the Canonical PDB yields the best heuristic estimates. The algorithm is basically a local search (hill climbing) which searches the \"pattern neighbourhood\" (starting initially with a pattern for each goal variable) for improving the pattern collection. This is done as described in the section \"pattern construction as search\" in the paper, except for the corrected search neighbourhood discussed below. For evaluating the neighbourhood, the \"counting approximation\" as introduced in the paper was implemented. An important difference however consists in the fact that this implementation computes all pattern databases for each candidate pattern rather than using A* search to compute the heuristic values only for the sample states for each pattern. Also the logic for sampling the search space differs a bit from the original implementation. The original implementation uses a random walk of a length which is binomially distributed with the mean at the estimated solution depth (estimation is done with the current pattern collection heuristic). In the Fast Downward implementation, also a random walk is used, where the length is the estimation of the number of solution steps, which is calculated by dividing the current heuristic estimate for the initial state by the average operator costs of the planning task (calculated only once and not updated during sampling!) to take non-unit cost problems into account. This yields a random walk of an expected lenght of np = 2 * estimated number of solution steps. If the random walk gets stuck, it is being restarted from the initial state, exactly as described in the original paper. The section \"avoiding redundant evaluations\" describes how the search neighbourhood of patterns can be restricted to variables that are relevant to the variables already included in the pattern by analyzing causal graphs. There is a mistake in the paper that leads to some relevant neighbouring patterns being ignored. See the errata for details. This mistake has been addressed in this implementation. The second approach described in the paper (statistical confidence interval) is not applicable to this implementation, as it doesn't use A* search but constructs the entire pattern databases for all candidate patterns anyway. The search is ended if there is no more improvement (or the improvement is smaller than the minimal improvement which can be set as an option), however there is no limit of iterations of the local search. This is similar to the techniques used in the original implementation as described in the paper.","title":"Implementation Notes"},{"location":"PatternCollectionGenerator/#manual_patterns","text":"manual_patterns(patterns, verbosity=normal) patterns (list of list of int): list of patterns (which are lists of variable numbers of the planning task). verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"manual_patterns"},{"location":"PatternCollectionGenerator/#multiple_cegar","text":"This pattern collection generator implements the multiple CEGAR algorithm described in the paper Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning . In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019) , pp. 362-367. AAAI Press, 2019. It is an instantiation of the 'multiple algorithm framework'. To compute a pattern in each iteration, it uses the CEGAR algorithm restricted to a single goal variable. See below for descriptions of the algorithms. multiple_cegar(max_pdb_size=1M, max_collection_size=10M, pattern_generation_max_time=infinity, total_max_time=100.0, stagnation_limit=20.0, blacklist_trigger_percentage=0.75, enable_blacklist_on_stagnation=true, verbosity=normal, random_seed=-1, use_wildcard_plans=true) max_pdb_size (int [1, infinity]): maximum number of states for each pattern database, computed by compute_pattern (possibly ignored by singleton patterns consisting of a goal variable) max_collection_size (int [1, infinity]): maximum number of states in all pattern databases of the collection (possibly ignored, see max_pdb_size) pattern_generation_max_time (double [0.0, infinity]): maximum time in seconds for each call to the algorithm for computing a single pattern total_max_time (double [0.0, infinity]): maximum time in seconds for this pattern collection generator. It will always execute at least one iteration, i.e., call the algorithm for computing a single pattern at least once. stagnation_limit (double [1.0, infinity]): maximum time in seconds this pattern generator is allowed to run without generating a new pattern. It terminates prematurely if this limit is hit unless enable_blacklist_on_stagnation is enabled. blacklist_trigger_percentage (double [0.0, 1.0]): percentage of total_max_time after which blacklisting is enabled enable_blacklist_on_stagnation (bool): if true, blacklisting is enabled when stagnation_limit is hit for the first time (unless it was already enabled due to blacklist_trigger_percentage) and pattern generation is terminated when stagnation_limit is hit for the second time. If false, pattern generation is terminated already the first time stagnation_limit is hit. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. use_wildcard_plans (bool): if true, compute wildcard plans which are sequences of sets of operators that induce the same transition; otherwise compute regular plans which are sequences of single operators","title":"Multiple CEGAR"},{"location":"PatternCollectionGenerator/#short_description_of_the_cegar_algorithm_1","text":"The CEGAR algorithm computes a pattern collection for a given planning task and a given (sub)set of its goals in a randomized order as follows. Starting from the pattern collection consisting of a singleton pattern for each goal variable, it repeatedly attempts to execute an optimal plan of each pattern in the concrete task, collects reasons why this is not possible (so-called flaws) and refines the pattern in question by adding a variable to it. Further parameters allow blacklisting a (sub)set of the non-goal variables which are then never added to the collection, limiting PDB and collection size, setting a time limit and switching between computing regular or wildcard plans, where the latter are sequences of parallel operators inducing the same abstract transition.","title":"Short description of the CEGAR algorithm"},{"location":"PatternCollectionGenerator/#implementation_notes_about_the_cegar_algorithm_1","text":"The following describes differences of the implementation to the original implementation used and described in the paper. Conceptually, there is one larger difference which concerns the computation of (regular or wildcard) plans for PDBs. The original implementation used an enforced hill-climbing (EHC) search with the PDB as the perfect heuristic, which ensured finding strongly optimal plans, i.e., optimal plans with a minimum number of zero-cost operators, in domains with zero-cost operators. The original implementation also slightly modified EHC to search for a best-improving successor, chosen uniformly at random among all best-improving successors. In contrast, the current implementation computes a plan alongside the computation of the PDB itself. A modification to Dijkstra's algorithm for computing the PDB values stores, for each state, the operator leading to that state (in a regression search). This generating operator is updated only if the algorithm found a cheaper path to the state. After Dijkstra finishes, the plan computation starts at the initial state and iteratively follows the generating operator, computes all operators of the same cost inducing the same transition, until reaching a goal. This constitutes a wildcard plan. It is turned into a regular one by randomly picking a single operator for each transition. Note that this kind of plan extraction does not consider all successors of a state uniformly at random but rather uses the previously deterministically chosen generating operator to settle on one successor state, which is biased by the number of operators leading to the same successor from the given state. Further note that in the presence of zero-cost operators, this procedure does not guarantee that the computed plan is strongly optimal because it does not minimize the number of used zero-cost operators leading to the state when choosing a generating operator. Experiments have shown (issue1007) that this speeds up the computation significantly while not having a strongly negative effect on heuristic quality due to potentially computing worse plans. Two further changes fix bugs of the original implementation to match the description in the paper. The first bug fix is to raise a flaw for all goal variables of the task if the plan for a PDB can be executed on the concrete task but does not lead to a goal state. Previously, such flaws would not have been raised because all goal variables are part of the collection from the start on and therefore not considered. This means that the original implementation accidentally disallowed merging patterns due to goal violation flaws. The second bug fix is to actually randomize the order of parallel operators in wildcard plan steps.","title":"Implementation notes about the CEGAR algorithm"},{"location":"PatternCollectionGenerator/#short_description_of_the_multiple_algorithm_framework","text":"This algorithm is a general framework for computing a pattern collection for a given planning task. It requires as input a method for computing a single pattern for the given task and a single goal of the task. The algorithm works as follows. It first stores the goals of the task in random order. Then, it repeatedly iterates over all goals and for each goal, it uses the given method for computing a single pattern. If the pattern is new (duplicate detection), it is kept for the final collection. The algorithm runs until reaching a given time limit. Another parameter allows exiting early if no new patterns are found for a certain time ('stagnation'). Further parameters allow enabling blacklisting for the given pattern computation method after a certain time to force some diversification or to enable said blacklisting when stagnating.","title":"Short description of the 'multiple algorithm framework'"},{"location":"PatternCollectionGenerator/#implementation_note_about_the_multiple_algorithm_framework","text":"A difference compared to the original implementation used in the paper is that the original implementation of stagnation in the multiple CEGAR/RCG algorithms started counting the time towards stagnation only after having generated a duplicate pattern. Now, time towards stagnation starts counting from the start and is reset to the current time only when having found a new pattern or when enabling blacklisting.","title":"Implementation note about the 'multiple algorithm framework'"},{"location":"PatternCollectionGenerator/#multiple_random_patterns","text":"This pattern collection generator implements the 'multiple randomized causal graph' (mRCG) algorithm described in experiments of the paper Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning . In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019) , pp. 362-367. AAAI Press, 2019. It is an instantiation of the 'multiple algorithm framework'. To compute a pattern in each iteration, it uses the random pattern algorithm, called 'single randomized causal graph' (sRCG) in the paper. See below for descriptions of the algorithms. random_patterns(max_pdb_size=1M, max_collection_size=10M, pattern_generation_max_time=infinity, total_max_time=100.0, stagnation_limit=20.0, blacklist_trigger_percentage=0.75, enable_blacklist_on_stagnation=true, verbosity=normal, random_seed=-1, bidirectional=true) max_pdb_size (int [1, infinity]): maximum number of states for each pattern database, computed by compute_pattern (possibly ignored by singleton patterns consisting of a goal variable) max_collection_size (int [1, infinity]): maximum number of states in all pattern databases of the collection (possibly ignored, see max_pdb_size) pattern_generation_max_time (double [0.0, infinity]): maximum time in seconds for each call to the algorithm for computing a single pattern total_max_time (double [0.0, infinity]): maximum time in seconds for this pattern collection generator. It will always execute at least one iteration, i.e., call the algorithm for computing a single pattern at least once. stagnation_limit (double [1.0, infinity]): maximum time in seconds this pattern generator is allowed to run without generating a new pattern. It terminates prematurely if this limit is hit unless enable_blacklist_on_stagnation is enabled. blacklist_trigger_percentage (double [0.0, 1.0]): percentage of total_max_time after which blacklisting is enabled enable_blacklist_on_stagnation (bool): if true, blacklisting is enabled when stagnation_limit is hit for the first time (unless it was already enabled due to blacklist_trigger_percentage) and pattern generation is terminated when stagnation_limit is hit for the second time. If false, pattern generation is terminated already the first time stagnation_limit is hit. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. bidirectional (bool): this option decides if the causal graph is considered to be directed or undirected selecting predecessors of already selected variables. If true (default), it is considered to be undirected (precondition-effect edges are bidirectional). If false, it is considered to be directed (a variable is a neighbor only if it is a predecessor.","title":"Multiple Random Patterns"},{"location":"PatternCollectionGenerator/#short_description_of_the_random_pattern_algorithm","text":"The random pattern algorithm computes a pattern for a given planning task and a single goal of the task as follows. Starting with the given goal variable, the algorithm executes a random walk on the causal graph. In each iteration, it selects a random causal graph neighbor of the current variable. It terminates if no neighbor fits the pattern due to the size limit or if the time limit is reached.","title":"Short description of the random pattern algorithm"},{"location":"PatternCollectionGenerator/#implementation_notes_about_the_random_pattern_algorithm","text":"In the original implementation used in the paper, the algorithm selected a random neighbor and then checked if selecting it would violate the PDB size limit. If so, the algorithm would not select it and terminate. In the current implementation, the algorithm instead loops over all neighbors of the current variable in random order and selects the first one not violating the PDB size limit. If no such neighbor exists, the algorithm terminates.","title":"Implementation notes about the random pattern algorithm"},{"location":"PatternCollectionGenerator/#short_description_of_the_multiple_algorithm_framework_1","text":"This algorithm is a general framework for computing a pattern collection for a given planning task. It requires as input a method for computing a single pattern for the given task and a single goal of the task. The algorithm works as follows. It first stores the goals of the task in random order. Then, it repeatedly iterates over all goals and for each goal, it uses the given method for computing a single pattern. If the pattern is new (duplicate detection), it is kept for the final collection. The algorithm runs until reaching a given time limit. Another parameter allows exiting early if no new patterns are found for a certain time ('stagnation'). Further parameters allow enabling blacklisting for the given pattern computation method after a certain time to force some diversification or to enable said blacklisting when stagnating.","title":"Short description of the 'multiple algorithm framework'"},{"location":"PatternCollectionGenerator/#implementation_note_about_the_multiple_algorithm_framework_1","text":"A difference compared to the original implementation used in the paper is that the original implementation of stagnation in the multiple CEGAR/RCG algorithms started counting the time towards stagnation only after having generated a duplicate pattern. Now, time towards stagnation starts counting from the start and is reset to the current time only when having found a new pattern or when enabling blacklisting.","title":"Implementation note about the 'multiple algorithm framework'"},{"location":"PatternCollectionGenerator/#sys-scp_patterns","text":"Systematically generate larger (interesting) patterns but only keep a pattern if it's useful under a saturated cost partitioning. For details, see Jendrik Seipp. Pattern Selection for Optimal Classical Planning with Saturated Cost Partitioning . In Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI 2019) , pp. 5621-5627. IJCAI, 2019. sys_scp(max_pattern_size=infinity, max_pdb_size=2M, max_collection_size=20M, max_patterns=infinity, max_time=100, max_time_per_restart=10, max_evaluations_per_restart=infinity, max_total_evaluations=infinity, saturate=true, pattern_type=interesting_non_negative, ignore_useless_patterns=false, store_dead_ends=true, order=CG_DOWN, random_seed=-1, verbosity=normal) max_pattern_size (int [1, infinity]): maximum number of variables per pattern max_pdb_size (int [1, infinity]): maximum number of states in a PDB max_collection_size (int [1, infinity]): maximum number of states in the pattern collection max_patterns (int [1, infinity]): maximum number of patterns max_time (double [0.0, infinity]): maximum time in seconds for generating patterns max_time_per_restart (double [0.0, infinity]): maximum time in seconds for each restart max_evaluations_per_restart (int [0, infinity]): maximum pattern evaluations per the inner loop max_total_evaluations (int [0, infinity]): maximum total pattern evaluations saturate (bool): only select patterns useful in saturated cost partitionings pattern_type ({naive, interesting_general, interesting_non_negative}): type of pattern ignore_useless_patterns (bool): ignore patterns that induce no transitions with positive finite cost store_dead_ends (bool): store dead ends in dead end tree (used to prune the search later) order ({RANDOM, STATES_UP, STATES_DOWN, OPS_UP, OPS_DOWN, CG_UP, CG_DOWN}): order in which to consider patterns of the same size (based on states in projection, active operators or position of the pattern variables in the partial ordering of the causal graph) random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Sys-SCP patterns"},{"location":"PatternCollectionGenerator/#systematically_generated_patterns","text":"Generates all (interesting) patterns with up to pattern_max_size variables. For details, see Florian Pommerening, Gabriele Roeger and Malte Helmert. Getting the Most Out of Pattern Databases for Classical Planning . In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI 2013) , pp. 2357-2364. AAAI Press, 2013. The pattern_type=interesting_general setting was introduced in Florian Pommerening, Thomas Keller, Valentina Halasi, Jendrik Seipp, Silvan Sievers and Malte Helmert. Dantzig-Wolfe Decomposition for Cost Partitioning . In Proceedings of the 31st International Conference on Automated Planning and Scheduling (ICAPS 2021) , pp. 271-280. AAAI Press, 2021. systematic(pattern_max_size=1, pattern_type=interesting_non_negative, verbosity=normal) pattern_max_size (int [1, infinity]): max number of variables per pattern pattern_type ({naive, interesting_general, interesting_non_negative}): type of pattern verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Systematically generated patterns"},{"location":"PatternGenerator/","text":"Factory for single patterns CEGAR # This pattern generator uses the CEGAR algorithm restricted to a random single goal of the task to compute a pattern. See below for a description of the algorithm and some implementation notes. The original algorithm (called single CEGAR) is described in the paper Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning . In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019) , pp. 362-367. AAAI Press, 2019. cegar_pattern(max_pdb_size=1000000, max_time=infinity, use_wildcard_plans=true, verbosity=normal, random_seed=-1) max_pdb_size (int [1, infinity]): maximum number of states in the final pattern database (possibly ignored by a singleton pattern consisting of a single goal variable) max_time (double [0.0, infinity]): maximum time in seconds for the pattern generation use_wildcard_plans (bool): if true, compute wildcard plans which are sequences of sets of operators that induce the same transition; otherwise compute regular plans which are sequences of single operators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. Short description of the CEGAR algorithm # The CEGAR algorithm computes a pattern collection for a given planning task and a given (sub)set of its goals in a randomized order as follows. Starting from the pattern collection consisting of a singleton pattern for each goal variable, it repeatedly attempts to execute an optimal plan of each pattern in the concrete task, collects reasons why this is not possible (so-called flaws) and refines the pattern in question by adding a variable to it. Further parameters allow blacklisting a (sub)set of the non-goal variables which are then never added to the collection, limiting PDB and collection size, setting a time limit and switching between computing regular or wildcard plans, where the latter are sequences of parallel operators inducing the same abstract transition. Implementation notes about the CEGAR algorithm # The following describes differences of the implementation to the original implementation used and described in the paper. Conceptually, there is one larger difference which concerns the computation of (regular or wildcard) plans for PDBs. The original implementation used an enforced hill-climbing (EHC) search with the PDB as the perfect heuristic, which ensured finding strongly optimal plans, i.e., optimal plans with a minimum number of zero-cost operators, in domains with zero-cost operators. The original implementation also slightly modified EHC to search for a best-improving successor, chosen uniformly at random among all best-improving successors. In contrast, the current implementation computes a plan alongside the computation of the PDB itself. A modification to Dijkstra's algorithm for computing the PDB values stores, for each state, the operator leading to that state (in a regression search). This generating operator is updated only if the algorithm found a cheaper path to the state. After Dijkstra finishes, the plan computation starts at the initial state and iteratively follows the generating operator, computes all operators of the same cost inducing the same transition, until reaching a goal. This constitutes a wildcard plan. It is turned into a regular one by randomly picking a single operator for each transition. Note that this kind of plan extraction does not consider all successors of a state uniformly at random but rather uses the previously deterministically chosen generating operator to settle on one successor state, which is biased by the number of operators leading to the same successor from the given state. Further note that in the presence of zero-cost operators, this procedure does not guarantee that the computed plan is strongly optimal because it does not minimize the number of used zero-cost operators leading to the state when choosing a generating operator. Experiments have shown (issue1007) that this speeds up the computation significantly while not having a strongly negative effect on heuristic quality due to potentially computing worse plans. Two further changes fix bugs of the original implementation to match the description in the paper. The first bug fix is to raise a flaw for all goal variables of the task if the plan for a PDB can be executed on the concrete task but does not lead to a goal state. Previously, such flaws would not have been raised because all goal variables are part of the collection from the start on and therefore not considered. This means that the original implementation accidentally disallowed merging patterns due to goal violation flaws. The second bug fix is to actually randomize the order of parallel operators in wildcard plan steps. greedy # greedy(max_states=1000000, verbosity=normal) max_states (int [1, infinity]): maximal number of abstract states in the pattern database. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output manual_pattern # manual_pattern(pattern, verbosity=normal) pattern (list of int): list of variable numbers of the planning task that should be used as pattern. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Random Pattern # This pattern generator implements the 'single randomized causal graph' algorithm described in experiments of the the paper Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning . In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019) , pp. 362-367. AAAI Press, 2019. See below for a description of the algorithm and some implementation notes. random_pattern(max_pdb_size=1000000, max_time=infinity, bidirectional=true, verbosity=normal, random_seed=-1) max_pdb_size (int [1, infinity]): maximum number of states in the final pattern database (possibly ignored by a singleton pattern consisting of a single goal variable) max_time (double [0.0, infinity]): maximum time in seconds for the pattern generation bidirectional (bool): this option decides if the causal graph is considered to be directed or undirected selecting predecessors of already selected variables. If true (default), it is considered to be undirected (precondition-effect edges are bidirectional). If false, it is considered to be directed (a variable is a neighbor only if it is a predecessor. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. Short description of the random pattern algorithm # The random pattern algorithm computes a pattern for a given planning task and a single goal of the task as follows. Starting with the given goal variable, the algorithm executes a random walk on the causal graph. In each iteration, it selects a random causal graph neighbor of the current variable. It terminates if no neighbor fits the pattern due to the size limit or if the time limit is reached. Implementation notes about the random pattern algorithm # In the original implementation used in the paper, the algorithm selected a random neighbor and then checked if selecting it would violate the PDB size limit. If so, the algorithm would not select it and terminate. In the current implementation, the algorithm instead loops over all neighbors of the current variable in random order and selects the first one not violating the PDB size limit. If no such neighbor exists, the algorithm terminates.","title":"PatternGenerator"},{"location":"PatternGenerator/#cegar","text":"This pattern generator uses the CEGAR algorithm restricted to a random single goal of the task to compute a pattern. See below for a description of the algorithm and some implementation notes. The original algorithm (called single CEGAR) is described in the paper Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning . In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019) , pp. 362-367. AAAI Press, 2019. cegar_pattern(max_pdb_size=1000000, max_time=infinity, use_wildcard_plans=true, verbosity=normal, random_seed=-1) max_pdb_size (int [1, infinity]): maximum number of states in the final pattern database (possibly ignored by a singleton pattern consisting of a single goal variable) max_time (double [0.0, infinity]): maximum time in seconds for the pattern generation use_wildcard_plans (bool): if true, compute wildcard plans which are sequences of sets of operators that induce the same transition; otherwise compute regular plans which are sequences of single operators verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"CEGAR"},{"location":"PatternGenerator/#short_description_of_the_cegar_algorithm","text":"The CEGAR algorithm computes a pattern collection for a given planning task and a given (sub)set of its goals in a randomized order as follows. Starting from the pattern collection consisting of a singleton pattern for each goal variable, it repeatedly attempts to execute an optimal plan of each pattern in the concrete task, collects reasons why this is not possible (so-called flaws) and refines the pattern in question by adding a variable to it. Further parameters allow blacklisting a (sub)set of the non-goal variables which are then never added to the collection, limiting PDB and collection size, setting a time limit and switching between computing regular or wildcard plans, where the latter are sequences of parallel operators inducing the same abstract transition.","title":"Short description of the CEGAR algorithm"},{"location":"PatternGenerator/#implementation_notes_about_the_cegar_algorithm","text":"The following describes differences of the implementation to the original implementation used and described in the paper. Conceptually, there is one larger difference which concerns the computation of (regular or wildcard) plans for PDBs. The original implementation used an enforced hill-climbing (EHC) search with the PDB as the perfect heuristic, which ensured finding strongly optimal plans, i.e., optimal plans with a minimum number of zero-cost operators, in domains with zero-cost operators. The original implementation also slightly modified EHC to search for a best-improving successor, chosen uniformly at random among all best-improving successors. In contrast, the current implementation computes a plan alongside the computation of the PDB itself. A modification to Dijkstra's algorithm for computing the PDB values stores, for each state, the operator leading to that state (in a regression search). This generating operator is updated only if the algorithm found a cheaper path to the state. After Dijkstra finishes, the plan computation starts at the initial state and iteratively follows the generating operator, computes all operators of the same cost inducing the same transition, until reaching a goal. This constitutes a wildcard plan. It is turned into a regular one by randomly picking a single operator for each transition. Note that this kind of plan extraction does not consider all successors of a state uniformly at random but rather uses the previously deterministically chosen generating operator to settle on one successor state, which is biased by the number of operators leading to the same successor from the given state. Further note that in the presence of zero-cost operators, this procedure does not guarantee that the computed plan is strongly optimal because it does not minimize the number of used zero-cost operators leading to the state when choosing a generating operator. Experiments have shown (issue1007) that this speeds up the computation significantly while not having a strongly negative effect on heuristic quality due to potentially computing worse plans. Two further changes fix bugs of the original implementation to match the description in the paper. The first bug fix is to raise a flaw for all goal variables of the task if the plan for a PDB can be executed on the concrete task but does not lead to a goal state. Previously, such flaws would not have been raised because all goal variables are part of the collection from the start on and therefore not considered. This means that the original implementation accidentally disallowed merging patterns due to goal violation flaws. The second bug fix is to actually randomize the order of parallel operators in wildcard plan steps.","title":"Implementation notes about the CEGAR algorithm"},{"location":"PatternGenerator/#greedy","text":"greedy(max_states=1000000, verbosity=normal) max_states (int [1, infinity]): maximal number of abstract states in the pattern database. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"greedy"},{"location":"PatternGenerator/#manual_pattern","text":"manual_pattern(pattern, verbosity=normal) pattern (list of int): list of variable numbers of the planning task that should be used as pattern. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"manual_pattern"},{"location":"PatternGenerator/#random_pattern","text":"This pattern generator implements the 'single randomized causal graph' algorithm described in experiments of the the paper Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning . In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019) , pp. 362-367. AAAI Press, 2019. See below for a description of the algorithm and some implementation notes. random_pattern(max_pdb_size=1000000, max_time=infinity, bidirectional=true, verbosity=normal, random_seed=-1) max_pdb_size (int [1, infinity]): maximum number of states in the final pattern database (possibly ignored by a singleton pattern consisting of a single goal variable) max_time (double [0.0, infinity]): maximum time in seconds for the pattern generation bidirectional (bool): this option decides if the causal graph is considered to be directed or undirected selecting predecessors of already selected variables. If true (default), it is considered to be undirected (precondition-effect edges are bidirectional). If false, it is considered to be directed (a variable is a neighbor only if it is a predecessor. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"Random Pattern"},{"location":"PatternGenerator/#short_description_of_the_random_pattern_algorithm","text":"The random pattern algorithm computes a pattern for a given planning task and a single goal of the task as follows. Starting with the given goal variable, the algorithm executes a random walk on the causal graph. In each iteration, it selects a random causal graph neighbor of the current variable. It terminates if no neighbor fits the pattern due to the size limit or if the time limit is reached.","title":"Short description of the random pattern algorithm"},{"location":"PatternGenerator/#implementation_notes_about_the_random_pattern_algorithm","text":"In the original implementation used in the paper, the algorithm selected a random neighbor and then checked if selecting it would violate the PDB size limit. If so, the algorithm would not select it and terminate. In the current implementation, the algorithm instead loops over all neighbors of the current variable in random order and selects the first one not violating the PDB size limit. If no such neighbor exists, the algorithm terminates.","title":"Implementation notes about the random pattern algorithm"},{"location":"PruningMethod/","text":"Prune or reorder applicable operators. Atom-centric stubborn sets # Stubborn sets are a state pruning method which computes a subset of applicable actions in each state such that completeness and optimality of the overall search is preserved. Previous stubborn set implementations mainly track information about actions. In contrast, this implementation focuses on atomic propositions (atoms), which often speeds up the computation on IPC benchmarks. For details, see Gabriele Roeger, Malte Helmert, Jendrik Seipp and Silvan Sievers. An Atom-Centric Perspective on Stubborn Sets . In Proceedings of the 13th Annual Symposium on Combinatorial Search (SoCS 2020) , pp. 57-65. AAAI Press, 2020. atom_centric_stubborn_sets(use_sibling_shortcut=true, atom_selection_strategy=quick_skip, verbosity=normal) use_sibling_shortcut (bool): use variable-based marking in addition to atom-based marking atom_selection_strategy ({fast_downward, quick_skip, static_small, dynamic_small}): Strategy for selecting unsatisfied atoms from action preconditions or the goal atoms. All strategies use the fast_downward strategy for breaking ties. fast_downward : select the atom (v, d) with the variable v that comes first in the Fast Downward variable ordering (which is based on the causal graph) quick_skip : if possible, select an unsatisfied atom whose producers are already marked static_small : select the atom achieved by the fewest number of actions dynamic_small : select the atom achieved by the fewest number of actions that are not yet part of the stubborn set verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method ( null ). We recommend using at most normal verbosity for running experiments. Limited pruning # Limited pruning applies another pruning method and switches it off after a fixed number of expansions if the pruning ratio is below a given value. The pruning ratio is the sum of all pruned operators divided by the sum of all operators before pruning, considering all previous expansions. limited_pruning(pruning, min_required_pruning_ratio=0.2, expansions_before_checking_pruning_ratio=1000, verbosity=normal) pruning ( PruningMethod ): the underlying pruning method to be applied min_required_pruning_ratio (double [0.0, 1.0]): disable pruning if the pruning ratio is lower than this value after 'expansions_before_checking_pruning_ratio' expansions expansions_before_checking_pruning_ratio (int [0, infinity]): number of expansions before deciding whether to disable pruning verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Example: To use atom centric stubborn sets and limit them, use pruning=limited_pruning(pruning=atom_centric_stubborn_sets(),min_required_pruning_ratio=0.2,expansions_before_checking_pruning_ratio=1000) in an eager search such as astar. Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method ( null ). We recommend using at most normal verbosity for running experiments. No pruning # This is a skeleton method that does not perform any pruning, i.e., all applicable operators are applied in all expanded states. null(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method ( null ). We recommend using at most normal verbosity for running experiments. StubbornSetsEC # Stubborn sets represent a state pruning method which computes a subset of applicable operators in each state such that completeness and optimality of the overall search is preserved. As stubborn sets rely on several design choices, there are different variants thereof. The variant 'StubbornSetsEC' resolves the design choices such that the resulting pruning method is guaranteed to strictly dominate the Expansion Core pruning method. For details, see Martin Wehrle, Malte Helmert, Yusra Alkhazraji and Robert Mattmueller. The Relative Pruning Power of Strong Stubborn Sets and Expansion Core . In Proceedings of the 23rd International Conference on Automated Planning and Scheduling (ICAPS 2013) , pp. 251-259. AAAI Press, 2013. stubborn_sets_ec(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method ( null ). We recommend using at most normal verbosity for running experiments. Stubborn sets simple # Stubborn sets represent a state pruning method which computes a subset of applicable operators in each state such that completeness and optimality of the overall search is preserved. As stubborn sets rely on several design choices, there are different variants thereof. The variant 'StubbornSetsSimple' resolves the design choices in a straight-forward way. For details, see the following papers: Yusra Alkhazraji, Martin Wehrle, Robert Mattmueller and Malte Helmert. A Stubborn Set Algorithm for Optimal Planning . In Proceedings of the 20th European Conference on Artificial Intelligence (ECAI 2012) , pp. 891-892. IOS Press, 2012. Martin Wehrle and Malte Helmert. Efficient Stubborn Sets: Generalized Algorithms and Selection Strategies . In Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS 2014) , pp. 323-331. AAAI Press, 2014. stubborn_sets_simple(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method ( null ). We recommend using at most normal verbosity for running experiments.","title":"PruningMethod"},{"location":"PruningMethod/#atom-centric_stubborn_sets","text":"Stubborn sets are a state pruning method which computes a subset of applicable actions in each state such that completeness and optimality of the overall search is preserved. Previous stubborn set implementations mainly track information about actions. In contrast, this implementation focuses on atomic propositions (atoms), which often speeds up the computation on IPC benchmarks. For details, see Gabriele Roeger, Malte Helmert, Jendrik Seipp and Silvan Sievers. An Atom-Centric Perspective on Stubborn Sets . In Proceedings of the 13th Annual Symposium on Combinatorial Search (SoCS 2020) , pp. 57-65. AAAI Press, 2020. atom_centric_stubborn_sets(use_sibling_shortcut=true, atom_selection_strategy=quick_skip, verbosity=normal) use_sibling_shortcut (bool): use variable-based marking in addition to atom-based marking atom_selection_strategy ({fast_downward, quick_skip, static_small, dynamic_small}): Strategy for selecting unsatisfied atoms from action preconditions or the goal atoms. All strategies use the fast_downward strategy for breaking ties. fast_downward : select the atom (v, d) with the variable v that comes first in the Fast Downward variable ordering (which is based on the causal graph) quick_skip : if possible, select an unsatisfied atom whose producers are already marked static_small : select the atom achieved by the fewest number of actions dynamic_small : select the atom achieved by the fewest number of actions that are not yet part of the stubborn set verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method ( null ). We recommend using at most normal verbosity for running experiments.","title":"Atom-centric stubborn sets"},{"location":"PruningMethod/#limited_pruning","text":"Limited pruning applies another pruning method and switches it off after a fixed number of expansions if the pruning ratio is below a given value. The pruning ratio is the sum of all pruned operators divided by the sum of all operators before pruning, considering all previous expansions. limited_pruning(pruning, min_required_pruning_ratio=0.2, expansions_before_checking_pruning_ratio=1000, verbosity=normal) pruning ( PruningMethod ): the underlying pruning method to be applied min_required_pruning_ratio (double [0.0, 1.0]): disable pruning if the pruning ratio is lower than this value after 'expansions_before_checking_pruning_ratio' expansions expansions_before_checking_pruning_ratio (int [0, infinity]): number of expansions before deciding whether to disable pruning verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Example: To use atom centric stubborn sets and limit them, use pruning=limited_pruning(pruning=atom_centric_stubborn_sets(),min_required_pruning_ratio=0.2,expansions_before_checking_pruning_ratio=1000) in an eager search such as astar. Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method ( null ). We recommend using at most normal verbosity for running experiments.","title":"Limited pruning"},{"location":"PruningMethod/#no_pruning","text":"This is a skeleton method that does not perform any pruning, i.e., all applicable operators are applied in all expanded states. null(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method ( null ). We recommend using at most normal verbosity for running experiments.","title":"No pruning"},{"location":"PruningMethod/#stubbornsetsec","text":"Stubborn sets represent a state pruning method which computes a subset of applicable operators in each state such that completeness and optimality of the overall search is preserved. As stubborn sets rely on several design choices, there are different variants thereof. The variant 'StubbornSetsEC' resolves the design choices such that the resulting pruning method is guaranteed to strictly dominate the Expansion Core pruning method. For details, see Martin Wehrle, Malte Helmert, Yusra Alkhazraji and Robert Mattmueller. The Relative Pruning Power of Strong Stubborn Sets and Expansion Core . In Proceedings of the 23rd International Conference on Automated Planning and Scheduling (ICAPS 2013) , pp. 251-259. AAAI Press, 2013. stubborn_sets_ec(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method ( null ). We recommend using at most normal verbosity for running experiments.","title":"StubbornSetsEC"},{"location":"PruningMethod/#stubborn_sets_simple","text":"Stubborn sets represent a state pruning method which computes a subset of applicable operators in each state such that completeness and optimality of the overall search is preserved. As stubborn sets rely on several design choices, there are different variants thereof. The variant 'StubbornSetsSimple' resolves the design choices in a straight-forward way. For details, see the following papers: Yusra Alkhazraji, Martin Wehrle, Robert Mattmueller and Malte Helmert. A Stubborn Set Algorithm for Optimal Planning . In Proceedings of the 20th European Conference on Artificial Intelligence (ECAI 2012) , pp. 891-892. IOS Press, 2012. Martin Wehrle and Malte Helmert. Efficient Stubborn Sets: Generalized Algorithms and Selection Strategies . In Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS 2014) , pp. 323-331. AAAI Press, 2014. stubborn_sets_simple(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method ( null ). We recommend using at most normal verbosity for running experiments.","title":"Stubborn sets simple"},{"location":"SearchEngine/","text":"A* search (eager) # A* is a special case of eager best first search that uses g+h as f-function. We break ties using the evaluator. Closed nodes are re-opened. astar(eval, lazy_evaluator=<none>, pruning=null(), cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) eval ( Evaluator ): evaluator for h-value lazy_evaluator ( Evaluator ): An evaluator that re-evaluates a state before it is expanded. pruning ( PruningMethod ): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output lazy_evaluator: When a state s is taken out of the open list, the lazy evaluator h re-evaluates s. If h(s) changes (for example because h is path-dependent), s is not expanded, but instead reinserted into the open list. This option is currently only present for the A* algorithm. Equivalent statements using general eager search # --search astar(evaluator) is equivalent to --evaluator h=evaluator --search eager(tiebreaking([sum([g(), h]), h], unsafe_pruning=false), reopen_closed=true, f_eval=sum([g(), h])) Breadth-first search # Breadth-first graph search. brfs(single_plan=true, write_plan=true, pruning=null(), verbosity=normal) single_plan (bool): Stop search after finding the first (shortest) plan. write_plan (bool): Store the necessary information during search for writing plans once they're found. pruning ( PruningMethod ): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Depth-first search # This is a depth-first tree search that avoids running in cycles by skipping states s that are already visited earlier on the path to s. Doing so, the search becomes complete. dfs(single_plan=false, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) single_plan (bool): stop after finding the first plan cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Exhaustive search # Dump the reachable state space. dump_reachable_search_space(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Eager best-first search # eager(open, reopen_closed=false, f_eval=<none>, preferred=[], pruning=null(), cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) open ( OpenList ): open list reopen_closed (bool): reopen closed nodes f_eval ( Evaluator ): set evaluator for jump statistics. (Optional; if no evaluator is used, jump statistics will not be displayed.) preferred (list of Evaluator ): use preferred operators of these evaluators pruning ( PruningMethod ): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Greedy search (eager) # eager_greedy(evals, preferred=[], boost=0, pruning=null(), cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) evals (list of Evaluator ): evaluators preferred (list of Evaluator ): use preferred operators of these evaluators boost (int): boost value for preferred operator open lists pruning ( PruningMethod ): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Open list: In most cases, eager greedy best first search uses an alternation open list with one queue for each evaluator. If preferred operator evaluators are used, it adds an extra queue for each of these evaluators that includes only the nodes that are generated with a preferred operator. If only one evaluator and no preferred operator evaluator is used, the search does not use an alternation open list but a standard open list with only one queue. Closed nodes: Closed node are not re-opened Equivalent statements using general eager search # --evaluator h2=eval2 --search eager_greedy([eval1, h2], preferred=h2, boost=100) is equivalent to --evaluator h1=eval1 --heuristic h2=eval2 --search eager(alt([single(h1), single(h1, pref_only=true), single(h2), single(h2, pref_only=true)], boost=100), preferred=h2) --search eager_greedy([eval1, eval2]) is equivalent to --search eager(alt([single(eval1), single(eval2)])) --evaluator h1=eval1 --search eager_greedy(h1, preferred=h1) is equivalent to --evaluator h1=eval1 --search eager(alt([single(h1), single(h1, pref_only=true)]), preferred=h1) --search eager_greedy(eval1) is equivalent to --search eager(single(eval1)) Eager weighted A* search # eager_wastar(evals, preferred=[], reopen_closed=true, boost=0, w=1, pruning=null(), cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) evals (list of Evaluator ): evaluators preferred (list of Evaluator ): use preferred operators of these evaluators reopen_closed (bool): reopen closed nodes boost (int): boost value for preferred operator open lists w (int): evaluator weight pruning ( PruningMethod ): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Open lists and equivalent statements using general eager search: See corresponding notes for \"(Weighted) A* search (lazy)\" Note: Eager weighted A search uses an alternation open list while A search uses a tie-breaking open list. Consequently, --search eager_wastar([h()], w=1) is not equivalent to --search astar(h()) Lazy enforced hill-climbing # ehc(h, preferred_usage=PRUNE_BY_PREFERRED, preferred=[], cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) h ( Evaluator ): heuristic preferred_usage ({PRUNE_BY_PREFERRED, RANK_PREFERRED_FIRST}): preferred operator usage preferred (list of Evaluator ): use preferred operators of these evaluators cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output IDA* search # IDA* search with an optional g-value cache. idastar(eval, initial_f_limit=0, cache_size=0, single_plan=true, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) eval ( Evaluator ): evaluator for h-value. Make sure to use cache_estimates=false. initial_f_limit (int [0, infinity]): initial depth limit cache_size (int [0, infinity]): maximum number of states to cache. For cache_size=infinity the cache fills up until approaching the memory limit, at which point the current number of states becomes the maximum cache size. single_plan (bool): stop after finding the first plan cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Iterative deepening search # ids(single_plan=true, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) single_plan (bool): stop after finding the first (shortest) plan cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Iterated search # iterated(engine_configs, pass_bound=true, repeat_last=false, continue_on_fail=false, continue_on_solve=true, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) engine_configs (list of ParseTree (this just means the input is parsed at a later point. The real type is probably a search engine.)): list of search engines for each phase pass_bound (bool): use bound from previous search. The bound is the real cost of the plan found before, regardless of the cost_type parameter. repeat_last (bool): repeat last phase of search continue_on_fail (bool): continue search after no solution found continue_on_solve (bool): continue search after solution found cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note 1: We don't cache heuristic values between search iterations at the moment. If you perform a LAMA-style iterative search, heuristic values will be computed multiple times. Note 2: The configuration --search \"iterated([lazy_wastar(merge_and_shrink(),w=10), lazy_wastar(merge_and_shrink(),w=5), lazy_wastar(merge_and_shrink(),w=3), lazy_wastar(merge_and_shrink(),w=2), lazy_wastar(merge_and_shrink(),w=1)])\" would perform the preprocessing phase of the merge and shrink heuristic 5 times (once before each iteration). To avoid this, use heuristic predefinition, which avoids duplicate preprocessing, as follows: --evaluator \"h=merge_and_shrink()\" --search \"iterated([lazy_wastar(h,w=10), lazy_wastar(h,w=5), lazy_wastar(h,w=3), lazy_wastar(h,w=2), lazy_wastar(h,w=1)])\" Note 3: If you reuse the same landmark count heuristic (using heuristic predefinition) between iterations, the path data (that is, landmark status for each visited state) will be saved between iterations. Iterated width search # iw(width=2, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) width (int [1, 2]): maximum conjunction size cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Lazy best-first search # lazy(open, reopen_closed=false, preferred=[], randomize_successors=false, preferred_successors_first=false, random_seed=-1, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) open ( OpenList ): open list reopen_closed (bool): reopen closed nodes preferred (list of Evaluator ): use preferred operators of these evaluators randomize_successors (bool): randomize the order in which successors are generated preferred_successors_first (bool): consider preferred operators first random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Successor ordering: When using randomize_successors=true and preferred_successors_first=true, randomization happens before preferred operators are moved to the front. Greedy search (lazy) # lazy_greedy(evals, preferred=[], reopen_closed=false, boost=1000, randomize_successors=false, preferred_successors_first=false, random_seed=-1, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) evals (list of Evaluator ): evaluators preferred (list of Evaluator ): use preferred operators of these evaluators reopen_closed (bool): reopen closed nodes boost (int): boost value for alternation queues that are restricted to preferred operator nodes randomize_successors (bool): randomize the order in which successors are generated preferred_successors_first (bool): consider preferred operators first random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Open lists: In most cases, lazy greedy best first search uses an alternation open list with one queue for each evaluator. If preferred operator evaluators are used, it adds an extra queue for each of these evaluators that includes only the nodes that are generated with a preferred operator. If only one evaluator and no preferred operator evaluator is used, the search does not use an alternation open list but a standard open list with only one queue. Equivalent statements using general lazy search # --evaluator h2=eval2 --search lazy_greedy([eval1, h2], preferred=h2, boost=100) is equivalent to --evaluator h1=eval1 --heuristic h2=eval2 --search lazy(alt([single(h1), single(h1, pref_only=true), single(h2), single(h2, pref_only=true)], boost=100), preferred=h2) --search lazy_greedy([eval1, eval2], boost=100) is equivalent to --search lazy(alt([single(eval1), single(eval2)], boost=100)) --evaluator h1=eval1 --search lazy_greedy(h1, preferred=h1) is equivalent to --evaluator h1=eval1 --search lazy(alt([single(h1), single(h1, pref_only=true)], boost=1000), preferred=h1) --search lazy_greedy(eval1) is equivalent to --search lazy(single(eval1)) Successor ordering: When using randomize_successors=true and preferred_successors_first=true, randomization happens before preferred operators are moved to the front. (Weighted) A* search (lazy) # Weighted A* is a special case of lazy best first search. lazy_wastar(evals, preferred=[], reopen_closed=true, boost=1000, w=1, randomize_successors=false, preferred_successors_first=false, random_seed=-1, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) evals (list of Evaluator ): evaluators preferred (list of Evaluator ): use preferred operators of these evaluators reopen_closed (bool): reopen closed nodes boost (int): boost value for preferred operator open lists w (int): evaluator weight randomize_successors (bool): randomize the order in which successors are generated preferred_successors_first (bool): consider preferred operators first random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Open lists: In the general case, it uses an alternation open list with one queue for each evaluator h that ranks the nodes by g + w * h. If preferred operator evaluators are used, it adds for each of the evaluators another such queue that only inserts nodes that are generated by preferred operators. In the special case with only one evaluator and no preferred operator evaluators, it uses a single queue that is ranked by g + w * h. Equivalent statements using general lazy search # --evaluator h1=eval1 --search lazy_wastar([h1, eval2], w=2, preferred=h1, bound=100, boost=500) is equivalent to --evaluator h1=eval1 --heuristic h2=eval2 --search lazy(alt([single(sum([g(), weight(h1, 2)])), single(sum([g(), weight(h1, 2)]), pref_only=true), single(sum([g(), weight(h2, 2)])), single(sum([g(), weight(h2, 2)]), pref_only=true)], boost=500), preferred=h1, reopen_closed=true, bound=100) --search lazy_wastar([eval1, eval2], w=2, bound=100) is equivalent to --search lazy(alt([single(sum([g(), weight(eval1, 2)])), single(sum([g(), weight(eval2, 2)]))], boost=1000), reopen_closed=true, bound=100) --search lazy_wastar([eval1, eval2], bound=100, boost=0) is equivalent to --search lazy(alt([single(sum([g(), eval1])), single(sum([g(), eval2]))]) reopen_closed=true, bound=100) --search lazy_wastar(eval1, w=2) is equivalent to --search lazy(single(sum([g(), weight(eval1, 2)])), reopen_closed=true) Successor ordering: When using randomize_successors=true and preferred_successors_first=true, randomization happens before preferred operators are moved to the front.","title":"SearchEngine"},{"location":"SearchEngine/#a_search_eager","text":"A* is a special case of eager best first search that uses g+h as f-function. We break ties using the evaluator. Closed nodes are re-opened. astar(eval, lazy_evaluator=<none>, pruning=null(), cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) eval ( Evaluator ): evaluator for h-value lazy_evaluator ( Evaluator ): An evaluator that re-evaluates a state before it is expanded. pruning ( PruningMethod ): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output lazy_evaluator: When a state s is taken out of the open list, the lazy evaluator h re-evaluates s. If h(s) changes (for example because h is path-dependent), s is not expanded, but instead reinserted into the open list. This option is currently only present for the A* algorithm.","title":"A* search (eager)"},{"location":"SearchEngine/#equivalent_statements_using_general_eager_search","text":"--search astar(evaluator) is equivalent to --evaluator h=evaluator --search eager(tiebreaking([sum([g(), h]), h], unsafe_pruning=false), reopen_closed=true, f_eval=sum([g(), h]))","title":"Equivalent statements using general eager search"},{"location":"SearchEngine/#breadth-first_search","text":"Breadth-first graph search. brfs(single_plan=true, write_plan=true, pruning=null(), verbosity=normal) single_plan (bool): Stop search after finding the first (shortest) plan. write_plan (bool): Store the necessary information during search for writing plans once they're found. pruning ( PruningMethod ): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Breadth-first search"},{"location":"SearchEngine/#depth-first_search","text":"This is a depth-first tree search that avoids running in cycles by skipping states s that are already visited earlier on the path to s. Doing so, the search becomes complete. dfs(single_plan=false, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) single_plan (bool): stop after finding the first plan cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Depth-first search"},{"location":"SearchEngine/#exhaustive_search","text":"Dump the reachable state space. dump_reachable_search_space(verbosity=normal) verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Exhaustive search"},{"location":"SearchEngine/#eager_best-first_search","text":"eager(open, reopen_closed=false, f_eval=<none>, preferred=[], pruning=null(), cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) open ( OpenList ): open list reopen_closed (bool): reopen closed nodes f_eval ( Evaluator ): set evaluator for jump statistics. (Optional; if no evaluator is used, jump statistics will not be displayed.) preferred (list of Evaluator ): use preferred operators of these evaluators pruning ( PruningMethod ): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Eager best-first search"},{"location":"SearchEngine/#greedy_search_eager","text":"eager_greedy(evals, preferred=[], boost=0, pruning=null(), cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) evals (list of Evaluator ): evaluators preferred (list of Evaluator ): use preferred operators of these evaluators boost (int): boost value for preferred operator open lists pruning ( PruningMethod ): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Open list: In most cases, eager greedy best first search uses an alternation open list with one queue for each evaluator. If preferred operator evaluators are used, it adds an extra queue for each of these evaluators that includes only the nodes that are generated with a preferred operator. If only one evaluator and no preferred operator evaluator is used, the search does not use an alternation open list but a standard open list with only one queue. Closed nodes: Closed node are not re-opened","title":"Greedy search (eager)"},{"location":"SearchEngine/#equivalent_statements_using_general_eager_search_1","text":"--evaluator h2=eval2 --search eager_greedy([eval1, h2], preferred=h2, boost=100) is equivalent to --evaluator h1=eval1 --heuristic h2=eval2 --search eager(alt([single(h1), single(h1, pref_only=true), single(h2), single(h2, pref_only=true)], boost=100), preferred=h2) --search eager_greedy([eval1, eval2]) is equivalent to --search eager(alt([single(eval1), single(eval2)])) --evaluator h1=eval1 --search eager_greedy(h1, preferred=h1) is equivalent to --evaluator h1=eval1 --search eager(alt([single(h1), single(h1, pref_only=true)]), preferred=h1) --search eager_greedy(eval1) is equivalent to --search eager(single(eval1))","title":"Equivalent statements using general eager search"},{"location":"SearchEngine/#eager_weighted_a_search","text":"eager_wastar(evals, preferred=[], reopen_closed=true, boost=0, w=1, pruning=null(), cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) evals (list of Evaluator ): evaluators preferred (list of Evaluator ): use preferred operators of these evaluators reopen_closed (bool): reopen closed nodes boost (int): boost value for preferred operator open lists w (int): evaluator weight pruning ( PruningMethod ): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Open lists and equivalent statements using general eager search: See corresponding notes for \"(Weighted) A* search (lazy)\" Note: Eager weighted A search uses an alternation open list while A search uses a tie-breaking open list. Consequently, --search eager_wastar([h()], w=1) is not equivalent to --search astar(h())","title":"Eager weighted A* search"},{"location":"SearchEngine/#lazy_enforced_hill-climbing","text":"ehc(h, preferred_usage=PRUNE_BY_PREFERRED, preferred=[], cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) h ( Evaluator ): heuristic preferred_usage ({PRUNE_BY_PREFERRED, RANK_PREFERRED_FIRST}): preferred operator usage preferred (list of Evaluator ): use preferred operators of these evaluators cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Lazy enforced hill-climbing"},{"location":"SearchEngine/#ida_search","text":"IDA* search with an optional g-value cache. idastar(eval, initial_f_limit=0, cache_size=0, single_plan=true, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) eval ( Evaluator ): evaluator for h-value. Make sure to use cache_estimates=false. initial_f_limit (int [0, infinity]): initial depth limit cache_size (int [0, infinity]): maximum number of states to cache. For cache_size=infinity the cache fills up until approaching the memory limit, at which point the current number of states becomes the maximum cache size. single_plan (bool): stop after finding the first plan cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"IDA* search"},{"location":"SearchEngine/#iterative_deepening_search","text":"ids(single_plan=true, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) single_plan (bool): stop after finding the first (shortest) plan cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Iterative deepening search"},{"location":"SearchEngine/#iterated_search","text":"iterated(engine_configs, pass_bound=true, repeat_last=false, continue_on_fail=false, continue_on_solve=true, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) engine_configs (list of ParseTree (this just means the input is parsed at a later point. The real type is probably a search engine.)): list of search engines for each phase pass_bound (bool): use bound from previous search. The bound is the real cost of the plan found before, regardless of the cost_type parameter. repeat_last (bool): repeat last phase of search continue_on_fail (bool): continue search after no solution found continue_on_solve (bool): continue search after solution found cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Note 1: We don't cache heuristic values between search iterations at the moment. If you perform a LAMA-style iterative search, heuristic values will be computed multiple times. Note 2: The configuration --search \"iterated([lazy_wastar(merge_and_shrink(),w=10), lazy_wastar(merge_and_shrink(),w=5), lazy_wastar(merge_and_shrink(),w=3), lazy_wastar(merge_and_shrink(),w=2), lazy_wastar(merge_and_shrink(),w=1)])\" would perform the preprocessing phase of the merge and shrink heuristic 5 times (once before each iteration). To avoid this, use heuristic predefinition, which avoids duplicate preprocessing, as follows: --evaluator \"h=merge_and_shrink()\" --search \"iterated([lazy_wastar(h,w=10), lazy_wastar(h,w=5), lazy_wastar(h,w=3), lazy_wastar(h,w=2), lazy_wastar(h,w=1)])\" Note 3: If you reuse the same landmark count heuristic (using heuristic predefinition) between iterations, the path data (that is, landmark status for each visited state) will be saved between iterations.","title":"Iterated search"},{"location":"SearchEngine/#iterated_width_search","text":"iw(width=2, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) width (int [1, 2]): maximum conjunction size cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output","title":"Iterated width search"},{"location":"SearchEngine/#lazy_best-first_search","text":"lazy(open, reopen_closed=false, preferred=[], randomize_successors=false, preferred_successors_first=false, random_seed=-1, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) open ( OpenList ): open list reopen_closed (bool): reopen closed nodes preferred (list of Evaluator ): use preferred operators of these evaluators randomize_successors (bool): randomize the order in which successors are generated preferred_successors_first (bool): consider preferred operators first random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Successor ordering: When using randomize_successors=true and preferred_successors_first=true, randomization happens before preferred operators are moved to the front.","title":"Lazy best-first search"},{"location":"SearchEngine/#greedy_search_lazy","text":"lazy_greedy(evals, preferred=[], reopen_closed=false, boost=1000, randomize_successors=false, preferred_successors_first=false, random_seed=-1, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) evals (list of Evaluator ): evaluators preferred (list of Evaluator ): use preferred operators of these evaluators reopen_closed (bool): reopen closed nodes boost (int): boost value for alternation queues that are restricted to preferred operator nodes randomize_successors (bool): randomize the order in which successors are generated preferred_successors_first (bool): consider preferred operators first random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Open lists: In most cases, lazy greedy best first search uses an alternation open list with one queue for each evaluator. If preferred operator evaluators are used, it adds an extra queue for each of these evaluators that includes only the nodes that are generated with a preferred operator. If only one evaluator and no preferred operator evaluator is used, the search does not use an alternation open list but a standard open list with only one queue.","title":"Greedy search (lazy)"},{"location":"SearchEngine/#equivalent_statements_using_general_lazy_search","text":"--evaluator h2=eval2 --search lazy_greedy([eval1, h2], preferred=h2, boost=100) is equivalent to --evaluator h1=eval1 --heuristic h2=eval2 --search lazy(alt([single(h1), single(h1, pref_only=true), single(h2), single(h2, pref_only=true)], boost=100), preferred=h2) --search lazy_greedy([eval1, eval2], boost=100) is equivalent to --search lazy(alt([single(eval1), single(eval2)], boost=100)) --evaluator h1=eval1 --search lazy_greedy(h1, preferred=h1) is equivalent to --evaluator h1=eval1 --search lazy(alt([single(h1), single(h1, pref_only=true)], boost=1000), preferred=h1) --search lazy_greedy(eval1) is equivalent to --search lazy(single(eval1)) Successor ordering: When using randomize_successors=true and preferred_successors_first=true, randomization happens before preferred operators are moved to the front.","title":"Equivalent statements using general lazy search"},{"location":"SearchEngine/#weighted_a_search_lazy","text":"Weighted A* is a special case of lazy best first search. lazy_wastar(evals, preferred=[], reopen_closed=true, boost=1000, w=1, randomize_successors=false, preferred_successors_first=false, random_seed=-1, cost_type=NORMAL, bound=infinity, max_time=infinity, verbosity=normal) evals (list of Evaluator ): evaluators preferred (list of Evaluator ): use preferred operators of these evaluators reopen_closed (bool): reopen closed nodes boost (int): boost value for preferred operator open lists w (int): evaluator weight randomize_successors (bool): randomize the order in which successors are generated preferred_successors_first (bool): consider preferred operators first random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. cost_type ({NORMAL, ONE, PLUSONE}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions. NORMAL : all actions are accounted for with their real cost ONE : all actions are accounted for as unit cost PLUSONE : all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search engines, but is supported for both. bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space. verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level. silent : only the most basic output normal : relevant information to monitor progress verbose : full output debug : like verbose with additional debug output Open lists: In the general case, it uses an alternation open list with one queue for each evaluator h that ranks the nodes by g + w * h. If preferred operator evaluators are used, it adds for each of the evaluators another such queue that only inserts nodes that are generated by preferred operators. In the special case with only one evaluator and no preferred operator evaluators, it uses a single queue that is ranked by g + w * h.","title":"(Weighted) A* search (lazy)"},{"location":"SearchEngine/#equivalent_statements_using_general_lazy_search_1","text":"--evaluator h1=eval1 --search lazy_wastar([h1, eval2], w=2, preferred=h1, bound=100, boost=500) is equivalent to --evaluator h1=eval1 --heuristic h2=eval2 --search lazy(alt([single(sum([g(), weight(h1, 2)])), single(sum([g(), weight(h1, 2)]), pref_only=true), single(sum([g(), weight(h2, 2)])), single(sum([g(), weight(h2, 2)]), pref_only=true)], boost=500), preferred=h1, reopen_closed=true, bound=100) --search lazy_wastar([eval1, eval2], w=2, bound=100) is equivalent to --search lazy(alt([single(sum([g(), weight(eval1, 2)])), single(sum([g(), weight(eval2, 2)]))], boost=1000), reopen_closed=true, bound=100) --search lazy_wastar([eval1, eval2], bound=100, boost=0) is equivalent to --search lazy(alt([single(sum([g(), eval1])), single(sum([g(), eval2]))]) reopen_closed=true, bound=100) --search lazy_wastar(eval1, w=2) is equivalent to --search lazy(single(sum([g(), weight(eval1, 2)])), reopen_closed=true) Successor ordering: When using randomize_successors=true and preferred_successors_first=true, randomization happens before preferred operators are moved to the front.","title":"Equivalent statements using general lazy search"},{"location":"ShrinkStrategy/","text":"This page describes the various shrink strategies supported by the planner. Bismulation based shrink strategy # This shrink strategy implements the algorithm described in the paper: Raz Nissim, Joerg Hoffmann and Malte Helmert. Computing Perfect Heuristics in Polynomial Time: On Bisimulation and Merge-and-Shrink Abstractions in Optimal Planning. . In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence (IJCAI 2011) , pp. 1983-1990. AAAI Press, 2011. shrink_bisimulation(greedy=false, at_limit=RETURN) greedy (bool): use greedy bisimulation at_limit ({RETURN, USE_UP}): what to do when the size limit is hit shrink_bisimulation(greedy=true): Combine this with the merge-and-shrink options max_states=infinity and threshold_before_merge=1 and with the linear merge strategy reverse_level to obtain the variant 'greedy bisimulation without size limit', called M&S-gop in the IJCAI 2011 paper. When we last ran experiments on interaction of shrink strategies with label reduction, this strategy performed best when used with label reduction before shrinking (and no label reduction before merging). shrink_bisimulation(greedy=false): Combine this with the merge-and-shrink option max_states=N (where N is a numerical parameter for which sensible values include 1000, 10000, 50000, 100000 and 200000) and with the linear merge strategy reverse_level to obtain the variant 'exact bisimulation with a size limit', called DFP-bop in the IJCAI 2011 paper. When we last ran experiments on interaction of shrink strategies with label reduction, this strategy performed best when used with label reduction before shrinking (and no label reduction before merging). f-preserving shrink strategy # This shrink strategy implements the algorithm described in the paper: Malte Helmert, Patrik Haslum and Joerg Hoffmann. Flexible Abstraction Heuristics for Optimal Sequential Planning . In Proceedings of the Seventeenth International Conference on Automated Planning and Scheduling (ICAPS 2007) , pp. 176-183. AAAI Press, 2007. shrink_fh(random_seed=-1, shrink_f=HIGH, shrink_h=LOW) random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. shrink_f ({HIGH, LOW}): prefer shrinking states with high or low f values shrink_h ({HIGH, LOW}): prefer shrinking states with high or low h values shrink_fh(): Combine this with the merge-and-shrink option max_states=N (where N is a numerical parameter for which sensible values include 1000, 10000, 50000, 100000 and 200000) and the linear merge startegy cg_goal_level to obtain the variant 'f-preserving shrinking of transition systems', called called HHH in the IJCAI 2011 paper, see bisimulation based shrink strategy. When we last ran experiments on interaction of shrink strategies with label reduction, this strategy performed best when used with label reduction before merging (and no label reduction before shrinking). We also recommend using full pruning with this shrink strategy, because both distances from the initial state and to the goal states must be computed anyway, and because the existence of only one dead state causes this shrink strategy to always use the map-based approach for partitioning states rather than the more efficient vector-based approach. Random # shrink_random(random_seed=-1) random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"ShrinkStrategy"},{"location":"ShrinkStrategy/#bismulation_based_shrink_strategy","text":"This shrink strategy implements the algorithm described in the paper: Raz Nissim, Joerg Hoffmann and Malte Helmert. Computing Perfect Heuristics in Polynomial Time: On Bisimulation and Merge-and-Shrink Abstractions in Optimal Planning. . In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence (IJCAI 2011) , pp. 1983-1990. AAAI Press, 2011. shrink_bisimulation(greedy=false, at_limit=RETURN) greedy (bool): use greedy bisimulation at_limit ({RETURN, USE_UP}): what to do when the size limit is hit shrink_bisimulation(greedy=true): Combine this with the merge-and-shrink options max_states=infinity and threshold_before_merge=1 and with the linear merge strategy reverse_level to obtain the variant 'greedy bisimulation without size limit', called M&S-gop in the IJCAI 2011 paper. When we last ran experiments on interaction of shrink strategies with label reduction, this strategy performed best when used with label reduction before shrinking (and no label reduction before merging). shrink_bisimulation(greedy=false): Combine this with the merge-and-shrink option max_states=N (where N is a numerical parameter for which sensible values include 1000, 10000, 50000, 100000 and 200000) and with the linear merge strategy reverse_level to obtain the variant 'exact bisimulation with a size limit', called DFP-bop in the IJCAI 2011 paper. When we last ran experiments on interaction of shrink strategies with label reduction, this strategy performed best when used with label reduction before shrinking (and no label reduction before merging).","title":"Bismulation based shrink strategy"},{"location":"ShrinkStrategy/#f-preserving_shrink_strategy","text":"This shrink strategy implements the algorithm described in the paper: Malte Helmert, Patrik Haslum and Joerg Hoffmann. Flexible Abstraction Heuristics for Optimal Sequential Planning . In Proceedings of the Seventeenth International Conference on Automated Planning and Scheduling (ICAPS 2007) , pp. 176-183. AAAI Press, 2007. shrink_fh(random_seed=-1, shrink_f=HIGH, shrink_h=LOW) random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. shrink_f ({HIGH, LOW}): prefer shrinking states with high or low f values shrink_h ({HIGH, LOW}): prefer shrinking states with high or low h values shrink_fh(): Combine this with the merge-and-shrink option max_states=N (where N is a numerical parameter for which sensible values include 1000, 10000, 50000, 100000 and 200000) and the linear merge startegy cg_goal_level to obtain the variant 'f-preserving shrinking of transition systems', called called HHH in the IJCAI 2011 paper, see bisimulation based shrink strategy. When we last ran experiments on interaction of shrink strategies with label reduction, this strategy performed best when used with label reduction before merging (and no label reduction before shrinking). We also recommend using full pruning with this shrink strategy, because both distances from the initial state and to the goal states must be computed anyway, and because the existence of only one dead state causes this shrink strategy to always use the map-based approach for partitioning states rather than the more efficient vector-based approach.","title":"f-preserving shrink strategy"},{"location":"ShrinkStrategy/#random","text":"shrink_random(random_seed=-1) random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"Random"},{"location":"SubtaskGenerator/","text":"Subtask generator (used by the CEGAR heuristic). goals # goals(order=HADD_DOWN, random_seed=-1) order ({ORIGINAL, RANDOM, HADD_UP, HADD_DOWN}): ordering of goal or landmark facts random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. landmarks # landmarks(order=HADD_DOWN, random_seed=-1, combine_facts=true) order ({ORIGINAL, RANDOM, HADD_UP, HADD_DOWN}): ordering of goal or landmark facts random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. combine_facts (bool): combine landmark facts with domain abstraction original # original(copies=1) copies (int [1, infinity]): number of task copies","title":"SubtaskGenerator"},{"location":"SubtaskGenerator/#goals","text":"goals(order=HADD_DOWN, random_seed=-1) order ({ORIGINAL, RANDOM, HADD_UP, HADD_DOWN}): ordering of goal or landmark facts random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.","title":"goals"},{"location":"SubtaskGenerator/#landmarks","text":"landmarks(order=HADD_DOWN, random_seed=-1, combine_facts=true) order ({ORIGINAL, RANDOM, HADD_UP, HADD_DOWN}): ordering of goal or landmark facts random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed. combine_facts (bool): combine landmark facts with domain abstraction","title":"landmarks"},{"location":"SubtaskGenerator/#original","text":"original(copies=1) copies (int [1, infinity]): number of task copies","title":"original"}]}