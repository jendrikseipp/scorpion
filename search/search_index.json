{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Scorpion Documentation","text":"<p>This website contains the documentation for the Scorpion planner. Since Scorpion is based on Fast Downward, the documentation is mostly the same as the Fast Downward documentation.</p> <ul> <li>The README shows how to run Scorpion and lists the differences to Fast Downward.</li> <li>Planner usage explains ways of invoking the      planner. For setting up the planner see Getting started.</li> <li>Search plugins documents the different ingredients for the      search configuration, such as search algorithms and heuristics.</li> <li>Syntax for search plugins defines the syntax for configuring the search      plugins.</li> <li>Exit Codes describes the exit codes as returned by the      planner.</li> <li>PDDL support specifies the subset of PDDL that is      supported by the planner.</li> <li>Translator output format documents the      internal file format that is generated by the translator component and      used as input by the search component.</li> </ul>"},{"location":"BUILD/","title":"Build instructions","text":""},{"location":"BUILD/#dependencies","title":"Dependencies","text":""},{"location":"BUILD/#mandatory_dependencies","title":"Mandatory Dependencies","text":"<p>Linux/MacOS: you need a C++ compiler, CMake and GNU make.   To run the planner, you also need Python 3.</p> <p>On Debian/Ubuntu, the following should install all these dependencies:   <pre><code>sudo apt install cmake g++ make python3\n</code></pre></p> <p>Windows: install Visual Studio &gt;= 2017, Python, and CMake. During the installation of Visual Studio, the C++ compiler is not installed by default, but the IDE prompts you to install it when you create a new C++ project.</p>"},{"location":"BUILD/#optional_linear-programming_solvers","title":"Optional: Linear-Programming Solvers","text":"<p>Some planner configurations depend on an LP or MIP solver. We support CPLEX (commercial, free academic license) and SoPlex (Apache License, no MIP support). You can install one or both solvers without causing conflicts.</p> <p>Once LP solvers are installed and the environment variables <code>cplex_DIR</code> and/or <code>soplex_DIR</code> are set up correctly, Fast Downward automatically includes each solver detected on the system in the build.</p>"},{"location":"BUILD/#installing_cplex","title":"Installing CPLEX","text":"<p>Obtain CPLEX and follow the guided installation. See troubleshooting if you have problems accessing the installer. On Windows, install CPLEX into a directory without spaces.</p> <p>After the installation, set the environment variable <code>cplex_DIR</code> to the subdirectory <code>/cplex</code> of the installation. For example on Ubuntu: <pre><code>export cplex_DIR=/opt/ibm/ILOG/CPLEX_Studio2211/cplex\n</code></pre> Note that on Windows, setting up the environment variable might require using <code>/</code> instead of the more Windows-common <code>\\</code>.</p>"},{"location":"BUILD/#installing_soplex_on_linuxmacos","title":"Installing SoPlex on Linux/macOS","text":"<p>Important:  The GNU Multiple Precision library (GMP) is critical for the performance of SoPlex but the build does not complain if it is not present. Make sure that the build uses the library (check the output of CMake for <code>Found GMP</code>).</p> <p>We require at least SoPlex 7.1.0, which can be built from source as follows (adapt the paths if you install a different version or want to use a different location): <pre><code>sudo apt install libgmp3-dev\nwget https://github.com/scipopt/soplex/archive/refs/tags/release-710.tar.gz -O - | tar -xz\ncmake -S soplex-release-710 -B build\ncmake --build build\nexport soplex_DIR=/opt/soplex-7.1.0\ncmake --install build --prefix $soplex_DIR\nrm -rf soplex-release-710 build\n</code></pre></p> <p>After installation, permanently set the environment variable <code>soplex_DIR</code> to the value you used during the installation.</p>"},{"location":"BUILD/#optional_plan_validator","title":"Optional: Plan Validator","text":"<p>You can validate the found plans by passing <code>--validate</code> (implied by <code>--debug</code>) to the planner if the VAL plan validation software is installed on your system and the binary <code>validate</code> is on the <code>PATH</code>.</p> <p>Note: VAL has a bug that prevents it from correctly handling the IPC 18 data network domain. You can install an older version, e.g., under Debian/Ubuntu:</p> <pre><code>sudo apt install g++ make flex bison\ngit clone https://github.com/KCL-Planning/VAL.git\ncd VAL\ngit checkout a5565396007eee73ac36527fbf904142b3077c74\nmake clean  # Remove old binaries.\nsed -i 's/-Werror //g' Makefile  # Ignore warnings.\nmake\n</code></pre> <p>Don't forget to add the resulting <code>validate</code> binary to your <code>PATH</code>.</p>"},{"location":"BUILD/#compiling_the_planner","title":"Compiling the planner","text":"<p>To build the planner, from the top-level directory run:</p> <pre><code>./build.py\n</code></pre> <p>This creates the default build <code>release</code> in the directory <code>builds</code>. For information on alternative builds (e.g. <code>debug</code>) and further options, call <code>./build.py --help</code>. Our website has details on how to set up development builds.</p>"},{"location":"BUILD/#compiling_on_windows","title":"Compiling on Windows","text":"<p>Windows does not interpret the shebang in Python files, so you have to call <code>build.py</code> as <code>python3 build.py</code> (make sure <code>python3</code> is on your <code>PATH</code>). Also note that options are passed without <code>--</code>, e.g., <code>python3 build.py build=debug</code>.</p> <p>Note that compiling from the terminal is only possible with the right environment. The easiest way to get such an environment is to use the <code>Developer PowerShell for VS 2019</code> or <code>Developer PowerShell</code>.</p> <p>Alternatively, you can create a Visual Studio Project, open it in Visual Studio and build from there. Visual Studio creates its binary files in subdirectories of the project that our driver script currently does not recognize. If you build with Visual Studio, you have to run the individual components of the planner yourself.</p>"},{"location":"BUILD/#testing_the_build","title":"Testing the build","text":"<p>To test your build use:</p> <pre><code>./fast-downward.py misc/tests/benchmarks/miconic/s1-0.pddl --search \"astar(lmcut())\"\n</code></pre> <p>To test the LP support use: <pre><code>./fast-downward.py misc/tests/benchmarks/miconic/s1-0.pddl --search \"astar(operatorcounting([lmcut_constraints()]))\"\n</code></pre></p>"},{"location":"BUILD/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>If you changed the build environment, delete the <code>builds</code> directory and rebuild.</li> <li>Windows: If you cannot execute the Fast Downward binary in a new command line, then it might be unable to find a dynamically linked library.   Use <code>dumpbin /dependents PATH\\TO\\DOWNWARD\\BINARY</code> to list all required libraries and ensure that they can be found in your <code>PATH</code> variable.</li> <li>CPLEX: After logging in at the IBM website, you find the Ilog studio software under Technology -&gt; Data Science. Choose the right version and switch to HTTP download unless you have the IBM download manager installed. If you have problems using their website with Firefox, try Chrome instead. Execute the downloaded binary and follow the guided installation.</li> <li>CPLEX: If you get warnings about unresolved references with CPLEX, visit their help pages.</li> <li>MacOS: If your compiler doesn't find flex or bison when building VAL, your include directories might be in a non-standard location. In this case you probably have to specify where to look for includes and libraries in VAL's    Makefile (probably <code>/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr</code>).</li> </ul>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<p>This file controls the navigation below \"documentation\" on the website.</p> <ul> <li>README</li> <li>Build instructions</li> <li>Planner usage</li> <li>Search plugins</li> <li>Syntax for search plugins</li> <li>Exit codes</li> <li>PDDL support</li> <li>Translator output format</li> </ul>"},{"location":"exit-codes/","title":"Exit Codes","text":"<p>Fast Downward returns the following positive exit codes, listing the names as used in src/search/utils/system.h and driver/returncodes.py. If it gets killed by a specific signal, it returns the signal as exit code, except for SIGXCPU which we intercept. The exit codes we defined are grouped in four blocks.</p> <p>The first block (0-9) represents successful termination of a component which does not prevent the execution of further components.</p> Code Name Meaning 0 SUCCESS All run components successfully terminated (translator: completed, search: found a plan, validate: validated a plan) 1 SEARCH_PLAN_FOUND_AND_OUT_OF_MEMORY Only returned by portfolios: at least one plan was found and another component ran out of memory. 2 SEARCH_PLAN_FOUND_AND_OUT_OF_TIME Only returned by portfolios: at least one plan was found and another component ran out of time. 3 SEARCH_PLAN_FOUND_AND_OUT_OF_MEMORY_AND_TIME Only returned by portfolios: at least one plan was found, another component ran out of memory, and yet another one ran out of time. <p>The second block (10-19) represents unsuccessful, but error-free termination which prevents the execution of further components.</p> Code Name Meaning 10 TRANSLATE_UNSOLVABLE Translator proved task to be unsolvable. Currently not used 11 SEARCH_UNSOLVABLE Task is provably unsolvable with current bound. Currently only used by hillclimbing search. See also issue377. 12 SEARCH_UNSOLVED_INCOMPLETE Search ended without finding a solution. <p>The third block (20-29) represents expected failures which prevent the execution of further components.</p> Code Name Meaning 20 TRANSLATE_OUT_OF_MEMORY Memory exhausted. 21 TRANSLATE_OUT_OF_TIME Time exhausted. Not supported on Windows because we use SIGXCPU to kill the planner. 22 SEARCH_OUT_OF_MEMORY Memory exhausted. 23 SEARCH_OUT_OF_TIME Timeout occurred. Not supported on Windows because we use SIGXCPU to kill the planner. 24 SEARCH_OUT_OF_MEMORY_AND_TIME Only returned by portfolios: one component ran out of memory and another one out of time. <p>The fourth block (30-39) represents unrecoverable failures which prevent the execution of further components.</p> Code Name Meaning 30 TRANSLATE_CRITICAL_ERROR Critical error: something went wrong (e.g. translator bug, but also malformed PDDL input). 31 TRANSLATE_INPUT_ERROR Usage error: wrong command line options or invalid PDDL inputs 32 SEARCH_CRITICAL_ERROR Something went wrong that should not have gone wrong (e.g. planner bug). 33 SEARCH_INPUT_ERROR Wrong command line options or SAS+ file. 34 SEARCH_UNSUPPORTED Requested unsupported feature. 35 DRIVER_CRITICAL_ERROR Something went wrong in the driver (e.g. failed setting resource limits, ill-defined portfolio, complete plan generated after an incomplete one). 36 DRIVER_INPUT_ERROR Usage error: wrong or missing command line options, including (implicitly) specifying non-existing paths (e.g. for input files or build directory). 37 DRIVER_UNSUPPORTED Requested unsupported feature (e.g.  limiting memory on macOS)."},{"location":"ipc-planners/","title":"IPC planners","text":"<p>This page describes how to run any of the planner configurations based on Fast Downward that participated in IPC 2011 and the two Fast Downward Stone Soup portfolios from IPC 2018.</p>"},{"location":"ipc-planners/#what_is_the_relationship_between_fast_downward_and_the_ipc_2011_planners_based_on_fast_downward","title":"What is the relationship between \"Fast Downward\" and the IPC 2011 planners based on Fast Downward?","text":"<p>All the following planners from IPC 2011 (called \"IPC configurations\" in the following) used exactly the same code, a snapshot from the Fast Downward repository. They only differ in command-line options for the search component of the planner.</p> <ul> <li> <p>satisficing track:</p> </li> <li> <p>Fast Downward Autotune 1, satisficing version (<code>seq-sat-fd-autotune-1</code>)</p> </li> <li>Fast Downward Autotune 2, satisficing version (<code>seq-sat-fd-autotune-2</code>)</li> <li>*Fast Downward Stone Soup 1, satisficing version (<code>seq-sat-fdss-1</code>)</li> <li> <p>*Fast Downward Stone Soup 2, satisficing version (<code>seq-sat-fdss-2</code>)</p> <ul> <li>LAMA 2011 (<code>seq-sat-lama-2011</code>)</li> </ul> </li> <li> <p>optimization track:</p> </li> <li>BJOLP (<code>seq-opt-bjolp</code>)</li> <li>Fast Downward Autotune, optimizing version (<code>seq-opt-fd-autotune</code>)</li> <li>*Fast Downward Stone Soup 1, optimizing version (<code>seq-opt-fdss-1</code>)</li> <li>*Fast Downward Stone Soup 2, optimizing version (<code>seq-opt-fdss-2</code>)</li> <li>LM-Cut (<code>seq-opt-lmcut</code>)</li> <li>*Merge and Shrink (<code>seq-opt-merge-and-shrink</code>)</li> <li>Selective Max (<code>seq-opt-selmax</code>)</li> </ul> <p>The planners marked with a star (*) are portfolio configurations, which are a bit special because they use hard-coded time limits. See below.</p> <p>Note</p> <p>Note on running LAMA: As of 2011, LAMA has been merged back into the Fast Downward codebase. \"LAMA 2011\", the version of LAMA that participated in IPC 2011, is Fast Downward with a particular set of command-line arguments. Since LAMA 2011 greatly outperformed LAMA 2008 in the competition, we strongly encourage you to use the current Fast Downward code when evaluating your planner against LAMA.</p>"},{"location":"ipc-planners/#ipc_2018_fast_downward_stone_soup_planners","title":"IPC 2018 Fast Downward Stone Soup planners","text":"<p>We describe the two portfolios in this planner abstract. The two portfolios use the same configurations but the cost-bounded version stops after finding the first plan that's cheaper than the given cost bound.</p> <ul> <li>satisficing track:         <code>./fast-downward.py --alias seq-sat-fdss-2018 --overall-time-limit 30m ../benchmarks/depot/p01.pddl</code></li> <li>cost-bounded track:         <code>./fast-downward.py --portfolio-single-plan --portfolio-bound=20 --alias seq-sat-fdss-2018 --overall-time-limit 30m ../benchmarks/depot/p01.pddl</code></li> </ul> <p>The portfolios are available in several versions:</p> <ul> <li>The version that was used in IPC 2018: satisficing     track     and cost-bounded     track.     Both repositories contain Singularity files for easier compilation.</li> <li>Released version from the Fast Downward releases</li> <li>Latest revision from Git repository.</li> </ul>"},{"location":"ipc-planners/#how_do_i_run_an_ipc_configuration","title":"How do I run an IPC configuration?","text":"<p>The <code>src/fast-downward.py</code> script provides short aliases for the IPC configurations. To run e.g.  the LAMA-2011 configuration on the first gripper task run</p> <pre><code>./fast-downward.py --alias seq-sat-lama-2011 misc/tests/benchmarks/gripper/prob01.pddl\n</code></pre> <p>and the correct parameter settings will automatically be set. To see all available aliases run</p> <pre><code>./fast-downward.py --show-aliases\n</code></pre> <p>If you are interested in the actual parameter settings, look inside the</p> <pre><code>src/driver/aliases.py\n</code></pre> <p>module.</p>"},{"location":"ipc-planners/#using_time_limits_other_than_30_minutes","title":"Using time limits other than 30 minutes","text":"<p>The portfolio configurations are intimately tied to the competition time limit of 30 minutes. If you use a different time limit, you cannot use these planner configurations out of the box.</p> <p>Please also note that all planner configurations have an internal time limit of 5 minutes for the invariant synthesis part of the translator. This is generous for all but very few planning tasks, but still it makes sense to adapt this value if you're running the overall planner with a different overall timeout from the usual 30 minutes, especially if it is a significantly lower time limit.</p>"},{"location":"ipc-planners/#which_code_version_of_the_ipc_2011_planners_should_i_use","title":"Which code version of the IPC 2011 planners should I use?","text":"<p>The two main options are</p> <ul> <li>the snapshot used at IPC 2011</li> <li>the most current version of the main branch of the repository</li> </ul> <p>We usually recommend using the newest code from the repository since we tend to fix bugs every now and then (but of course, we also introduce new ones...). If you do a proper experiment and performance in some domain looks worse than what you'd expect from our papers or the IPC results, we're very happy to be notified since this may be an indication that we introduced a bug.</p> <p>The tarball linked above is identical to the code that was run at IPC 2011 except that it uses 32-bit mode rather than 64-bit mode. For an explanation of which of these two modes you want and how to set it, please check the planner usage page.</p>"},{"location":"pddl-support/","title":"PDDL support of Fast Downward","text":"<p>On this page, we collect information regarding the subset of PDDL that is supported by Fast Downward. So far, this is not an exhaustive list, but we hope that it will become more comprehensive over time. If you want to contribute information or have a question, please get in touch! (See the contact information on the home page.)</p>"},{"location":"pddl-support/#general_information","title":"General information","text":"<p>Fast Downward aims to support PDDL 2.2 level 1 plus the <code>:action-costs</code> requirement from PDDL 3.1. For a definition of the various \"levels\" of PDDL, see p. 63 the paper \"PDDL2.1: An Extension to PDDL for Expressing Temporal Planning Domains\" by Maria Fox and Derek Long (JAIR 20:61-124, 2003).</p> <p>This means that the following major parts of PDDL are unsupported:</p> <ul> <li>All aspects of numerical planning. These are introduced at level 2     of PDDL. Exception: some numerical features are part of the     <code>:action-costs</code> requirement of PDDL 3.1, and these are supported by the     planner.</li> <li>All aspects of temporal planning. These are introduced at level 3 of     PDDL and above.</li> <li>Soft goals and preferences. These are introduced in PDDL 3.0.</li> <li>Object fluents. These are introduced in PDDL 3.1.</li> </ul> <p>Expressed positively, this means that the following features of PDDL are supported beyond basic STRIPS, with some limitations mentioned below:</p> <ul> <li>all ADL features such as quantified and conditional effects and     negation, disjunction and quantification in conditions</li> <li>axioms and derived predicates (introduced in PDDL 2.2)</li> <li>action costs (introduced in PDDL 3.1)</li> </ul>"},{"location":"pddl-support/#limitations","title":"Limitations","text":"<ul> <li>PDDL types: <code>(either ...)</code> types are not supported</li> <li>conditional effects: Not all heuristics support conditional     effects. See Evaluator for details.</li> <li>axioms: Not all heuristics support axioms. See     Evaluator for details.</li> <li>universal conditions: Universal conditions in preconditions,     effect conditions and the goal are internally compiled into axioms     by the planner. Therefore, heuristics that do not support axioms     (see previous point) do not support universal conditions either.</li> <li>action costs: Action costs must be non-negative integers (i.e.,     not fractional), and each action may contain at most one effect     affecting <code>(total-cost)</code>, which may not be part of conditional effects.     These are the same restrictions that were in use for IPC 2008 and IPC 2011.</li> </ul> <p>These limitations are somewhat likely to be lifted in the future, but progress is slow.</p>"},{"location":"pddl-support/#bugs","title":"Bugs","text":"<p>Some features are supported in theory, but currently affected by bugs. In addition to the issues with conditional effects mentioned above which are somewhere between a bug and a missing feature, we are currently aware of the following bugs:</p> <ul> <li>http://issues.fast-downward.org/issue215: incorrect atoms     (undeclared predicate, wrong arity, unknown object) and assignments     (undeclared functions, wrong arity, referring to unknown objects, or     unsupported value) may cause errors that are not correctly reported.</li> </ul> <p>The above list might be outdated by the time you are reading this. Follow the links to the issue tracker to be sure. If the list is not up to date, it would be great if you could send us a note so that we can remedy this. (See contact information on the home page.)</p>"},{"location":"planner-usage/","title":"Usage","text":"<p>Fast Downward is a domain-independent classical planning system that consists of two main components:</p> <ul> <li>a translation phase translates a PDDL input task into a SAS+ tasks. </li> <li>a search phase perfoms a search on a SAS+ task to find a plan.</li> </ul> <p>To run Fast Downward, use the <code>fast-downward.py</code> driver script. We will here give a short introduction into the basic usage of the main components. </p> <p>Note that the driver script has many additional options to do things like running portfolios, using a non-standard build and various other things. To see the complete list of options, run</p> <pre><code>./fast-downward.py --help\n</code></pre> <p>If you want to run any of the planners based on Fast Downward that participated in IPC 2011, please also check the page on IPC planners.</p>"},{"location":"planner-usage/#translation_component","title":"Translation component","text":"<p>To translate a PDDL input task into a SAS+ task without performing a search run the following:</p> <pre><code>./fast-downward.py --translate [&lt;domain.pddl&gt;] &lt;task.pddl&gt;\n</code></pre> <p>Note:</p> <ul> <li>Giving the domain file as input is optional.      In case no domain file is specified, the component will search for a file called <code>domain.pddl</code> located in the same directory as the task file. </li> <li>Translator component options can be specified after the input files following the <code>--translator-options</code> flag.</li> </ul>"},{"location":"planner-usage/#search_component","title":"Search component","text":"<p>To run a search on a PDDL input task run the following:</p> <pre><code>./fast-downward.py [&lt;domain.pddl&gt;] &lt;task.pddl&gt; \\\n--search \"&lt;some-search-algorithm&gt;(&lt;algorithm-parameters&gt;)\"\n</code></pre> <p>Note:</p> <ul> <li>The PDDL task is translated into a SAS+ task internally without the need to explicitly call the <code>translate</code> component.     Instead of a PDDL task a SAS+ translator output file could be given as input. In this case the translation step is omitted.</li> <li>Giving the domain file as input is optional.      In case no domain file is specified, the component will search for a file called <code>domain.pddl</code> located in the same directory as the task file. </li> <li><code>&lt;some-search-algorithm&gt;</code> can be any of the search algorithms with corresponding <code>&lt;algorithm-parameters&gt;</code> as input.</li> <li>Search component options can be specified anywhere after the input files.      Search component options following translator component options need to first be escaped with the <code>--search-options</code> flag.</li> </ul>"},{"location":"planner-usage/#example","title":"Example","text":"<p>The following example is a recommended search algorithm configuration: A* algorithm with the LM-cut heuristic, which can be run as follows:</p> <pre><code>./fast-downward.py [&lt;domain.pddl&gt;] &lt;task.pddl&gt; --search \"astar(lmcut())\"\n</code></pre> <p>As this is a common search configuration an alias (<code>seq-opt-lmcut</code>) exists that results in the same execution and can be used as follows:</p> <pre><code>./fast-downward.py --alias seq-opt-lmcut [&lt;domain.pddl&gt;] &lt;task.pddl&gt;\n</code></pre>"},{"location":"planner-usage/#aliases","title":"Aliases","text":"<p>Many other common search configurations are also specified as aliases. To see the full list of aliases call:</p> <pre><code>./fast-downward.py --show-aliases\n</code></pre> <p>To find out which actual search options the aliases corresponds to, check the source code of the <code>src/driver/aliases.py</code> module.</p> <p>For example to run the \"LAMA 2011 configuration\" of the planner, call:</p> <pre><code>./fast-downward.py --alias seq-sat-lama-2011 [&lt;domain.pddl&gt;] &lt;task.pddl&gt;\n</code></pre> <p>Note:</p> <ul> <li>This is not really the same as \"LAMA 2011\" as it participated at IPC 2011     because there have been bug fixes and other changes to the planner since 2011.     See \"IPC planners\" for more information. </li> </ul>"},{"location":"planner-usage/#caveats","title":"Caveats","text":"<p>The search options are built with flexibility in mind, not ease of use. It is very easy to use option settings that look plausible, yet introduce significant inefficiencies. For example, an invocation like</p> <pre><code>./fast-downward.py [&lt;domain.pddl&gt;] &lt;task.pddl&gt; \\\n--search \"lazy_greedy([ff()], preferred=[ff()])\"\n</code></pre> <p>looks plausible, yet is hugely inefficient since it will compute the FF heuristic twice per state. To circumvent this a <code>let</code>-expression could be used:</p> <pre><code>./fast-downward.py [&lt;domain.pddl&gt;] &lt;task.pddl&gt; \\\n--search \"let(hff, ff(), lazy_greedy([hff], preferred=[hff]))\"\n</code></pre>"},{"location":"planner-usage/#validating_plans","title":"Validating plans","text":"<p>To validate a plan found by some search algorithm using VAL run the following:</p> <pre><code>./fast-downward.py --validate [&lt;domain.pddl&gt;] &lt;task.pddl&gt; \\\n--search \"&lt;some-search-algorithm&gt;(&lt;algorithm-parameters&gt;)\"\n</code></pre> <p>Note:</p> <ul> <li>VAL must be available locally and added to the PATH (see Plan Validator).</li> <li>The search algorithm must be specified (see Search component).</li> </ul>"},{"location":"planner-usage/#exit_codes","title":"Exit codes","text":"<p>The driver exits with 0 if no errors are encountered. Otherwise, it returns the exit code of the first component that failed (cf. documentation of exit codes).</p>"},{"location":"planner-usage/#different_builds","title":"Different builds","text":"<p>Different builds of Fast Downward (e.g. release vs. debug) are placed in different directories by the build script. Hence, several builds can coexist and <code>fast-downward.py</code> must be told which build to use. By default, the <code>release</code> build is used, which is also the default build produced by <code>build.py</code>.  To use a different build, pass <code>--build=&lt;name&gt;</code> to the driver script. The parameter <code>--debug</code> is an alias for <code>--build=debug --validate</code>.</p> <p>Note on IDE projects (Visual Studio, XCode): You can use the CMake build system to generate a project for you favourite IDE. These projects are what CMake calls \"multi-config generators\", i.e., they are created without fixing the build configuration. At build time, the IDE decides whether to do a debug or release build and creates subdirectories in the output folder. Use the full path to the binaries as the value of <code>--build</code> (e.g., <code>--build=path/to/visual/studio/project/bin/Debug/</code>).</p>"},{"location":"planner-usage/#lp_support","title":"LP support","text":"<p>Features that use an LP solver have a command-line option <code>lpsolver</code> to switch between different solver types. See issue752 and issue1076 for a discussion of the relative performance of CPLEX and SoPlex.</p> <p>Note that SoPlex is not a MIP solver, so using it for configurations that require integer variables will result in an error. Please use CPLEX for such cases.</p>"},{"location":"quick-start/","title":"Quick start","text":"<p>This page provides you with different options for setting up Fast Downward on your machine. </p> <p>Fast Downward is released in four flavours: Tarball, Apptainer (formerly known as Singularity), Docker and Vagrant. Here we provide instructions to get you started as quickly as possible. You can find more usage information at planner usage.</p>"},{"location":"quick-start/#what_flavour_is_for_me","title":"What flavour is for me?","text":"<ul> <li>running experiments: We recommend Apptainer or the tarball.     Docker is an alternative, but be mindful of its significant     overhead.</li> <li>teaching: We recommend Vagrant.</li> <li>development: We recommend working on a clone of the master     repository.</li> </ul> <p>See what-flavour-is-for-me for a more detailed discussion.</p>"},{"location":"quick-start/#apptainer","title":"Apptainer","text":""},{"location":"quick-start/#apptainer_installation","title":"Apptainer Installation","text":"<p>To run the Apptainer image, first install one of the Apptainer releases or follow the steps provided on the Apptainer page. We tested with versions 1.2.2 and 1.4.1.</p> <p>To download the Fast Downward image, run:</p> <pre><code>apptainer pull fast-downward.sif docker://aibasel/downward:latest\n</code></pre>"},{"location":"quick-start/#apptainer_usage","title":"Apptainer Usage","text":"<p>You can run the planner as follows:</p> <pre><code>./fast-downward.sif &lt;your-planner-options&gt;\n</code></pre> <p>Assume you want to solve a planning task (e.g. from the Fast Downward benchmarks) using A* search with the LM-cut heuristic. To do so you can run the following:</p> <pre><code>./fast-downward.sif &lt;domain.pddl&gt; &lt;task.pddl&gt; --search \"astar(lmcut())\"\n</code></pre> <p>See more planner options at planner usage.</p>"},{"location":"quick-start/#docker","title":"Docker","text":""},{"location":"quick-start/#docker_installation","title":"Docker Installation","text":"<p>To install Docker on your machine follow the steps provided on the Docker page.</p>"},{"location":"quick-start/#docker_usage","title":"Docker Usage","text":"<p>You can run the planner as follows:</p> <pre><code>sudo docker run aibasel/downward &lt;your-planner-options&gt;\n</code></pre> <p>Note:</p> <ul> <li>The use of <code>sudo</code> (Docker usually requires root privileges).</li> <li>The Docker image for Fast Downward is installed on your machine as a side-effect of the command.</li> <li>You can use the Docker flag <code>-rm</code> for cleaning up the container (recommended)</li> </ul> <p>Assume you want to solve a planning task (e.g. from the Fast Downward benchmarks) using A* search with the LM-cut heuristic. To do so you can run the following:</p> <pre><code>sudo docker run --rm -v &lt;path-to-benchmarks&gt;:/benchmarks aibasel/downward \\\n/benchmarks/&lt;domain.pddl&gt; /benchmarks/&lt;task.pddl&gt; \\\n--search \"astar(lmcut())\"\n</code></pre> <p>Here <code>&lt;path-to-benchmarks&gt;</code> refers to your local directory containing your domain and task file.</p> <p>Note:</p> <ul> <li>The Docker flag <code>-v</code> mounts the local directory <code>&lt;path-to-benchmarks&gt;</code> of your host      machine under the container directory <code>/benchmarks</code>, which is the     place where the containerised planner looks for the problem.</li> <li><code>&lt;path-to-benchmarks&gt;</code> must be an absolute path; relative paths are only supported as of Docker Engine version 23.</li> </ul> <p>See more planner options at planner usage.</p>"},{"location":"quick-start/#vagrant","title":"Vagrant","text":""},{"location":"quick-start/#vagrant_installation","title":"Vagrant Installation","text":"<p>To install Vagrant on your machine follow the steps provided on the Vagrant page. For Vagrant to work you also need a \"provider\" such as VirtualBox, VMware, Hyper-V.</p> <p>Note:</p> <ul> <li>Not all provider versions and Vagrant versions are compatible!</li> <li>We recommend using Vagrant 2.4.1 and VirtualBox 7.0.20.</li> </ul> <p>To create your virtual machine using Vagrant create a new directory <code>&lt;my-fast-downward-vm&gt;</code> containing only the Fast Downward Vagrantfile for the desired release. </p> <p>If you want to use LP solvers follow the steps under LP Solvers.</p> <p>Otherwise, you can set up your virtual machine directly from the <code>&lt;my-fast-downward-vm&gt;</code> directory using:</p> <pre><code>vagrant up\n</code></pre>"},{"location":"quick-start/#lp_solvers","title":"LP solvers","text":"<p>The SoPlex LP solver is included automatically. If you want to also use the CPLEX LP solver within the planner, its installer file must be present in the directory <code>&lt;path-to-lp-installers&gt;</code>. As of Fast Downward 23.06, you will need CPLEX 22.1.1 (installer filename <code>cplex_studio2211.linux-x86-64.bin</code>). </p> <p>To set up your virtual machine from the <code>&lt;my-fast-downward-vm&gt;</code> directory as follows:</p> <pre><code>export DOWNWARD_LP_INSTALLERS=&lt;path-to-lp-installers&gt;\n\nvagrant up\n</code></pre> <p>You can now safely delete the LP installers and unset the environment variable.</p>"},{"location":"quick-start/#vagrant_usage","title":"Vagrant Usage","text":"<p>You can run the planner from within the vagrant VM as follows:</p> <pre><code>downward/fast-downward.py &lt;your-planner-options&gt;\n</code></pre> <p>Assume you want to solve a planning task (e.g. from the Fast Downward benchmarks) using A* search with the LM-cut heuristic. To do so you can run the following:</p> <pre><code># From the &lt;my-fast-downward-vm&gt; directory \n\n# Upload the benchmarks to the benchmarks directory on your vagrant machine\nvagrant upload &lt;path-to-benchmarks&gt; benchmarks/\n\n# Log into the VM.\nvagrant ssh\n\n# Run the planner.\ndownward/fast-downward.py \\\n/vagrant/benchmarks/&lt;domain.pddl&gt; /vagrant/benchmarks/&lt;task.pddl&gt; \\\n--search \"astar(lmcut())\"\n\n# Log out from the VM.\nlogout\n\n# Shut down the machine\nvagrant halt\n</code></pre> <p>Here <code>&lt;path-to-benchmarks&gt;</code> refers to your local directory containing your domain and task file.</p> <p>See more planner options at planner usage.</p>"},{"location":"quick-start/#source_code","title":"Source Code","text":""},{"location":"quick-start/#source_code_installation","title":"Source Code Installation","text":"<p>We recommend using the latest release, especially for scientific experiments. See the build instructions for a complete description on how to build the planner from source.</p>"},{"location":"quick-start/#tarball","title":"Tarball","text":"<p>Download the tarball from the latest release. E.g. to build Fast Downward 24.06.01 download the tarball from the Fast Downward 24.06 release page and run the following: </p> <pre><code>tar -xvzf fast-downward-24.06.1.tar.gz\ncd fast-downward-24.06.1\n./build.py\n</code></pre>"},{"location":"quick-start/#repository","title":"Repository","text":"<p>Alternatively, you can fork/clone the repository. If you are using the main branch, be aware that things can break or degrade with every commit.</p>"},{"location":"quick-start/#source_code_usage","title":"Source Code Usage","text":"<p>You can run the planner as follows:</p> <pre><code>./fast-downward.py &lt;your-planner-options&gt;\n</code></pre> <p>Assume you want to solve a planning task (e.g. from the Fast Downward benchmarks) using A* search with the LM-cut heuristic. To do so you can run the following:</p> <pre><code>./fast-downward.py &lt;domain.pddl&gt; &lt;task.pddl&gt; --search \"astar(lmcut())\"\n</code></pre> <p>See more planner options at planner usage.</p>"},{"location":"quick-start/#next_steps","title":"Next steps","text":"<ul> <li>See other ways of invoking the planner on     planner usage.</li> <li>Read about recommended experiment     setups.</li> </ul>"},{"location":"readme/","title":"Scorpion","text":"<p>Scorpion is a classical planning system that extends Fast Downward. The main extensions are:</p> <ul> <li>novel state-of-the-art algorithms for optimal classical planning</li> <li>additional search algorithms</li> <li>several new plugin options and utilities</li> </ul> <p>See below for a detailed list of extensions. We regularly port the latest changes from Fast Downward to Scorpion and also integrate some features from Scorpion back into Fast Downward.</p> <p>Citing Scorpion: Jendrik Seipp, Thomas Keller and Malte Helmert. Saturated Cost Partitioning for Optimal Classical Planning. Journal of Artificial Intelligence Research 67, pp. 129-167. 2020.</p>"},{"location":"readme/#instructions","title":"Instructions","text":""},{"location":"readme/#apptainer_image","title":"Apptainer image","text":"<p>To simplify the installation process, we provide an executable Apptainer container (formerly known as Singularity). It accepts the same arguments as the <code>fast-downward.py</code> script (see below).</p> <pre><code># Download the image,\napptainer pull scorpion.sif oras://ghcr.io/jendrikseipp/scorpion:latest\n\n# or build it yourself.\napptainer build scorpion.sif Apptainer\n\n# Then run the recommended configuration (for solving STRIPS tasks optimally).\n./scorpion.sif --preprocess --alias scorpion [DOMAIN_FILE] PROBLEM_FILE\n</code></pre>"},{"location":"readme/#manual_compilation","title":"Manual compilation","text":"<p>Install the dependencies (the table below lists which versions are tested):</p> <pre><code>sudo apt install cmake g++ git make python3\n</code></pre> <p>For plugins based on linear programming (e.g., <code>ocp()</code>, <code>pho()</code>) you need to add an LP solver. Then compile the planner with</p> <pre><code>./build.py\n</code></pre> <p>and see the available options with</p> <pre><code>./fast-downward.py --help  # driver\n./fast-downward.py --search -- --help  # search component\n</code></pre> <p>For more details (including build instructions for macOS and Windows), see the documentation about compiling the planner. The plugin documentation shows which plugins are available (heuristics, search algorithms, etc.) and how to use them.</p>"},{"location":"readme/#recommended_configurations","title":"Recommended configurations","text":"<p>In case you want to solve tasks quickly and do not require optimality, we recommend using NOLAN:</p> <pre><code>./fast-downward.py --preprocess --alias nolan [DOMAIN_FILE] PROBLEM_FILE\n</code></pre> <p>which is equivalent to</p> <pre><code>./fast-downward.py --preprocess [DOMAIN_FILE] PROBLEM_FILE \\\n  --evaluator \"hlm=landmark_sum(lm_factory=lm_reasonable_orders_hps(lm_rhw()), transform=adapt_costs(one), pref=false)\" \\\n  --evaluator \"hff=ff(transform=adapt_costs(one))\" \\\n  --search \"lazy(alt([single(hff), single(hff, pref_only=true), single(hlm, pref_only=true),\n    tiebreaking([novelty(width=2, evals=[hlm]), hlm, g()])], boost=1000),\n    preferred=[hff, hlm], cost_type=one, reopen_closed=false)\"\n</code></pre> <p>For solving STRIPS tasks optimally, we recommend using the <code>--alias scorpion</code> shortcut</p> <pre><code>./fast-downward.py --preprocess --alias scorpion [DOMAIN_FILE] PROBLEM_FILE\n</code></pre> <p>which is equivalent to</p> <pre><code>./fast-downward.py --preprocess [DOMAIN_FILE] PROBLEM_FILE \\\n  --search \"astar(scp_online([\n      projections(sys_scp(max_time=100, max_time_per_restart=10)),\n      cartesian()],\n      saturator=perimstar, max_time=1000, interval=10K, orders=greedy_orders()),\n      pruning=limited_pruning(pruning=atom_centric_stubborn_sets(), min_required_pruning_ratio=0.2))\"\n</code></pre> <p>The <code>--preprocess</code> parameter uses h\u00b2 to prune irrelevant operators and atoms in a preprocessing step. The search configuration uses partial order reduction and maximizes over diverse, subset-saturated cost partitioning heuristics computed online during the search. The underlying abstractions are Sys-SCP pattern databases and Cartesian abstractions.</p> <p>(In Downward Lab you can use <code>add_algorithm(name=\"scorpion\", repo=\"path/to/repo\", rev=\"scorpion\", component_options=[], driver_options=[\"--preprocess\", \"--alias\", \"scorpion\"]</code> to run the recommended Scorpion configuration.)</p> <p>For solving tasks with conditional effects optimally, we recommend using</p> <pre><code>./fast-downward.py --preprocess [DOMAIN_FILE] PROBLEM_FILE \\\n  --search \"astar(scp_online([projections(sys_scp(\n        max_time=100, max_time_per_restart=10, max_pdb_size=2M, max_collection_size=20M,\n        pattern_type=interesting_non_negative, create_complete_transition_system=true),\n      create_complete_transition_system=true)],\n    saturator=perimstar, max_time=100, max_size=1M, interval=10K, orders=greedy_orders()))\"\n</code></pre>"},{"location":"readme/#ipc_versions","title":"IPC versions","text":"<p>If you prefer to run the Scorpion versions from the IPC 2018 or 2023 (which are based on an older Fast Downward version and use different abstractions), we recommend using the Apptainer images from the Scorpion 2018 or Scorpion 2023 repos.</p>"},{"location":"readme/#differences_between_scorpion_and_fast_downward","title":"Differences between Scorpion and Fast Downward","text":"<p>Diff between the latest merged version of Fast Downward and Scorpion: https://github.com/jendrikseipp/scorpion/compare/main...scorpion</p> <ul> <li>Scorpion comes with the   h\u00b2-preprocessor   by Vidal Alc\u00e1zar and \u00c1lvaro Torralba that prunes irrelevant operators.   Pass <code>--preprocess</code> to use it.</li> <li>Scorpion uses incremental search for Cartesian abstraction   refinement.</li> <li>Scorpion uses a   phmap::flat_hash_set to check   for duplicate states, which often drastically reduces the peak memory usage,   compared to Fast Downward's <code>IntHashSet</code>.</li> <li>If ccache is installed (recommended), Scorpion   uses it to cache compilation files.</li> </ul>"},{"location":"readme/#new_translator_options","title":"New translator options","text":"<ul> <li>Use <code>--dump-predicates</code> and <code>--dump-static-atoms</code> to write files with   information that's useful for learning domain control knowledge.</li> </ul>"},{"location":"readme/#new_plugin_options","title":"New plugin options","text":"<ul> <li> <p><code>{cegar/cartesian}(..., transition_representation={store, compute})</code>:   compute transitions on demand instead of storing them   (paper, default=<code>store</code>).</p> </li> <li> <p><code>{cegar/cartesian}(..., pick_flawed_abstract_state={batch_min_h, ...})</code>:   find all current flaws, then iteratively repair the flaw that's closest to the goal   (paper, default=<code>batch_min_h</code>).</p> </li> <li> <p><code>{cegar/cartesian}(..., pick_split={max_cover, ...}, tiebreak_split={max_refined, ...})</code>:   smarter strategies for splitting a flawed abstract state   (paper, default=<code>max_cover</code>   and <code>max_refined</code> for tiebreaking).</p> </li> <li> <p><code>{cegar,cartesian}(..., dot_graph_verbosity={silent, write_to_console, write_to_file})</code>:   write intermediate abstractions as Graphviz dot files to stdout or to files (default=<code>silent</code>).</p> </li> <li> <p><code>systematic(..., pattern_type=interesting_general)</code>: compute interesting   patterns for general cost partitioning.</p> </li> </ul>"},{"location":"readme/#new_cost_partitioning_algorithms_for_abstraction_heuristics","title":"New cost partitioning algorithms for abstraction heuristics","text":"<p>We use Cartesian abstractions in the example configurations below (<code>[cartesian()]</code>). You can also use pattern database heuristics, e.g., <code>[projections(systematic(2))]</code>, or mix abstractions, e.g., <code>[projections(systematic(3)), cartesian()]</code>. Some of the algorithms below are also part of vanilla Fast Downward, but are only implemented for PDB heuristics.</p> <ul> <li>Optimal cost partitioning:   <code>ocp([cartesian()])</code></li> <li>Canonical heuristic:   <code>canonical_heuristic([cartesian()])</code></li> <li>Uniform cost partitioning:   <code>ucp([cartesian()], opportunistic=false)</code></li> <li>Opportunistic uniform cost partitioning:   <code>ucp([cartesian()], ..., opportunistic=true)</code></li> <li>Greedy zero-one cost partitioning:   <code>gzocp([cartesian()], ...)</code></li> <li>Saturated cost partitioning:   <code>scp([cartesian()], ...)</code> (offline), <code>scp_online([cartesian()], ...)</code> (online)</li> <li>(Saturated) post-hoc optimization:   <code>pho([cartesian()], ..., saturated={false,true})</code> (offline),   <code>operatorcounting([pho_abstraction_constraints([cartesian()], saturated={false,true})])</code> (online)</li> </ul> <p>You can also compute the maximum over abstraction heuristics:</p> <ul> <li><code>maximize([cartesian()])</code></li> </ul> <p>The plugin documentation shows all options for cost partitioning heuristics.</p>"},{"location":"readme/#new_pattern_collection_generators","title":"New pattern collection generators","text":"<ul> <li>Systematic patterns with size limits:   <code>sys_scp(max_pattern_size=X, max_pdb_size=Y, max_collection_size=Z, ..., saturate=false)</code></li> <li>Sys-SCP patterns:   <code>sys_scp(...)</code></li> </ul>"},{"location":"readme/#new_cost_partitioning_algorithms_for_landmark_heuristics","title":"New cost partitioning algorithms for landmark heuristics","text":"<p>Example using A* search and saturated cost partitioning over BJOLP landmarks:</p> <pre><code>--evaluator\n  \"lmc=landmark_cost_partitioning(lm_merged([lm_rhw(), lm_hm(m=1)]),\n  cost_partitioning=saturated, scoring_function=max_heuristic_per_stolen_costs)\"\n--search\n  \"astar(lmc, lazy_evaluator=lmc)\"\n</code></pre> <p>Different cost partitioning algorithms for landmark heuristics:</p> <ul> <li>Optimal cost partitioning (part of vanilla Fast Downward):   <code>landmark_cost_partitioning(..., cost_partitioning=optimal)</code></li> <li>Canonical heuristic:   <code>landmark_cost_partitioning(..., cost_partitioning=canonical)</code></li> <li>Post-hoc optimization:   <code>landmark_cost_partitioning(..., cost_partitioning=pho)</code></li> <li>Saturated post-hoc optimization:   <code>landmark_cost_partitioning(..., cost_partitioning=saturated_pho)</code></li> <li>Uniform cost partitioning:   <code>landmark_cost_partitioning(..., cost_partitioning=uniform)</code></li> <li>Opportunistic uniform cost partitioning (also part of vanilla Fast Downward):   <code>landmark_cost_partitioning(..., cost_partitioning=opportunistic_uniform, scoring_function=min_stolen_costs)</code></li> <li>Greedy zero-one cost partitioning:   <code>landmark_cost_partitioning(..., cost_partitioning=greedy_zero_one, scoring_function=max_heuristic)</code></li> <li>Saturated cost partitioning:   <code>landmark_cost_partitioning(..., cost_partitioning=saturated, scoring_function=max_heuristic_per_stolen_costs)</code></li> </ul>"},{"location":"readme/#new_evaluators","title":"New evaluators","text":"<ul> <li>Novelty evaluator:   <code>novelty(width=2, evals=[hlm])</code></li> </ul>"},{"location":"readme/#new_search_algorithms","title":"New search algorithms","text":"<ul> <li>Breadth-first search (without overhead of the more general <code>eager()</code> search):   <code>brfs()</code></li> <li>Depth-first search:   <code>dfs()</code></li> <li>Exhaustive search (useful for dumping the reachable state space of small input tasks):   <code>dump_reachable_search_space()</code></li> <li>IDA* search:   <code>idastar(cegar(cache_estimates=false))</code></li> <li>Iterative width search:   <code>iw(width=2)</code></li> </ul> <p>Fast Downward is a domain-independent classical planning system.</p> <p>Copyright 2003-2025 Fast Downward contributors (see below).</p> <p>For further information: - Fast Downward website: https://www.fast-downward.org - Report a bug or file an issue: https://issues.fast-downward.org - Fast Downward mailing list: https://groups.google.com/forum/#!forum/fast-downward - Fast Downward main repository: https://github.com/aibasel/downward</p>"},{"location":"readme/#scientific_experiments","title":"Scientific experiments","text":"<p>We recommend to use the latest release instead of the tip of the main branch. The Downward Lab Python package helps running Fast Downward experiments. Our separate benchmark repository contains a collection of planning tasks.</p>"},{"location":"readme/#supported_software_versions","title":"Supported software versions","text":"<p>The planner is mainly developed under Linux; and all of its features should work with no restrictions under this platform. The planner should compile and run correctly on macOS, but we cannot guarantee that it works as well as under Linux. The same comment applies for Windows, where additionally some diagnostic features (e.g., reporting peak memory usage when the planner is terminated by a signal) are not supported. Setting time and memory limits and running portfolios is not supported under Windows either.</p> <p>This version of Fast Downward has been tested with the following software versions:</p> OS Python C++ compiler CMake Ubuntu 24.04 3.10 GCC 14, Clang 18 3.30 Ubuntu 22.04 3.10 GCC 12 3.30 macOS 14 3.10 AppleClang 15 3.30 macOS 13 3.10 AppleClang 15 3.30 Windows 10 3.8 Visual Studio Enterprise 2019 (MSVC 19.29) and 2022 (MSVC 19.41) 3.30 <p>We test LP support with CPLEX 22.1.1 and SoPlex 7.1.1. On Ubuntu we test both CPLEX and SoPlex. On Windows we currently only test CPLEX, and on macOS we do not test LP solvers (yet).</p>"},{"location":"readme/#build_instructions","title":"Build instructions","text":"<p>See BUILD.md.</p>"},{"location":"readme/#contributors","title":"Contributors","text":"<p>The following list includes all people that actively contributed to Fast Downward, i.e., all people that appear in some commits in Fast Downward's history (see below for a history on how Fast Downward emerged) or people that influenced the development of such commits. Currently, this list is sorted by the last year the person has been active, and in case of ties, by the earliest year the person started contributing, and finally by last name.</p> <ul> <li>2003-2025 Malte Helmert</li> <li>2008-2016, 2018-2025 Gabriele Roeger</li> <li>2009, 2025 Christian Muise</li> <li>2010-2025 Jendrik Seipp</li> <li>2010-2011, 2013-2025 Silvan Sievers</li> <li>2012-2025 Florian Pommerening</li> <li>2013, 2015-2025 Salom\u00e9 Eriksson</li> <li>2021-2025 Clemens B\u00fcchner</li> <li>2022-2025 Remo Christen</li> <li>2022-2025 Simon Dold</li> <li>2023-2025 Claudia S. Grundke</li> <li>2024\u20132025 Tanja Schindler</li> <li>2024-2025 David Speck</li> <li>2025 Travis Rivera Petit</li> <li>2018-2024 Patrick Ferber</li> <li>2024 Mart\u00edn Pozo</li> <li>2015, 2021-2023 Thomas Keller</li> <li>2018-2020, 2023 Augusto B. Corr\u00eaa</li> <li>2023 Victor Pal\u00e9ologue</li> <li>2023 Emanuele Tirendi</li> <li>2021-2022 Dominik Drexler</li> <li>2016-2020 Cedric Geissmann</li> <li>2017-2020 Guillem Franc\u00e8s</li> <li>2020 Rik de Graaff</li> <li>2015-2019 Manuel Heusner</li> <li>2017 Daniel Killenberger</li> <li>2016 Yusra Alkhazraji</li> <li>2016 Martin Wehrle</li> <li>2014-2015 Patrick von Reth</li> <li>2009-2014 Erez Karpas</li> <li>2014 Robert P. Goldman</li> <li>2010-2012 Andrew Coles</li> <li>2010, 2012 Patrik Haslum</li> <li>2003-2011 Silvia Richter</li> <li>2009-2011 Emil Keyder</li> <li>2010-2011 Moritz Gronbach</li> <li>2010-2011 Manuela Ortlieb</li> <li>2011 Vidal Alc\u00e1zar Saiz</li> <li>2011 Michael Katz</li> <li>2011 Raz Nissim</li> <li>2010 Moritz Goebelbecker</li> <li>2007-2009 Matthias Westphal</li> </ul>"},{"location":"readme/#history","title":"History","text":"<p>The current version of Fast Downward is the merger of three different projects:</p> <ul> <li>the original version of Fast Downward developed by Malte Helmert   and Silvia Richter</li> <li>LAMA, developed by Silvia Richter and Matthias Westphal based on   the original Fast Downward</li> <li>FD-Tech, a modified version of Fast Downward developed by Erez   Karpas and Michael Katz based on the original code</li> </ul> <p>In addition to these three main sources, the codebase incorporates code and features from numerous branches of the Fast Downward codebase developed for various research papers. The main contributors to these branches are Malte Helmert, Gabi R\u00f6ger and Silvia Richter.</p>"},{"location":"readme/#license","title":"License","text":"<pre><code>Fast Downward is free software: you can redistribute it and/or modify\nit under the terms of the GNU General Public License as published by\nthe Free Software Foundation, either version 3 of the License, or (at\nyour option) any later version.\n\nFast Downward is distributed in the hope that it will be useful, but\nWITHOUT ANY WARRANTY; without even the implied warranty of\nMERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU\nGeneral Public License for more details.\n\nYou should have received a copy of the GNU General Public License\nalong with this program. If not, see &lt;https://www.gnu.org/licenses/&gt;.\n</code></pre>"},{"location":"search-plugin-syntax/","title":"Syntax for Search Plugins","text":"<p>This page explains the syntax for configuring the plugins for the search component of the planner. </p>"},{"location":"search-plugin-syntax/#meaning_of_the_syntax_documentation","title":"Meaning of the syntax documentation","text":"<p>All parameters can be specified by keyword or by position. Once a parameter is specified by keyword, the rest of the parameters must be specified by keyword too. Some parameters have default values and are optional. These parameters are documented in the form <code>keyword = defaultvalue</code>.</p> <p>Consider the following example of a search plugin called <code>name</code>:</p> <pre><code>name(p, qs, r, s=v1, t=Enum1)\n</code></pre> <ul> <li><code>p</code> (type_p): some explanation</li> <li><code>qs</code> (list of type_q): some explanation</li> <li><code>r</code> (type_r): some explanation</li> <li><code>s</code> (type_s): some explanation</li> <li><code>t</code> ({Enum0, Enum1, Enum2}): some explanation<ul> <li>Enum0: some explanation</li> <li>Enum1: some explanation</li> <li>Enum2: some explanation</li> </ul> </li> </ul> <p>Parameters <code>p</code>, <code>qs</code> and <code>r</code> are mandatory. <code>qs</code> is a list parameter. List parameters have to be enclosed in square brackets. For example, let <code>h1</code>, <code>h2</code>, <code>h3</code> be heuristic specifications, then <code>[h1, h3]</code> and <code>[h2]</code> are examples for a list of heuristic specifications.</p> <p>Parameters <code>s</code> and <code>t</code> are optional. <code>s</code> has the default value <code>v1</code> and <code>t</code> the default value <code>Enum1</code>. <code>t</code> is an enumeration parameter and can only take the values listed (here Enum0, Enum1, Enum2).</p> <p>Some possible calls for this specification (with <code>X</code> and <code>Xi</code> having type_x):</p> <ul> <li><code>name(P, [Q], R)</code>: <code>s</code> and <code>t</code> have their default values <code>v1</code> and <code>Enum1</code></li> <li><code>name(P, [Q1, Q2], R, t=Enum2)</code>: <code>s</code> has its default value <code>v1</code></li> <li><code>name(t=Enum1, r=R, qs=[Q1, Q2], s=S1, p=P)</code> is equivalent to     <code>name(P, [Q1, Q2], R, S1, Enum1)</code></li> </ul>"},{"location":"search-plugin-syntax/#note","title":"Note","text":"<ul> <li> <p>Search plugin names, parameter names and enumeration names are not case-sensitive. For example, <code>AsTaR(BlInd(verBosiTy=VeRBosE))</code> is equivalent to <code>astar(blind(verbosity=verbose))</code></p> </li> <li> <p>To get positions and keywords for a search plugin, use</p> </li> </ul> <pre><code>./fast-downward.py --search \"\" --help &lt;name&gt;  // e.g. with &lt;name&gt;=astar\n</code></pre>"},{"location":"search-plugin-syntax/#parameter_types","title":"Parameter Types","text":"<p>In the following we provide information on how parameters of common types have to be specified.</p>"},{"location":"search-plugin-syntax/#booleans","title":"Booleans","text":"<p>Parameters of type <code>bool</code> are specified by strings <code>true</code> or <code>false</code>.</p>"},{"location":"search-plugin-syntax/#integers","title":"Integers","text":"<p>Parameters of type <code>int</code> can be specified as \"infinity\". This means that the parameter will take the value <code>numeric_limits&lt;int&gt;::max()</code>, which is usually equal to 2^31 - 1. If an <code>int</code> parameter value ends with \"K\", \"M\" or \"G\", the value is multiplied by one thousand, one million or one billion, respectively. For example,</p> <pre><code>bound=2K\n</code></pre> <p>is equivalent to </p> <pre><code>bound=2000\n</code></pre>"},{"location":"search-plugin-syntax/#strings","title":"Strings","text":"<p>Parameters of type <code>string</code> can be specified in double quotes. Nested quotes can be escaped as <code>\\\"</code>, backslashes as <code>\\\\</code>, and newlines as <code>\\n</code>. For example,</p> <pre><code>filename=\"C:\\\\some.file\"\n</code></pre>"},{"location":"search-plugin-syntax/#lists","title":"Lists","text":"<p>List arguments have to be enclosed in square brackets now. For example,</p> <pre><code>lazy_greedy([h1, h2], preferred=[])\n</code></pre>"},{"location":"search-plugin-syntax/#enumerations","title":"Enumerations","text":"<p>Enumeration arguments should be specified by name and are not case-sensitive. For example,</p> <pre><code>eager_greedy([h1,h2], cost_type=normal)\n</code></pre> <p>To get enumeration names (and more) for a search plugin parameter, run the help command for the search plugin</p> <pre><code>./fast-downward.py --search \"\" --help &lt;name&gt;  // e.g. with &lt;name&gt;=eager_greedy\n</code></pre>"},{"location":"search-plugin-syntax/#variables_as_parameters","title":"Variables as Parameters","text":"<p>Often an object should be used for several purposes, e.g. a Heuristic or a LandmarkFactory. The most prevalent use case is a heuristic that is used for both the heuristic estimates and for its preferred operators. In this case, one should define a variable for the object. We currently only support variables for Heuristics and LandmarkFactories but will extend the support for other feature types in the future.</p> <p>Variables can be defined with</p> <pre><code>\"let(var_name, definition, expression)\"\n</code></pre> <ul> <li><code>var_name</code>: a variable name that should denote the feature</li> <li><code>definition</code>: an expression defining the value of the variable</li> <li><code>expression</code>: an expression defining any other feature.     Occurrences of <code>var_name</code> in this expression may refer to the feature     defined by <code>definition</code>.</li> </ul>"},{"location":"search-plugin-syntax/#example","title":"Example","text":"<p>Suppose I want to run GBFS with the <code>landmark_sum</code> heuristic, and then run another GBFS search with the <code>landmark_cost_partitioning</code> heuristic, using the h^m landmarks without discovering the landmarks twice.</p> <pre><code>--search \"let(lm, lm_hm(m=2), \n              iterated([lazy_greedy([landmark_sum(lm)]),\n                        lazy_greedy([landmark_cost_partitioning(lm))]]))\"\n</code></pre>"},{"location":"search-plugin-syntax/#old-style_predefinitions","title":"Old-style Predefinitions","text":"<p>We still support but deprecate the use of \"predefinitions\" before the<code>--search</code> option. They are internally converted to <code>let</code>-expressions.</p> <p>The command lines</p> <pre><code>--evaluator \"name=definition\" --search \"expression\"\n--landmarks \"name=definition\" --search \"expression\"\n</code></pre> <p>are both transformed to</p> <pre><code>--search \"let(name, definition, expression)\"\n</code></pre>"},{"location":"search-plugin-syntax/#conditional_options","title":"Conditional options","text":"<p>In some cases, it is useful to specify different options depending on properties of the input file. For example, the LAMA 2011 configuration makes use of this, adding an additional cost-ignoring search run at the start for tasks with non-unit action costs.</p>"},{"location":"search-plugin-syntax/#example_1","title":"Example","text":"<pre><code>--if-unit-cost --evaluator \"h1=ff()\" --evaluator \"h2=blind()\" \\\n--if-non-unit-cost --evaluator \"h1=cea()\" --evaluator \"h2=lmcut()\" \\\n--always --search \"eager_greedy([h1, h2])\"\n</code></pre> <p>This conducts an eager greedy search with two heuristics. On unit-cost tasks, it uses the FF heuristic and the blind heuristic. On other tasks, it uses the context-enhanced additive heuristic and the LM-Cut heuristic.</p>"},{"location":"search-plugin-syntax/#details","title":"Details","text":"<p>Options can be made conditional via selectors such as <code>--if-unit-cost</code>. All options following a selector are only used if the condition associated with the selector is true. (This really includes all options, including ones like <code>--plan-file</code> that do not affect the planning algorithm.) Each selector is in effect until it is overridden by a new selector. The following selectors are available:</p> <ul> <li><code>--if-unit-cost</code>: the following options are only used for     unit-cost planning tasks (i.e., tasks where all actions have cost 1,     including the case where no action costs are specified at all)</li> <li><code>--if-non-unit-cost</code>: opposite of <code>--if-unit-cost</code></li> <li><code>--always</code>: the following options are always used</li> </ul>"},{"location":"translator-output-format/","title":"Output of the Fast Downward translator","text":"<p>This page describes the output format of the translator component of Fast Downward.</p>"},{"location":"translator-output-format/#version_history","title":"Version history","text":"<p>This page describes version 3 of the output file format. The following list gives a brief version history:</p> <ul> <li>Version 1 (introduced 2004): the original Fast Downward translator,     generating the <code>output.sas</code> file with information for the preprocessor and     search code and a <code>test.groups</code> file with some additional information for human     users. Output files from this version can be identified by their lack of either     a <code>version</code> or <code>metric</code> section.</li> <li>Version 2 (introduced 2008): added the <code>metric</code> section and action cost     information and introduced a third output file, <code>all.groups</code>, with mutex     information used by the landmark generation procedures.  Output files from     this version can be identified by their lack of a <code>version</code> and inclusion     of a <code>metric</code> section.</li> <li>Version 3 (introduced September 2011): integrated the three     output files into one and added the <code>version</code> section.</li> </ul>"},{"location":"translator-output-format/#translator_file_format","title":"Translator file format","text":"<p>The translator file consists of eight sections:</p> <ol> <li>Version section</li> <li>Metric section</li> <li>Variables section</li> <li>Mutex section</li> <li>Initial state section</li> <li>Goal section</li> <li>Operator section</li> <li>Axiom section</li> </ol>"},{"location":"translator-output-format/#translator_file_format_version_section","title":"Translator file format: version section","text":"<p>The version section includes a version number that is used by the search component to determine if its input has been generated by a compatible translator version.</p> <p>It always looks like this for the version of the translator documented here:</p> <p>Sample version section:</p> <pre><code>begin_version\n3\nend_version\n</code></pre>"},{"location":"translator-output-format/#translator_file_format_metric_section","title":"Translator file format: metric section","text":"<p>The metric section indicates whether action costs are used or not. It begins with the line \"begin_metric\", followed by either a 0 or 1. 0 indicates that action costs are not used, and all actions are treated as unit-cost. 1 indicates that action costs are used. The section ends with the line \"end_metric\".</p> <p>Sample metric section (Gripper domain):</p> <pre><code>begin_metric\n0\nend_metric\n</code></pre>"},{"location":"translator-output-format/#translator_file_format_variables_section","title":"Translator file format: variables section","text":"<p>Background: the translation process works by partitioning the fluent facts of the grounded PDDL task into sets of mutually exclusive propositions (\"mutex groups\"). Such a partitioning is always possible since a decomposition into trivial mutex groups with only one element always works. However, the translator prefers to use larger mutex groups, trying to find a cover with few groups. A mutex group consisting of facts {p1, ..., pk} is turned into a finite-domain variable with domain {0, 1, ..., k}, where value i &lt; k means that fact p_{i+1} is true and all others are false, and value k means that all facts are false. (Sometimes this last value is omitted because the translator detects that at least one fact from the group must always be true.)</p> <p>The variables section begins with a line containing a single number, the number of finite-domain variables in the task. Following that line, each variable is defined in sequence.</p> <p>An variable definition is structured as follows:</p> <ul> <li>The first line is \"begin_variable\".</li> <li>The second line contains the name of the variable (which is     usually a nondescriptive name like \"var7\").</li> <li>The third line specifies the axiom layer of the variable.</li> <li>The fourth line specifies the variable's <code>range</code>, i.e., the number of     different values it can take it on. The value of a variable is always     from the set {0, 1, 2, ..., <code>range</code> - 1}.</li> <li>The following <code>range</code> lines specify the symbolic names for each of the     <code>range</code> values the variable can take on, one at a time. These typically     correspond to grounded PDDL facts, except for values that represent     that none out a set of PDDL facts is true.</li> <li>The final line is \"end_variable\".</li> </ul> <p>For state variables that do not correspond to axioms, i.e. which are not computed from the values of other state variables, the axiom layer is always -1. For state variables that do correspond to axioms, the axiom layer determines the order of evaluation of axiom rules, described further below in the section \"Evaluating Axioms\".</p> <p>Sample variables section (Gripper domain, <code>prob01.pddl</code> from IPC 1998):</p> <pre><code>  7\n  begin_variable\n  var0\n  -1\n  5\n  Atom carry(ball1, right)\n  Atom carry(ball2, right)\n  Atom carry(ball3, right)\n  Atom free(right)\n  Atom carry(ball4, right)\n  end_variable\n  begin_variable\n  var1\n  -1\n  5\n  Atom carry(ball3, left)\n  Atom free(left)\n  Atom carry(ball2, left)\n  Atom carry(ball1, left)\n  Atom carry(ball4, left)\n  end_variable\n  begin_variable\n  var2\n  -1\n  3\n  Atom at(ball4, rooma)\n  Atom at(ball4, roomb)\n  &lt;none of those&gt;\n  end_variable\n  begin_variable\n  var3\n  -1\n  3\n  Atom at(ball3, rooma)\n  Atom at(ball3, roomb)\n  &lt;none of those&gt;\n  end_variable\n  begin_variable\n  var4\n  -1\n  3\n  Atom at(ball1, rooma)\n  Atom at(ball1, roomb)\n  &lt;none of those&gt;\n  end_variable\n  begin_variable\n  var5\n  -1\n  3\n  Atom at(ball2, rooma)\n  Atom at(ball2, roomb)\n  &lt;none of those&gt;\n  end_variable\n  begin_variable\n  var6\n  -1\n  2\n  Atom at-robby(roomb)\n  Atom at-robby(rooma)\n  end_variable\n</code></pre> <p>The example shows that there are 7 finite-domain variables in this task. Please note that the order in which the variables are generated and the order of their values are not deterministic and can vary between translator runs.</p> <p>The first variable is not a derived variable (its axiom layer is -1), and it can take on 5 different values (from the set {0, 1, 2, 3, 4, 5}), which correspond to the PDDL facts <code>(carry ball1 right)</code>, <code>(carry ball2 right)</code>, <code>(carry ball3 right)</code>, <code>(free right)</code>, and <code>(carry ball4 right)</code>. This represents the state of the right gripper. The next variable is similar, but represents a state of the left gripper.</p> <p>The third variable is again not derived (axiom layer -1) and takes on three values, corresponding to ball4 being in rooma, ball4 being in roomb, and ball4 being in neither room (which implies that it is carried by either gripper). The next three state variables similarly represent the other balls, and the final state variable represents the location of the robot.</p>"},{"location":"translator-output-format/#translator_file_format_mutex_section","title":"Translator file format: mutex section","text":"<p>The mutex section encodes additional mutual exclusion constraints in the form of mutex groups (groups of variable/value pairs of which no two can be simultaneously true).</p> <p>A mutex group is called trivial if it only represents information that is obvious from the finite-domain representation (that the same variable cannot hold two different values concurrently). When used with default options, the translator will discard trivial mutexes, so the search component can rely on the fact that all mutexes are non-trivial. However, this is not guaranteed when using translator options <code>--translate-options</code> and <code>--keep-unreachable-facts</code>.</p> <p>The mutex section begins with a line containing a single number, the number of mutex groups in the task. Following that line, each mutex group is defined in sequence.</p> <p>An mutex group definition is structured as follows:</p> <ul> <li>The first line is \"begin_mutex_group\".</li> <li>The second line contains a single number, denoting the number of     facts in the mutex group.</li> <li>The following lines describe the facts in the group, one line     for each fact. Each fact is is given by two numbers separated by     a space, denoting the variable (indexing into the variable     section above, counting from 0) and a value for that variable     (indexing into the list of value names for that variable,     counting from 0).</li> <li>The final line is \"end_mutex_group\".</li> </ul> <p>Sample mutex section (Gripper):</p> <pre><code>  7\n  begin_mutex_group\n  4\n  1 4\n  0 4\n  2 0\n  2 1\n  end_mutex_group\n  begin_mutex_group\n  4\n  1 0\n  0 2\n  3 0\n  3 1\n  end_mutex_group\n  begin_mutex_group\n  4\n  1 3\n  0 0\n  4 0\n  4 1\n  end_mutex_group\n  begin_mutex_group\n  5\n  1 1\n  1 4\n  1 0\n  1 2\n  1 3\n  end_mutex_group\n  begin_mutex_group\n  5\n  0 3\n  0 4\n  0 2\n  0 1\n  0 0\n  end_mutex_group\n  begin_mutex_group\n  2\n  6 1\n  6 0\n  end_mutex_group\n  begin_mutex_group\n  4\n  1 2\n  0 1\n  5 0\n  5 1\n  end_mutex_group\n</code></pre> <p>There are 7 mutex groups.</p> <p>The first group encodes that the following variable/value pairs are mutually exclusive: variable 1 has value 4; variable 0 has value 4; variable 2 has value 0; variable 2 has value 1. This corresponds to the PDDL facts <code>(carry ball4 left)</code>, <code>(carry ball4 right)</code>, <code>(at ball4 rooma)</code>, <code>(at ball4 roomb)</code>.</p> <p>The second, third and seventh mutex groups encode similar mutual exclusion constraints for the other three balls.</p> <p>The fourth, fifth and sixth mutex groups are trivial.</p>"},{"location":"translator-output-format/#translator_file_format_initial_state_section","title":"Translator file format: initial state section","text":"<p>The initial state section begins with the line \"begin_state\", followed by one line for each SAS state variable. Each of those lines contains a single number, denoting the value of the given state variable in the initial state (for state variables which do not correspond to derived predicates) or the \"default value\" of the state variable (for state variables corresponding to derived predicates; see section \"Evaluating Axioms\" below). The section ends with the line \"end_state\".</p> <p>Here is the initial state section for the Gripper example:</p> <p>Sample initial state section (Gripper domain):</p> <pre><code>  begin_state\n  3\n  1\n  0\n  0\n  0\n  0\n  1\n  end_state\n</code></pre> <p>So the initial value of var0 in the example is 3, the initial value of var1 is 1, the initial values of var2 through var5 are 0, and the initial value of var6 is 1. Looking up the meaning of these values in the variable section shown earlier, this means that exactly the following STRIPS propositions are true in the initial state: <code>(free right)</code>, <code>(free left)</code>, <code>(at ball4 rooma)</code>, <code>(at ball3 rooma)</code>, <code>(at ball1 rooma)</code>, <code>(at ball2 rooma)</code>, <code>(at-robby rooma)</code>.</p>"},{"location":"translator-output-format/#translator_file_format_goal_section","title":"Translator file format: goal section","text":"<p>The goal section begins with the line \"begin_goal\", followed by a line which contains the number of goal pairings. This is followed by one line for each goal pairing, where a goal pairing is given by two numbers separated by spaces, where the pair \"i j\" means that \"var<code>&lt;i&gt;</code>\" must have the value j in the goal. The goal section ends with the line \"end_goal\".</p> <p>Here is the goal section for the Gripper example:</p> <p>Sample goal section (Gripper domain):</p> <pre><code>  begin_goal\n  4\n  2 1\n  3 1\n  4 1\n  5 1\n  end_goal\n</code></pre> <p>We see that there are four goal conditions: Each of the variables var2 through var5 shall assume the value 1. In other words, the goal is reached if all four balls are in roomb.</p> <p>Note that the goal condition of the translated task is always a simple conjunction of atomic goals. If the original PDDL goal is more complicated, it is transformed by the translator to fit this requirement. In some cases, this leads to the introduction of derived variables, even if the original PDDL task did not use derived predicates.</p>"},{"location":"translator-output-format/#translator_file_format_operator_section","title":"Translator file format: operator section","text":"<p>The operator section begins with a line containing a single number, the number of operators in the task. Following that line, each operator is defined in sequence.</p> <p>An operator definition is structured as follows:</p> <ul> <li>The first line is \"begin_operator\".</li> <li>The second line contains the name of the operator.</li> <li>The third line contains a single number, denoting the number of     prevail conditions.</li> <li>The following lines describe the prevail conditions, one line     for each condition. A prevail condition is given by two numbers     separated by spaces, denoting a variable/value pairing in the     same notation for goals described above.</li> <li>The first line after the prevail conditions contains a single     number, denoting the number of effects.</li> <li>The following lines describe the effects, one line for each     effect (read on).</li> <li>The line before last gives the operator cost. This line only     matters if metric is     1 (otherwise, any number here will be treated as 1).</li> <li>The final line is \"end_operator\".</li> </ul> <p>Of these parts, the lines that describe an effect are most complicated because effects can have associated effect conditions as well as a condition on the old value of the affected state variable (called a \"precondition\" as opposed to a \"prevail condition\" in the SAS+ literature). An effect is always given in a single line, with the individual parts separated by spaces. It is structured as follows:</p> <ul> <li>First comes the number of effect conditions. In STRIPS domains, this     will usually be 0 (additional effect conditions can be introduced by     the translator in rare cases, though).</li> <li>This is followed by one variable/value pair for each effect     condition. This is given as two numbers like for goal conditions and     prevail conditions.</li> <li>This is followed by a number denoting the variable affected by the     effect in the third-last position.</li> <li>This is followed by the value that this variable must have for the     operator to be applicable (precondition), or -1 if there is no     particular value that the variable must have. (Note that is truly     part of the operator precondition and not an effect condition, and     having it separated from the operator precondition is somewhat     clumsy. Let's call it a historical accident caused by SAS+'s     distinction of prevail and preconditions.)</li> <li>Finally, the last number denotes the new value for the affected     variable.</li> </ul> <p>Even for fairly small examples, the operator section becomes quite big, so we omit most operator definitions of the Gripper example:</p> <p>Sample operator section (Gripper domain):</p> <pre><code>  34\n  begin_operator\n  move rooma roomb\n  0\n  1\n  0 6 1 0\n  0\n  end_operator\n  begin_operator\n  pick ball4 rooma left\n  1\n  6 1\n  2\n  0 1 1 4\n  0 2 0 2\n  0\n  end_operator\n  [... 31 operators omitted]\n  begin_operator\n  pick ball1 roomb right\n  1\n  6 0\n  2\n  0 0 3 0\n  0 4 1 2\n  0\n  end_operator\n</code></pre> <p>The example shows that there are 34 operators in this domain, and three of them are shown in detail.</p> <p>The first operator is called \"move rooma roomb\" and has no prevail conditions (0) and one effect (1). The effect has no associated effect conditions (0) and affects var6 (6). It requires that the old value of the variable is 1, so it is only applicable if the robot is in rooma. It establishes the value 0, so that the robot will be in roomb afterwards. This domain does not use explicit action_costs (as encoded in the <code>metric</code> section), so the final line is <code>0</code>. (The search code will treat problems with no explicit action costs as unit-cost problems though, so the action will be handled as if its cost were 1.)</p> <p>The two pick-up operators are similar, so we only explain the last one. Its name is \"pick ball1 roomb right\". It has one prevail condition, namely that var6 has the value 0 (i.e. the robot is in roomb). It has two effects. The first effect has no associated conditions, requires that var0 currently has value 3 (that is, the right gripper is free) and changes var0 to value 0 (the right gripper carries ball1). The second effect has no associated conditions either, requires that var4 currently has value 1 (ball1 is in roomb) and sets it to value 2 (ball1 is in neither room afterwards). The operator again ends with the line <code>0</code> since this task does not define explicit action costs.</p> <p>As an example of an operator involving effect conditions and the don't care value -1 for an effect precondition, consider the following operator from a task in the Schedule domain:</p> <p>Sample operator with effect conditions and cost (Schedule domain, modified with costs):</p> <pre><code>  begin_operator\n  do-polish a0\n  1\n  7 0\n  4\n  0 24 1 0\n  0 3 -1 0\n  1 29 1 29 -1 0\n  0 22 1 0\n  7\n  end_operator\n</code></pre> <p>The operator is named \"do-polish a0\". The prevail condition \"7 0\" requires that the temperature of object a0 is cold. The four effects of the operators are:</p> <ul> <li><code>0 24 1 0</code>:</li> </ul> <p>Unconditionally\u00a0(0),\u00a0the\u00a0polisher\u00a0(var24),\u00a0which\u00a0must\u00a0be\u00a0non-busy\u00a0(1),\u00a0becomes\u00a0busy\u00a0(0).`</p> <ul> <li><code>0 3 -1 0</code>:</li> </ul> <p>Unconditionally\u00a0(0),\u00a0the\u00a0surface\u00a0condition\u00a0of\u00a0a0\u00a0(var3),\u00a0whose\u00a0current\u00a0status\u00a0can\u00a0be\u00a0anything\u00a0(-1),\u00a0will\u00a0become\u00a0polished\u00a0(0).`</p> <ul> <li><code>1 29 1 29 -1 0</code>:</li> </ul> <p>Under\u00a0the\u00a0one\u00a0(1)\u00a0effect\u00a0condition\u00a0that\u00a0we\u00a0have\u00a0not\u00a0currently\u00a0scheduled\u00a0any\u00a0object\u00a0(var29\u00a0equals\u00a01),\u00a0we\u00a0will\u00a0have\u00a0scheduled\u00a0an\u00a0object\u00a0afterwards\u00a0(var29\u00a0is\u00a0set\u00a0to\u00a00).\u00a0The\u00a0variable\u00a0var29\u00a0may\u00a0have\u00a0any\u00a0value\u00a0currently\u00a0(-1).`</p> <ul> <li><code>0 22 1 0</code>:</li> </ul> <p>Unconditionally\u00a0(0),\u00a0the\u00a0scheduled-status\u00a0of\u00a0a0\u00a0(var22),\u00a0which\u00a0must\u00a0be\u00a0not-scheduled\u00a0(1),\u00a0becomes\u00a0scheduled\u00a0(0).`</p> <p>Note that the only effect with an effect condition (1 29 1 29 -1 0) could be rewritten as (0 29 -1 0) in this situation, because var29 can only take on the possible values 0 and 1 anyway. However, the translator does not try to detect and simplify this effect pattern, which occurs quite commonly in some of the planning benchmarks.</p> <p>Finally, the 7 before the \"end_operator\" line indicates that this operator has a cost of 7.</p>"},{"location":"translator-output-format/#translator_file_format_axiom_section","title":"Translator file format: axiom section","text":"<p>The axiom section is similar in structure to the operator section, as axiom rules can be considered to be operators that are automatically executed whenever applicable. However, the section is somewhat simpler in structure because axiom rules only ever affect a single state variable.</p> <p>Similar to the operator section, the axiom section begins with a line containing the number of axiom rules. Following that line, each axiom rule is defined in sequence.</p> <p>An axiom rule is structured as follows:</p> <ul> <li>The first line is \"begin_rule\"</li> <li>The second line contains a single number, denoting the number of     conditions in the \"body\" of the rule.</li> <li>The following lines describe these conditions, one line for each     condition. A condition is given by two numbers separated by     spaces, denoting a variable/value pairing. In other words, the     same notation as for operator prevail conditions is used.</li> <li>The following line contains three numbers, denoting the variable     affected by the axiom rule, the value that this variable must     have for this rule to be applicable, and the new value assigned     to this variable. The variable and this latter value together     form the \"head\" of the rule.</li> <li>The final line is \"end_rule\".</li> </ul> <p>Variables appearing in the head of axiom rules (axiom variables) are disjoint from variables affected by operators. In the current version of the translator, axiom variables always have a binary domain, so the \"old value\" for the affected variable is always the complement of the new value and can be safely ignored.</p> <p>In the Gripper example, the axiom section looks as follows:</p> <p>Sample axiom section (Gripper domain):</p> <pre><code>  0\n</code></pre> <p>This shows that there are no axiom rules in this domain, which is the case for all pure-STRIPS benchmarks. Axiom rules will of course be generated for domains that contain derived predicates, but they can also be generated for PDDL tasks without derived predicates if they use non-STRIPS features such as universally quantified conditions, as some of these are compiled away with the help of axioms. As an example, here is an axiom rules from a Miconic-FullADL task:</p> <p>Sample axiom section (Miconic-FullADL domain):</p> <pre><code>  1\n  begin_rule\n  2\n  1 0\n  3 0\n  5 0 1\n  end_rule\n</code></pre> <p>The axiom section contains a single axiom rule. It has two conditions in the body, namely that var1 and var3 are both set to 0, i.e. that passengers p1 and p0 have both been served. The head of the axiom states that if the condition is satisfied, then var5 will assume the value 1 if it currently has the value0. Variable var5 corresponds to a proposition over a newly introduced predicate \"new-axiom@9\" which has been generated to simplify the original PDDL goal <code>(forall (?p - passenger) (served ?p))</code>. (Of course, in this case the goal could also have been transformed to a simple conjunction in a different way that does not require axioms.)</p>"},{"location":"translator-output-format/#evaluating_axioms","title":"Evaluating axioms","text":"<p>State variables that correspond to derived predicates are not directly affected by operator applications. Instead, their values in a given world state are computed from the values of the other state variables using the following algorithm:</p> <ul> <li>First, all axiom state variables are set to their default value     (the one specified in the initial state section).</li> <li>Second, all axiom rules which affect variables at axiom layer 0     are evaluated. An axiom rule is evaluated by determining whether     all variable/value pairings in its body match the current state.     If so, the variable in the head is changed to the value in the     head. This process is repeated until no further changes occur.</li> <li>Third, all axioms rules which affect variables at axiom layer 1     are evaluated.</li> <li>Fourth, all axioms rules which affect variables at axiom layer 2     are evaluated.</li> <li>...</li> </ul> <p>The semantics of the translation guarantees that the algorithm always terminates and that the result is independent of the order in which axiom rules at the same layer are considered.</p>"},{"location":"what-flavour-is-for-me/","title":"What flavour is for me","text":"<p>This page should help you decide which Fast Downward setup is most suitable for your use case. Back to quick start.</p>"},{"location":"what-flavour-is-for-me/#run-time_comparison","title":"Run-time comparison","text":"<p>These are results of a very informal experiment (wall-clock time) run in 2019. Please treat it as anecdotal and possibly outdated evidence. Native OS and compilers identical to container versions (we think; can verify these later). Three runs each.</p> <ul> <li>gripper prob01, blind search:<ul> <li>native build: 0.098 seconds, 0.101 seconds, 0.102 seconds</li> <li>Apptainer (then called Singularity): 0.320 seconds, 0.350     seconds, 0.364 seconds</li> <li>Docker: 1.124 seconds. 1.135 seconds, 1.203 seconds</li> <li>Vagrant: 1.726 seconds, 1.736 seconds, 1.792 seconds</li> </ul> </li> <li>gripper prob07, blind search:<ul> <li>native build: 19.985 seconds, 20.082 seconds, 20.134 seconds</li> <li>Apptainer: 20.386 seconds, 20.488 seconds, 20.501 seconds</li> <li>Docker: 26.841 seconds, 27.030 seconds, 26.623 seconds</li> <li>Vagrant: 22.576 seconds, 22.616 seconds, 22.624 seconds</li> </ul> </li> </ul> <p>Vagrant results using \"vagrant ssh -c\". Most of the penalty over native build seems to be establishing the ssh connection. For Docker, we observed significantly different overheads when running similar tests on different machines. In our tests, Apptainer/Singularity always caused a very small overhead when compared to the native build, Docker sometimes shows runtime overheads of around 40%. Again, keep in mind that these are very informal tests.</p>"},{"location":"what-flavour-is-for-me/#other_notes","title":"Other notes","text":"<ul> <li>points in favour of Apptainer over Docker:<ul> <li>once Apptainer is installed, setup is trivial/non-existent</li> <li>no root privileges needed</li> <li>leaves no permanent traces on the machine: the planner is     just a single file that can be used like a shell script with     no dependencies or changes to the system</li> </ul> </li> <li>Apptainer and Docker are made for different purposes and have     different isolation models. If you care about security, it is good     to be aware of what they do or don't do.<ul> <li>Apptainer: emphasis on running scientific experiments</li> <li>Docker: emphasis on deployment and composition of services</li> </ul> </li> </ul>"},{"location":"search/","title":"Search Plugins","text":"<p>The search component consists of many different plugins of different plugin types such as search algorithms or evaluators.</p> <p>The syntax documentation contains more information on how to read their documentation.</p> <p>The following pages document the plugins of each type:</p> <ul> <li>AbstractTask</li> <li>AbstractionGenerator</li> <li>ConstraintGenerator</li> <li>Evaluator</li> <li>LabelReduction</li> <li>LandmarkFactory</li> <li>MergeScoringFunction</li> <li>MergeSelector</li> <li>MergeStrategy</li> <li>MergeTree</li> <li>OpenList</li> <li>OrderGenerator</li> <li>PatternCollectionGenerator</li> <li>PatternGenerator</li> <li>PruningMethod</li> <li>SearchAlgorithm</li> <li>ShrinkStrategy</li> <li>SubtaskGenerator</li> </ul>"},{"location":"search/AbstractTask/","title":"AbstractTask","text":"<p>This page describes available transformations of the root task.</p>"},{"location":"search/AbstractTask/#cost-adapted_task","title":"Cost-adapted task","text":"<p>A cost-adapting transformation of the root task. <pre><code>adapt_costs(cost_type=normal)\n</code></pre></p> <ul> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> </ul>"},{"location":"search/AbstractTask/#root_task","title":"Root task","text":"<p>No transformation of the input task. <pre><code>no_transform()\n</code></pre></p>"},{"location":"search/AbstractionGenerator/","title":"AbstractionGenerator","text":"<p>Create abstractions for cost partitioning heuristics.</p>"},{"location":"search/AbstractionGenerator/#cartesian_abstraction_generator","title":"Cartesian abstraction generator","text":"<pre><code>cartesian(subtasks=[landmarks(order=random), goals(order=random)], max_states=infinity, max_transitions=1M, max_time=infinity, sort_transitions=false, transition_representation=store, pick_flawed_abstract_state=batch_min_h, pick_split=max_cover, tiebreak_split=max_refined, max_concrete_states_per_abstract_state=infinity, max_state_expansions=1M, memory_padding=500, random_seed=-1, dot_graph_verbosity=silent, verbosity=normal)\n</code></pre> <ul> <li>subtasks (list of SubtaskGenerator): subtask generators</li> <li>max_states (int [1, infinity]): maximum sum of abstract states over all abstractions</li> <li>max_transitions (int [0, infinity]): If transition_representation=store, this value limits the maximum sum of state-changing transitions (excluding self-loops) over all abstractions. Otherwise, this value limits the number of cached transitions in the shortest path tree of each abstraction individually.</li> <li>max_time (double [0.0, infinity]): maximum time in seconds for building abstractions</li> <li>sort_transitions (bool): sort transitions to ensure the different transition system representations yield the same abstractions</li> <li>transition_representation ({store, compute}): how to compute transitions between abstract states<ul> <li><code>store</code>: store transitions</li> <li><code>compute</code>: efficiently compute transitions on demand</li> </ul> </li> <li>pick_flawed_abstract_state ({first, first_on_shortest_path, random, min_h, max_h, batch_min_h}): flaw-selection strategy<ul> <li><code>first</code>: Consider first encountered flawed abstract state and a random concrete state.</li> <li><code>first_on_shortest_path</code>: Follow the arbitrary solution in the shortest path tree (no flaw search). Consider first encountered flawed abstract state and a random concrete state.</li> <li><code>random</code>: Collect all flawed abstract states and then consider a random abstract state and a random concrete state.</li> <li><code>min_h</code>: Collect all flawed abstract states and then consider a random abstract state with minimum h value and a random concrete state.</li> <li><code>max_h</code>: Collect all flawed abstract states and then consider a random abstract state with maximum h value and a random concrete state.</li> <li><code>batch_min_h</code>: Collect all flawed abstract states and iteratively refine them (by increasing h value). Only start a new flaw search once all remaining flawed abstract states are refined. For each abstract state consider all concrete states.</li> </ul> </li> <li>pick_split ({random, min_unwanted, max_unwanted, min_refined, max_refined, min_hadd, max_hadd, min_cg, max_cg, max_cover}): split-selection strategy<ul> <li><code>random</code>: select a random variable (among all eligible variables)</li> <li><code>min_unwanted</code>: select an eligible variable which has the least unwanted values (number of values of v that land in the abstract state whose h-value will probably be raised) in the flaw state</li> <li><code>max_unwanted</code>: select an eligible variable which has the most unwanted values (number of values of v that land in the abstract state whose h-value will probably be raised) in the flaw state</li> <li><code>min_refined</code>: select an eligible variable which is the least refined (-1 * (remaining_values(v) / original_domain_size(v))) in the flaw state</li> <li><code>max_refined</code>: select an eligible variable which is the most refined (-1 * (remaining_values(v) / original_domain_size(v))) in the flaw state</li> <li><code>min_hadd</code>: select an eligible variable with minimal h^add(s_0) value over all facts that need to be removed from the flaw state</li> <li><code>max_hadd</code>: select an eligible variable with maximal h^add(s_0) value over all facts that need to be removed from the flaw state</li> <li><code>min_cg</code>: order by increasing position in partial ordering of causal graph</li> <li><code>max_cg</code>: order by decreasing position in partial ordering of causal graph</li> <li><code>max_cover</code>: compute split that covers the maximum number of flaws for several concrete states.</li> </ul> </li> <li>tiebreak_split ({random, min_unwanted, max_unwanted, min_refined, max_refined, min_hadd, max_hadd, min_cg, max_cg, max_cover}): split-selection strategy for breaking ties<ul> <li><code>random</code>: select a random variable (among all eligible variables)</li> <li><code>min_unwanted</code>: select an eligible variable which has the least unwanted values (number of values of v that land in the abstract state whose h-value will probably be raised) in the flaw state</li> <li><code>max_unwanted</code>: select an eligible variable which has the most unwanted values (number of values of v that land in the abstract state whose h-value will probably be raised) in the flaw state</li> <li><code>min_refined</code>: select an eligible variable which is the least refined (-1 * (remaining_values(v) / original_domain_size(v))) in the flaw state</li> <li><code>max_refined</code>: select an eligible variable which is the most refined (-1 * (remaining_values(v) / original_domain_size(v))) in the flaw state</li> <li><code>min_hadd</code>: select an eligible variable with minimal h^add(s_0) value over all facts that need to be removed from the flaw state</li> <li><code>max_hadd</code>: select an eligible variable with maximal h^add(s_0) value over all facts that need to be removed from the flaw state</li> <li><code>min_cg</code>: order by increasing position in partial ordering of causal graph</li> <li><code>max_cg</code>: order by decreasing position in partial ordering of causal graph</li> <li><code>max_cover</code>: compute split that covers the maximum number of flaws for several concrete states.</li> </ul> </li> <li>max_concrete_states_per_abstract_state (int [1, infinity]): maximum number of flawed concrete states stored per abstract state</li> <li>max_state_expansions (int [1, infinity]): maximum number of state expansions per flaw search if a flaw has already been found</li> <li>memory_padding (int [0, infinity]): amount of extra memory in MB to reserve for recovering from out-of-memory situations gracefully. When the memory runs out, we stop refining and start the search. Due to memory fragmentation, the memory used for building the abstraction (states, transitions, etc.) often can't be reused for things that require big continuous blocks of memory. It is for this reason that we require a rather large amount of memory padding by default.</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>dot_graph_verbosity ({silent, write_to_console, write_to_file}): verbosity of printing/writing dot graphs<ul> <li><code>silent</code>: </li> <li><code>write_to_console</code>: </li> <li><code>write_to_file</code>: </li> </ul> </li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/AbstractionGenerator/#projections","title":"projections","text":"<p>Projection generator <pre><code>projections(patterns=&lt;none&gt;, dominance_pruning=false, combine_labels=true, create_complete_transition_system=false, verbosity=normal)\n</code></pre></p> <ul> <li>patterns (PatternCollectionGenerator): pattern generation method</li> <li>dominance_pruning (bool): prune dominated patterns</li> <li>combine_labels (bool): group labels that only induce parallel transitions</li> <li>create_complete_transition_system (bool): create explicit transition system</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/ConstraintGenerator/","title":"ConstraintGenerator","text":"<p>This page describes different types of constraints and their corresponding generator. Operator-counting constraints are linear constraints that are satisfied by all plans. They are defined over variables that represent the number of times each operator is used.  An operator-counting heuristic minimizes the total cost of used operators subject to a set of such constraints</p>"},{"location":"search/ConstraintGenerator/#delete_relaxation_constraints_from_imai_and_fukunaga","title":"Delete relaxation constraints from Imai and Fukunaga","text":"<p>Operator-counting constraints based on the delete relaxation. By default the constraints encode an easy-to-compute relaxation of h^+^. With the right settings, these constraints can be used to compute the optimal delete-relaxation heuristic h^+^ (see example below). For details, see</p> <ul> <li>Tatsuya Imai and Alex Fukunaga. On a practical, integer-linear programming model for delete-freetasks and its use as a heuristic for cost-optimal planning. Journal of Artificial Intelligence Research 54:631-677. 2015.</li> </ul> <pre><code>delete_relaxation_if_constraints(use_time_vars=false, use_integer_vars=false)\n</code></pre> <ul> <li>use_time_vars (bool): use variables for time steps. With these additional variables the constraints enforce an order between the selected operators. Leaving this off (default) corresponds to the time relaxation by Imai and Fukunaga. Switching it on, can increase the heuristic value but will increase the size of the constraints which has a strong impact on runtime. Constraints involving time variables use a big-M encoding, so they are more useful if used with integer variables.</li> <li>use_integer_vars (bool): restrict auxiliary variables to integer values. These variables encode whether operators are used, facts are reached, which operator first achieves which fact, and in which order the operators are used. Restricting them to integers generally improves the heuristic value at the cost of increased runtime.</li> </ul> <p>Example: To compute the optimal delete-relaxation heuristic h^+^, use <pre><code>operatorcounting(\n   [delete_relaxation_if_constraints(use_time_vars=true,use_integer_vars=true)],\n   use_integer_operator_counts=true)\n</code></pre></p> <p>Note: For best performance we recommend using the alternative formulation by Rankooh and Rintanen, accessible through the option <code>delete_relaxation_rr_constraints</code>.</p>"},{"location":"search/ConstraintGenerator/#delete_relaxation_constraints_from_rankooh_and_rintanen","title":"Delete relaxation constraints from Rankooh and Rintanen","text":"<p>Operator-counting constraints based on the delete relaxation. By default the constraints encode an easy-to-compute relaxation of h^+^. With the right settings, these constraints can be used to compute the optimal delete-relaxation heuristic h^+^ (see example below). For details, see</p> <ul> <li>Masood Feyzbakhsh Rankooh and Jussi Rintanen. Efficient Computation and Informative Estimation ofh+ by Integer and Linear Programming. Proceedings of the Thirty-Second International Conference on Automated Planning and Scheduling (ICAPS2022) 32:71-79. 2022.</li> </ul> <pre><code>delete_relaxation_rr_constraints(acyclicity_type=vertex_elimination, use_integer_vars=false)\n</code></pre> <ul> <li>acyclicity_type ({time_labels, vertex_elimination, none}): The most relaxed version of this constraint only enforces that achievers of facts are picked in such a way that all goal facts have an achiever, and the preconditions all achievers are either true in the current state or have achievers themselves. In this version, cycles in the achiever relation can occur. Such cycles can be excluded with additional auxilliary varibles and constraints.<ul> <li><code>time_labels</code>: introduces MIP variables that encode the time at which each fact is reached. Acyclicity is enforced with constraints that ensure that preconditions of actions are reached before their effects.</li> <li><code>vertex_elimination</code>: introduces binary variables based on vertex elimination. These variables encode that one fact has to be reached before another fact. Instead of adding such variables for every pair of states, they are only added for a subset sufficient to ensure acyclicity. Constraints enforce that preconditions of actions are reached before their effects and that the assignment encodes a valid order.</li> <li><code>none</code>: No acyclicity is enforced. The resulting heuristic is a relaxation of the delete-relaxation heuristic.</li> </ul> </li> <li>use_integer_vars (bool): restrict auxiliary variables to integer values. These variables encode whether facts are reached, which operator first achieves which fact, and (depending on the acyclicity_type) in which order the operators are used. Restricting them to integers generally improves the heuristic value at the cost of increased runtime.</li> </ul> <p>Example: To compute the optimal delete-relaxation heuristic h^+^, useinteger variables and some way of enforcing acyclicity (other than \"none\"). For example <pre><code>operatorcounting(\n   [delete_relaxation_rr_constraints(acyclicity_type=vertex_elimination,\n                                     use_integer_vars=true)],\n   use_integer_operator_counts=true)\n</code></pre></p> <p>Note: While the delete-relaxation constraints by Imai and Fukunaga (accessible via option <code>delete_relaxation_if_constraints</code>) serve a similar purpose to the constraints implemented here, we recommend using this formulation as it can generally be solved more efficiently, in particular in case of the h^+^ configuration, and some relaxations offer tighter bounds.</p>"},{"location":"search/ConstraintGenerator/#lm-cut_landmark_constraints","title":"LM-cut landmark constraints","text":"<p>Computes a set of landmarks in each state using the LM-cut method. For each landmark L the constraint sum_{o in L} Count_o &gt;= 1 is added to the operator-counting LP temporarily. After the heuristic value for the state is computed, all temporary constraints are removed again. For details, see</p> <ul> <li> <p>Florian Pommerening, Gabriele Roeger, Malte Helmert and Blai Bonet. LP-based Heuristics for Cost-optimal Planning.  In Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS 2014), pp. 226-234. AAAI Press, 2014.</p> </li> <li> <p>Blai Bonet. An admissible heuristic for SAS+ planning obtained from the state equation.  In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI 2013), pp. 2268-2274. AAAI Press, 2013.</p> </li> </ul> <pre><code>lmcut_constraints()\n</code></pre>"},{"location":"search/ConstraintGenerator/#saturated_posthoc_optimization_constraints_for_abstractions","title":"(Saturated) posthoc optimization constraints for abstractions","text":"<pre><code>pho_abstraction_constraints(abstractions=&lt;none&gt;, saturated=true)\n</code></pre> <ul> <li>abstractions (list of AbstractionGenerator): abstraction generation methods</li> <li>saturated (bool): use saturated instead of full operator costs in constraints</li> </ul>"},{"location":"search/ConstraintGenerator/#posthoc_optimization_constraints","title":"Posthoc optimization constraints","text":"<p>The generator will compute a PDB for each pattern and add the constraint h(s) &lt;= sum_{o in relevant(h)} Count_o. For details, see</p> <ul> <li>Florian Pommerening, Gabriele Roeger and Malte Helmert. Getting the Most Out of Pattern Databases for Classical Planning.  In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI 2013), pp. 2357-2364. AAAI Press, 2013.</li> </ul> <pre><code>pho_constraints(patterns=systematic(2))\n</code></pre> <ul> <li>patterns (PatternCollectionGenerator): pattern generation method</li> </ul>"},{"location":"search/ConstraintGenerator/#state_equation_constraints","title":"State equation constraints","text":"<p>For each fact, a permanent constraint is added that considers the net change of the fact, i.e., the total number of times the fact is added minus the total number of times is removed. The bounds of each constraint depend on the current state and the goal state and are updated in each state. For details, see</p> <ul> <li> <p>Menkes van den Briel, J. Benton, Subbarao Kambhampati and Thomas Vossen. An LP-based heuristic for optimal planning.  In Proceedings of the Thirteenth International Conference on Principles and Practice of Constraint Programming (CP 2007), pp. 651-665. Springer-Verlag, 2007.</p> </li> <li> <p>Blai Bonet. An admissible heuristic for SAS+ planning obtained from the state equation.  In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI 2013), pp. 2268-2274. AAAI Press, 2013.</p> </li> <li> <p>Florian Pommerening, Gabriele Roeger, Malte Helmert and Blai Bonet. LP-based Heuristics for Cost-optimal Planning.  In Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS 2014), pp. 226-234. AAAI Press, 2014.</p> </li> </ul> <pre><code>state_equation_constraints(verbosity=normal)\n</code></pre> <ul> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/Evaluator/","title":"Evaluator","text":"<p>An evaluator specification is either a newly created evaluator instance or an evaluator that has been defined previously. This page describes how one can specify a new evaluator instance.</p> <p>For evaluators that are heuristic, it is stated which of the following properties hold:</p> <ul> <li>admissible: h(s) &lt;= h*(s) for all states s</li> <li>consistent: h(s) &lt;= c(s, s') + h(s') for all states s connected to states s' by an action with cost c(s, s')</li> <li>safe: h(s) = infinity is only true for states with h*(s) = infinity</li> <li>preferred operators: this heuristic identifies preferred operators </li> </ul> <p>This feature type can be bound to variables using <code>let(variable_name, variable_definition, expression)</code> where <code>expression</code> can use <code>variable_name</code>. Predefinitions using <code>--evaluator</code>, <code>--heuristic</code>, and <code>--landmarks</code> are automatically transformed into <code>let</code>-expressions but are deprecated. (See search plugin syntax)</p>"},{"location":"search/Evaluator/#additive_heuristic","title":"Additive heuristic","text":"<pre><code>add(axioms=approximate_negative_cycles, transform=no_transform(), cache_estimates=true, description=\"add\", verbosity=normal)\n</code></pre> <ul> <li>axioms ({approximate_negative, approximate_negative_cycles}): How to compute axioms that describe how the negated (=default) value of a derived variable can be achieved.<ul> <li><code>approximate_negative</code>: Overapproximate negated axioms for all derived variables by setting an empty condition, indicating the default value can always be achieved for free.</li> <li><code>approximate_negative_cycles</code>: Overapproximate negated axioms for all derived variables which have cyclic dependencies by setting an empty condition, indicating the default value can always be achieved for free. For all other derived variables, the negated axioms are computed exactly. Note that this can potentially lead to a combinatorial explosion.</li> </ul> </li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: supported</li> <li>axioms: supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: no</li> <li>consistent: no</li> <li>safe: yes</li> <li>preferred operators: yes</li> </ul>"},{"location":"search/Evaluator/#blind_heuristic","title":"Blind heuristic","text":"<p>Returns cost of cheapest action for non-goal states, 0 for goal states <pre><code>blind(transform=no_transform(), cache_estimates=true, description=\"blind\", verbosity=normal)\n</code></pre></p> <ul> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: supported</li> <li>axioms: supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#context-enhanced_additive_heuristic","title":"Context-enhanced additive heuristic","text":"<pre><code>cea(axioms=approximate_negative_cycles, transform=no_transform(), cache_estimates=true, description=\"cea\", verbosity=normal)\n</code></pre> <ul> <li>axioms ({approximate_negative, approximate_negative_cycles}): How to compute axioms that describe how the negated (=default) value of a derived variable can be achieved.<ul> <li><code>approximate_negative</code>: Overapproximate negated axioms for all derived variables by setting an empty condition, indicating the default value can always be achieved for free.</li> <li><code>approximate_negative_cycles</code>: Overapproximate negated axioms for all derived variables which have cyclic dependencies by setting an empty condition, indicating the default value can always be achieved for free. For all other derived variables, the negated axioms are computed exactly. Note that this can potentially lead to a combinatorial explosion.</li> </ul> </li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: supported</li> <li>axioms: supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: no</li> <li>consistent: no</li> <li>safe: no</li> <li>preferred operators: yes</li> </ul>"},{"location":"search/Evaluator/#additive_cartesian_cegar_heuristic","title":"Additive Cartesian CEGAR heuristic","text":"<p>See the paper introducing counterexample-guided Cartesian abstraction refinement (CEGAR) for classical planning:</p> <ul> <li>Jendrik Seipp and Malte Helmert. Counterexample-guided Cartesian Abstraction Refinement.  In Proceedings of the 23rd International Conference on Automated Planning and Scheduling (ICAPS 2013), pp. 347-351. AAAI Press, 2013.</li> </ul> <p>and the paper showing how to make the abstractions additive:</p> <ul> <li>Jendrik Seipp and Malte Helmert. Diverse and Additive Cartesian Abstraction Heuristics.  In Proceedings of the 24th International Conference on Automated Planning and Scheduling (ICAPS 2014), pp. 289-297. AAAI Press, 2014.</li> </ul> <p>For more details on Cartesian CEGAR and saturated cost partitioning, see the journal paper</p> <ul> <li>Jendrik Seipp and Malte Helmert. Counterexample-Guided Cartesian Abstraction Refinement for Classical Planning. Journal of Artificial Intelligence Research 62:535-577. 2018.</li> </ul> <p>For a description of the incremental search, see the paper</p> <ul> <li>Jendrik Seipp, Samuel von Allmen and Malte Helmert. Incremental Search for Counterexample-Guided Cartesian Abstraction Refinement.  In Proceedings of the 30th International Conference on Automated Planning and Scheduling (ICAPS 2020), pp. 244-248. AAAI Press, 2020.</li> </ul> <p>Finally, we describe advanced flaw selection strategies here:</p> <ul> <li>David Speck and Jendrik Seipp. New Refinement Strategies for Cartesian Abstractions.  In Proceedings of the 32nd International Conference on Automated Planning and Scheduling (ICAPS 2022), pp. to appear. AAAI Press, 2022.</li> </ul> <pre><code>cegar(subtasks=[landmarks(order=random), goals(order=random)], max_states=infinity, max_transitions=1M, max_time=infinity, sort_transitions=false, transition_representation=store, pick_flawed_abstract_state=batch_min_h, pick_split=max_cover, tiebreak_split=max_refined, max_concrete_states_per_abstract_state=infinity, max_state_expansions=1M, memory_padding=500, random_seed=-1, dot_graph_verbosity=silent, use_general_costs=true, transform=no_transform(), cache_estimates=true, description=\"cegar\", verbosity=normal)\n</code></pre> <ul> <li>subtasks (list of SubtaskGenerator): subtask generators</li> <li>max_states (int [1, infinity]): maximum sum of abstract states over all abstractions</li> <li>max_transitions (int [0, infinity]): If transition_representation=store, this value limits the maximum sum of state-changing transitions (excluding self-loops) over all abstractions. Otherwise, this value limits the number of cached transitions in the shortest path tree of each abstraction individually.</li> <li>max_time (double [0.0, infinity]): maximum time in seconds for building abstractions</li> <li>sort_transitions (bool): sort transitions to ensure the different transition system representations yield the same abstractions</li> <li>transition_representation ({store, compute}): how to compute transitions between abstract states<ul> <li><code>store</code>: store transitions</li> <li><code>compute</code>: efficiently compute transitions on demand</li> </ul> </li> <li>pick_flawed_abstract_state ({first, first_on_shortest_path, random, min_h, max_h, batch_min_h}): flaw-selection strategy<ul> <li><code>first</code>: Consider first encountered flawed abstract state and a random concrete state.</li> <li><code>first_on_shortest_path</code>: Follow the arbitrary solution in the shortest path tree (no flaw search). Consider first encountered flawed abstract state and a random concrete state.</li> <li><code>random</code>: Collect all flawed abstract states and then consider a random abstract state and a random concrete state.</li> <li><code>min_h</code>: Collect all flawed abstract states and then consider a random abstract state with minimum h value and a random concrete state.</li> <li><code>max_h</code>: Collect all flawed abstract states and then consider a random abstract state with maximum h value and a random concrete state.</li> <li><code>batch_min_h</code>: Collect all flawed abstract states and iteratively refine them (by increasing h value). Only start a new flaw search once all remaining flawed abstract states are refined. For each abstract state consider all concrete states.</li> </ul> </li> <li>pick_split ({random, min_unwanted, max_unwanted, min_refined, max_refined, min_hadd, max_hadd, min_cg, max_cg, max_cover}): split-selection strategy<ul> <li><code>random</code>: select a random variable (among all eligible variables)</li> <li><code>min_unwanted</code>: select an eligible variable which has the least unwanted values (number of values of v that land in the abstract state whose h-value will probably be raised) in the flaw state</li> <li><code>max_unwanted</code>: select an eligible variable which has the most unwanted values (number of values of v that land in the abstract state whose h-value will probably be raised) in the flaw state</li> <li><code>min_refined</code>: select an eligible variable which is the least refined (-1 * (remaining_values(v) / original_domain_size(v))) in the flaw state</li> <li><code>max_refined</code>: select an eligible variable which is the most refined (-1 * (remaining_values(v) / original_domain_size(v))) in the flaw state</li> <li><code>min_hadd</code>: select an eligible variable with minimal h^add(s_0) value over all facts that need to be removed from the flaw state</li> <li><code>max_hadd</code>: select an eligible variable with maximal h^add(s_0) value over all facts that need to be removed from the flaw state</li> <li><code>min_cg</code>: order by increasing position in partial ordering of causal graph</li> <li><code>max_cg</code>: order by decreasing position in partial ordering of causal graph</li> <li><code>max_cover</code>: compute split that covers the maximum number of flaws for several concrete states.</li> </ul> </li> <li>tiebreak_split ({random, min_unwanted, max_unwanted, min_refined, max_refined, min_hadd, max_hadd, min_cg, max_cg, max_cover}): split-selection strategy for breaking ties<ul> <li><code>random</code>: select a random variable (among all eligible variables)</li> <li><code>min_unwanted</code>: select an eligible variable which has the least unwanted values (number of values of v that land in the abstract state whose h-value will probably be raised) in the flaw state</li> <li><code>max_unwanted</code>: select an eligible variable which has the most unwanted values (number of values of v that land in the abstract state whose h-value will probably be raised) in the flaw state</li> <li><code>min_refined</code>: select an eligible variable which is the least refined (-1 * (remaining_values(v) / original_domain_size(v))) in the flaw state</li> <li><code>max_refined</code>: select an eligible variable which is the most refined (-1 * (remaining_values(v) / original_domain_size(v))) in the flaw state</li> <li><code>min_hadd</code>: select an eligible variable with minimal h^add(s_0) value over all facts that need to be removed from the flaw state</li> <li><code>max_hadd</code>: select an eligible variable with maximal h^add(s_0) value over all facts that need to be removed from the flaw state</li> <li><code>min_cg</code>: order by increasing position in partial ordering of causal graph</li> <li><code>max_cg</code>: order by decreasing position in partial ordering of causal graph</li> <li><code>max_cover</code>: compute split that covers the maximum number of flaws for several concrete states.</li> </ul> </li> <li>max_concrete_states_per_abstract_state (int [1, infinity]): maximum number of flawed concrete states stored per abstract state</li> <li>max_state_expansions (int [1, infinity]): maximum number of state expansions per flaw search if a flaw has already been found</li> <li>memory_padding (int [0, infinity]): amount of extra memory in MB to reserve for recovering from out-of-memory situations gracefully. When the memory runs out, we stop refining and start the search. Due to memory fragmentation, the memory used for building the abstraction (states, transitions, etc.) often can't be reused for things that require big continuous blocks of memory. It is for this reason that we require a rather large amount of memory padding by default.</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>dot_graph_verbosity ({silent, write_to_console, write_to_file}): verbosity of printing/writing dot graphs<ul> <li><code>silent</code>: </li> <li><code>write_to_console</code>: </li> <li><code>write_to_file</code>: </li> </ul> </li> <li>use_general_costs (bool): allow negative costs in cost partitioning</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported</li> <li>axioms: not supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#causal_graph_heuristic","title":"Causal graph heuristic","text":"<pre><code>cg(max_cache_size=1000000, axioms=approximate_negative_cycles, transform=no_transform(), cache_estimates=true, description=\"cg\", verbosity=normal)\n</code></pre> <ul> <li>max_cache_size (int [0, infinity]): maximum number of cached entries per variable (set to 0 to disable cache)</li> <li>axioms ({approximate_negative, approximate_negative_cycles}): How to compute axioms that describe how the negated (=default) value of a derived variable can be achieved.<ul> <li><code>approximate_negative</code>: Overapproximate negated axioms for all derived variables by setting an empty condition, indicating the default value can always be achieved for free.</li> <li><code>approximate_negative_cycles</code>: Overapproximate negated axioms for all derived variables which have cyclic dependencies by setting an empty condition, indicating the default value can always be achieved for free. For all other derived variables, the negated axioms are computed exactly. Note that this can potentially lead to a combinatorial explosion.</li> </ul> </li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: supported</li> <li>axioms: supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: no</li> <li>consistent: no</li> <li>safe: no</li> <li>preferred operators: yes</li> </ul>"},{"location":"search/Evaluator/#ff_heuristic","title":"FF heuristic","text":"<pre><code>ff(axioms=approximate_negative_cycles, transform=no_transform(), cache_estimates=true, description=\"ff\", verbosity=normal)\n</code></pre> <ul> <li>axioms ({approximate_negative, approximate_negative_cycles}): How to compute axioms that describe how the negated (=default) value of a derived variable can be achieved.<ul> <li><code>approximate_negative</code>: Overapproximate negated axioms for all derived variables by setting an empty condition, indicating the default value can always be achieved for free.</li> <li><code>approximate_negative_cycles</code>: Overapproximate negated axioms for all derived variables which have cyclic dependencies by setting an empty condition, indicating the default value can always be achieved for free. For all other derived variables, the negated axioms are computed exactly. Note that this can potentially lead to a combinatorial explosion.</li> </ul> </li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: supported</li> <li>axioms: supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: no</li> <li>consistent: no</li> <li>safe: yes</li> <li>preferred operators: yes</li> </ul>"},{"location":"search/Evaluator/#goal_count_heuristic","title":"Goal count heuristic","text":"<pre><code>goalcount(transform=no_transform(), cache_estimates=true, description=\"goalcount\", verbosity=normal)\n</code></pre> <ul> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: ignored by design</li> <li>conditional effects: supported</li> <li>axioms: supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: no</li> <li>consistent: no</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#hm_heuristic","title":"h^m heuristic","text":"<pre><code>hm(m=2, transform=no_transform(), cache_estimates=true, description=\"hm\", verbosity=normal)\n</code></pre> <ul> <li>m (int [1, infinity]): subset size</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: ignored</li> <li>axioms: ignored</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes for tasks without conditional effects or axioms</li> <li>consistent: yes for tasks without conditional effects or axioms</li> <li>safe: yes for tasks without conditional effects or axioms</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#max_heuristic","title":"Max heuristic","text":"<pre><code>hmax(axioms=approximate_negative_cycles, transform=no_transform(), cache_estimates=true, description=\"hmax\", verbosity=normal)\n</code></pre> <ul> <li>axioms ({approximate_negative, approximate_negative_cycles}): How to compute axioms that describe how the negated (=default) value of a derived variable can be achieved.<ul> <li><code>approximate_negative</code>: Overapproximate negated axioms for all derived variables by setting an empty condition, indicating the default value can always be achieved for free.</li> <li><code>approximate_negative_cycles</code>: Overapproximate negated axioms for all derived variables which have cyclic dependencies by setting an empty condition, indicating the default value can always be achieved for free. For all other derived variables, the negated axioms are computed exactly. Note that this can potentially lead to a combinatorial explosion.</li> </ul> </li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: supported</li> <li>axioms: supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes for tasks without axioms</li> <li>consistent: yes for tasks without axioms</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#landmark_cost_partitioning_heuristic","title":"Landmark cost partitioning heuristic","text":"<p>Landmark progression is implemented according to the following paper:</p> <ul> <li>Clemens B\u00fcchner, Thomas Keller, Salom\u00e9 Eriksson and Malte Helmert. Landmarks Progression in Heuristic Search.  In Proceedings of the Thirty-Third International Conference on Automated Planning and Scheduling (ICAPS 2023), pp. 70-79. AAAI Press, 2023.</li> </ul> <pre><code>landmark_cost_partitioning(lm_factory, pref=false, prog_goal=true, prog_gn=true, prog_r=true, transform=no_transform(), cache_estimates=true, description=\"landmark_cost_partitioning\", verbosity=normal, cost_partitioning=uniform, alm=true, lpsolver=cplex, scoring_function=max_heuristic_per_stolen_costs, random_seed=-1)\n</code></pre> <ul> <li>lm_factory (LandmarkFactory): the set of landmarks to use for this heuristic. The set of landmarks can be specified here, or predefined (see LandmarkFactory).</li> <li>pref (bool): enable preferred operators (see note below)</li> <li>prog_goal (bool): Use goal progression.</li> <li>prog_gn (bool): Use greedy-necessary ordering progression.</li> <li>prog_r (bool): Use reasonable ordering progression.</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> <li>cost_partitioning ({optimal, uniform, opportunistic_uniform, greedy_zero_one, saturated, canonical, pho, saturated_pho}): strategy for partitioning operator costs among landmarks<ul> <li><code>optimal</code>: use optimal (LP-based) cost partitioning</li> <li><code>uniform</code>: partition operator costs uniformly among all landmarks achieved by that operator</li> <li><code>opportunistic_uniform</code>: like uniform, but order landmarks and reuse costs not consumed by earlier landmarks</li> <li><code>greedy_zero_one</code>: order landmarks and give each landmark the costs of all the operators it contains</li> <li><code>saturated</code>: like greedy_zero_one, but reuse costs not consumed by earlier landmarks</li> <li><code>canonical</code>: canonical heuristic over landmarks</li> <li><code>pho</code>: post-hoc optimization over landmarks</li> <li><code>saturated_pho</code>: saturated post-hoc optimization over landmarks</li> </ul> </li> <li>alm (bool): use action landmarks</li> <li>lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs<ul> <li><code>cplex</code>: commercial solver by IBM</li> <li><code>soplex</code>: open source solver by ZIB</li> </ul> </li> <li>scoring_function ({max_heuristic, min_stolen_costs, max_heuristic_per_stolen_costs}): metric for ordering abstractions/landmarks<ul> <li><code>max_heuristic</code>: order by decreasing heuristic value for the given state</li> <li><code>min_stolen_costs</code>: order by increasing sum of costs stolen from other heuristics</li> <li><code>max_heuristic_per_stolen_costs</code>: order by decreasing ratio of heuristic value divided by sum of stolen costs</li> </ul> </li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul> <p>Note: to use an LP solver, you must build the planner with LP support. See build instructions.</p> <p>Usage with A*: We recommend to add this heuristic as lazy_evaluator when using it in the A* algorithm. This way, the heuristic is recomputed before a state is expanded, leading to improved estimates that incorporate all knowledge gained from paths that were found after the state was inserted into the open list.</p> <p>Consistency: The heuristic is consistent along single paths if it is set as lazy_evaluator; i.e. when expanding s then we have h(s) &lt;= h(s')+cost(a) for all successors s' of s reached with a. But newly found paths to s can increase h(s), at which point the above inequality might not hold anymore.</p> <p>Optimal Cost Partitioning: To use <code>cost_partitioning=optimal</code>, you must build the planner with LP support. See build instructions.</p> <p>Preferred operators: Preferred operators should not be used for optimal planning. See Landmark sum heuristic for more information on using preferred operators; the comments there also apply to this heuristic.</p> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional_effects: supported if the LandmarkFactory supports them; otherwise not supported</li> <li>axioms: not allowed</li> </ul> <p>Properties:</p> <ul> <li>preferred operators: yes (if enabled; see <code>pref</code> option)</li> <li>admissible: yes</li> <li>consistent: no; see document note about consistency</li> <li>safe: yes</li> </ul>"},{"location":"search/Evaluator/#landmark_sum_heuristic","title":"Landmark sum heuristic","text":"<p>Landmark progression is implemented according to the following paper:</p> <ul> <li>Clemens B\u00fcchner, Thomas Keller, Salom\u00e9 Eriksson and Malte Helmert. Landmarks Progression in Heuristic Search.  In Proceedings of the Thirty-Third International Conference on Automated Planning and Scheduling (ICAPS 2023), pp. 70-79. AAAI Press, 2023.</li> </ul> <pre><code>landmark_sum(lm_factory, pref=false, prog_goal=true, prog_gn=true, prog_r=true, transform=no_transform(), cache_estimates=true, description=\"landmark_sum_heuristic\", verbosity=normal, axioms=approximate_negative_cycles)\n</code></pre> <ul> <li>lm_factory (LandmarkFactory): the set of landmarks to use for this heuristic. The set of landmarks can be specified here, or predefined (see LandmarkFactory).</li> <li>pref (bool): enable preferred operators (see note below)</li> <li>prog_goal (bool): Use goal progression.</li> <li>prog_gn (bool): Use greedy-necessary ordering progression.</li> <li>prog_r (bool): Use reasonable ordering progression.</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> <li>axioms ({approximate_negative, approximate_negative_cycles}): How to compute axioms that describe how the negated (=default) value of a derived variable can be achieved.<ul> <li><code>approximate_negative</code>: Overapproximate negated axioms for all derived variables by setting an empty condition, indicating the default value can always be achieved for free.</li> <li><code>approximate_negative_cycles</code>: Overapproximate negated axioms for all derived variables which have cyclic dependencies by setting an empty condition, indicating the default value can always be achieved for free. For all other derived variables, the negated axioms are computed exactly. Note that this can potentially lead to a combinatorial explosion.</li> </ul> </li> </ul> <p>Note on performance for satisficing planning: The cost of a landmark is based on the cost of the operators that achieve it. For satisficing search this can be counterproductive since it is often better to focus on distance from goal (i.e. length of the plan) rather than cost. In experiments we achieved the best performance using the option 'transform=adapt_costs(one)' to enforce unit costs.</p> <p>Preferred operators: Computing preferred operators is only enabled when setting pref=true because it has a nontrivial runtime cost. Using the heuristic for preferred operators without setting pref=true has no effect. Our implementation to compute preferred operators based on landmarks differs from the description in the literature (see reference above). The original implementation computes two kinds of preferred operators:</p> <ol> <li>If there is an applicable operator that reaches a landmark, all such operators are preferred.</li> <li>If no such operators exist, perform an FF-style relaxed exploration towards the nearest landmarks (according to the landmark orderings) and use the preferred operators of this exploration.</li> </ol> <p>Our implementation only considers preferred operators of the first type and does not include the second type. The rationale for this change is that it reduces code complexity and helps more cleanly separate landmark-based and FF-based computations in LAMA-like planner configurations. In our experiments, only considering preferred operators of the first type reduces performance when using the heuristic and its preferred operators in isolation but improves performance when using this heuristic in conjunction with the FF heuristic, as in LAMA-like planner configurations.</p> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional_effects: supported if the LandmarkFactory supports them; otherwise ignored</li> <li>axioms: supported</li> </ul> <p>Properties:</p> <ul> <li>preferred operators: yes (if enabled; see <code>pref</code> option)</li> <li>admissible: no</li> <li>consistent: no</li> <li>safe: yes except on tasks with conditional effects when using a LandmarkFactory not supporting them</li> </ul>"},{"location":"search/Evaluator/#landmark-cut_heuristic","title":"Landmark-cut heuristic","text":"<pre><code>lmcut(transform=no_transform(), cache_estimates=true, description=\"lmcut\", verbosity=normal)\n</code></pre> <ul> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported</li> <li>axioms: not supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: no</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#merge-and-shrink_heuristic","title":"Merge-and-shrink heuristic","text":"<p>This heuristic implements the algorithm described in the following paper:</p> <ul> <li>Silvan Sievers, Martin Wehrle and Malte Helmert. Generalized Label Reduction for Merge-and-Shrink Heuristics.  In Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI 2014), pp. 2358-2366. AAAI Press, 2014.</li> </ul> <p>For a more exhaustive description of merge-and-shrink, see the journal paper</p> <ul> <li>Silvan Sievers and Malte Helmert. Merge-and-Shrink: A Compositional Theory of Transformations of Factored Transition Systems. Journal of Artificial Intelligence Research 71:781-883. 2021.</li> </ul> <p>The following paper describes how to improve the DFP merge strategy with tie-breaking, and presents two new merge strategies (dyn-MIASM and SCC-DFP):</p> <ul> <li>Silvan Sievers, Martin Wehrle and Malte Helmert. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics.  In Proceedings of the 26th International Conference on Automated Planning and Scheduling (ICAPS 2016), pp. 294-298. AAAI Press, 2016.</li> </ul> <p>Details of the algorithms and the implementation are described in the paper</p> <ul> <li>Silvan Sievers. Merge-and-Shrink Heuristics for Classical Planning: Efficient Implementation and Partial Abstractions.  In Proceedings of the 11th Annual Symposium on Combinatorial Search (SoCS 2018), pp. 90-98. AAAI Press, 2018.</li> </ul> <pre><code>merge_and_shrink(merge_strategy, shrink_strategy, label_reduction=&lt;none&gt;, prune_unreachable_states=true, prune_irrelevant_states=true, max_states=-1, max_states_before_merge=-1, threshold_before_merge=-1, main_loop_max_time=infinity, transform=no_transform(), cache_estimates=true, description=\"merge_and_shrink\", verbosity=normal)\n</code></pre> <ul> <li>merge_strategy (MergeStrategy): See detailed documentation for merge strategies. We currently recommend SCC-DFP, which can be achieved using <code>merge_strategy=merge_sccs(order_of_sccs=topological,merge_selector=score_based_filtering(scoring_functions=[goal_relevance,dfp,total_order]))</code></li> <li>shrink_strategy (ShrinkStrategy): See detailed documentation for shrink strategies. We currently recommend non-greedy shrink_bisimulation, which can be achieved using <code>shrink_strategy=shrink_bisimulation(greedy=false)</code></li> <li>label_reduction (LabelReduction): See detailed documentation for labels. There is currently only one 'option' to use label_reduction, which is <code>label_reduction=exact</code> Also note the interaction with shrink strategies.</li> <li>prune_unreachable_states (bool): If true, prune abstract states unreachable from the initial state.</li> <li>prune_irrelevant_states (bool): If true, prune abstract states from which no goal state can be reached.</li> <li>max_states (int [-1, infinity]): maximum transition system size allowed at any time point.</li> <li>max_states_before_merge (int [-1, infinity]): maximum transition system size allowed for two transition systems before being merged to form the synchronized product.</li> <li>threshold_before_merge (int [-1, infinity]): If a transition system, before being merged, surpasses this soft transition system size limit, the shrink strategy is called to possibly shrink the transition system.</li> <li>main_loop_max_time (double [0.0, infinity]): A limit in seconds on the runtime of the main loop of the algorithm. If the limit is exceeded, the algorithm terminates, potentially returning a factored transition system with several factors. Also note that the time limit is only checked between transformations of the main loop, but not during, so it can be exceeded if a transformation is runtime-intense.</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note: Conditional effects are supported directly. Note, however, that for tasks that are not factored (in the sense of the JACM 2014 merge-and-shrink paper), the atomic transition systems on which merge-and-shrink heuristics are based are nondeterministic, which can lead to poor heuristics even when only perfect shrinking is performed.</p> <p>Note: When pruning unreachable states, admissibility and consistency is only guaranteed for reachable states and transitions between reachable states. While this does not impact regular A* search which will never encounter any unreachable state, it impacts techniques like symmetry-based pruning: a reachable state which is mapped to an unreachable symmetric state (which hence is pruned) would falsely be considered a dead-end and also be pruned, thus violating optimality of the search.</p> <p>Note: When using a time limit on the main loop of the merge-and-shrink algorithm, the heuristic will compute the maximum over all heuristics induced by the remaining factors if terminating the merge-and-shrink algorithm early. Exception: if there is an unsolvable factor, it will be used as the exclusive heuristic since the problem is unsolvable.</p> <p>Note: A currently recommended good configuration uses bisimulation based shrinking, the merge strategy SCC-DFP, and the appropriate label reduction setting (max_states has been altered to be between 10k and 200k in the literature). As merge-and-shrink heuristics can be expensive to compute, we also recommend limiting time by setting <code>main_loop_max_time</code> to a finite value. A sensible value would be half of the time allocated for the planner. <pre><code>merge_and_shrink(\n   merge_strategy=merge_sccs(\n       order_of_sccs=topological,\n       merge_selector=score_based_filtering(\n           scoring_functions=[goal_relevance(),dfp(),total_order()])),\n   shrink_strategy=shrink_bisimulation(greedy=false),\n   label_reduction=exact(before_shrinking=true,before_merging=false),\n   max_states=50k,\n   threshold_before_merge=1)\n</code></pre></p> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: supported (but see note)</li> <li>axioms: not supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes (but see note)</li> <li>consistent: yes (but see note)</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#novelty_evaluator","title":"Novelty evaluator","text":"<p>Computes the novelty w(s) of a state s given the partition functions evals=\u27e8h_1, ..., h_n\u27e9 as the size of the smallest set of atoms A such that s is the first evaluated state that subsumes A, among all states s' visited before s for which h_i(s) = h_i(s') for 1 \u2264 i \u2264 n. Best-First Width Search (BFWS) was introduced in </p> <ul> <li>Nir Lipovetzky and Hector Geffner. Best-First Width Search: Exploration and Exploitation in Classical Planning.  In Proceedings of the Thirty-First AAAI Conference on Artificial Intelligence (AAAI-17), pp. 3590-3596. AAAI Press, 2017.</li> </ul> <p>and BFWS was integrated into Scorpion in</p> <ul> <li>Augusto B. Corr\u00eaa and Jendrik Seipp. Alternation-Based Novelty Search.  In Proceedings of the 35th International Conference on Automated Planning and Scheduling (ICAPS 2025), pp. to appear. AAAI Press, 2025.</li> </ul> <pre><code>novelty(width=2, evals=[const()], consider_only_novel_states=true, max_variables_for_width2=100, transform=no_transform(), cache_estimates=true, description=\"novelty\", verbosity=normal)\n</code></pre> <ul> <li>width (int [1, 2]): maximum conjunction size</li> <li>evals (list of Evaluator): evaluators</li> <li>consider_only_novel_states (bool): assign infinity to non-novel states</li> <li>max_variables_for_width2 (int [0, infinity]): if there are more variables, use width=1</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: ignored by design</li> <li>conditional effects: supported</li> <li>axioms: supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: no</li> <li>consistent: no</li> <li>safe: if consider_only_novel_states=false</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#operator-counting_heuristic","title":"Operator-counting heuristic","text":"<p>An operator-counting heuristic computes a linear program (LP) in each state. The LP has one variable Count_o for each operator o that represents how often the operator is used in a plan. Operator-counting constraints are linear constraints over these varaibles that are guaranteed to have a solution with Count_o = occurrences(o, pi) for every plan pi. Minimizing the total cost of operators subject to some operator-counting constraints is an admissible heuristic. For details, see</p> <ul> <li>Florian Pommerening, Gabriele Roeger, Malte Helmert and Blai Bonet. LP-based Heuristics for Cost-optimal Planning.  In Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS 2014), pp. 226-234. AAAI Press, 2014.</li> </ul> <pre><code>operatorcounting(constraint_generators, use_integer_operator_counts=false, lpsolver=cplex, transform=no_transform(), cache_estimates=true, description=\"operatorcounting\", verbosity=normal)\n</code></pre> <ul> <li>constraint_generators (list of ConstraintGenerator): methods that generate constraints over operator-counting variables</li> <li>use_integer_operator_counts (bool): restrict operator-counting variables to integer values. Computing the heuristic with integer variables can produce higher values but requires solving a MIP instead of an LP which is generally more computationally expensive. Turning this option on can thus drastically increase the runtime.</li> <li>lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs<ul> <li><code>cplex</code>: commercial solver by IBM</li> <li><code>soplex</code>: open source solver by ZIB</li> </ul> </li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note: to use an LP solver, you must build the planner with LP support. See build instructions.</p> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented constraint generators do)</li> <li>axioms: not supported (the heuristic supports them in theory, but none of the currently implemented constraint generators do)</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes, if all constraint generators represent consistent heuristics</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#basic_evaluators","title":"Basic evaluators","text":""},{"location":"search/Evaluator/#constant_evaluator","title":"Constant evaluator","text":"<p>Returns a constant value. <pre><code>const(value=1, description=\"const\", verbosity=normal)\n</code></pre></p> <ul> <li>value (int [0, infinity]): the constant value</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/Evaluator/#g-value_evaluator","title":"g-value evaluator","text":"<p>Returns the g-value (path cost) of the search node. <pre><code>g(description=\"g\", verbosity=normal)\n</code></pre></p> <ul> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/Evaluator/#max_evaluator","title":"Max evaluator","text":"<p>Calculates the maximum of the sub-evaluators. <pre><code>max(evals, description=\"max\", verbosity=normal)\n</code></pre></p> <ul> <li>evals (list of Evaluator): at least one evaluator</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/Evaluator/#preference_evaluator","title":"Preference evaluator","text":"<p>Returns 0 if preferred is true and 1 otherwise. <pre><code>pref(description=\"pref\", verbosity=normal)\n</code></pre></p> <ul> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/Evaluator/#sum_evaluator","title":"Sum evaluator","text":"<p>Calculates the sum of the sub-evaluators. <pre><code>sum(evals, description=\"sum\", verbosity=normal)\n</code></pre></p> <ul> <li>evals (list of Evaluator): at least one evaluator</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/Evaluator/#weighted_evaluator","title":"Weighted evaluator","text":"<p>Multiplies the value of the evaluator with the given weight. <pre><code>weight(eval, weight, description=\"weight\", verbosity=normal)\n</code></pre></p> <ul> <li>eval (Evaluator): evaluator</li> <li>weight (int): weight</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/Evaluator/#cost_partitioning_heuristics","title":"Cost Partitioning Heuristics","text":""},{"location":"search/Evaluator/#canonical_heuristic_over_abstractions","title":"Canonical heuristic over abstractions","text":"<p>Shuffle abstractions randomly. <pre><code>canonical_heuristic(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], transform=no_transform(), cache_estimates=true, description=\"canonical_heuristic\", verbosity=normal)\n</code></pre></p> <ul> <li>abstractions (list of AbstractionGenerator): abstraction generators</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> <li>axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#greedy_zero-one_cost_partitioning","title":"Greedy zero-one cost partitioning","text":"<pre><code>gzocp(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], transform=no_transform(), cache_estimates=true, description=\"gzocp\", verbosity=normal, orders=greedy_orders(), max_orders=infinity, max_size=infinity, max_time=200, diversify=true, samples=1000, max_optimization_time=2, random_seed=-1)\n</code></pre> <ul> <li>abstractions (list of AbstractionGenerator): abstraction generators</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> <li>orders (OrderGenerator): order generator</li> <li>max_orders (int [0, infinity]): maximum number of orders</li> <li>max_size (int [0, infinity]): maximum heuristic size in KiB</li> <li>max_time (double [0, infinity]): maximum time in seconds for finding orders</li> <li>diversify (bool): only keep orders that have a higher heuristic value than all previous orders for any of the samples</li> <li>samples (int [1, infinity]): number of samples for diversification</li> <li>max_optimization_time (double [0, infinity]): maximum time in seconds for optimizing each order with hill climbing</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> <li>axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#maximum_over_abstractions","title":"Maximum over abstractions","text":"<p>Maximize over a set of abstraction heuristics. <pre><code>maximize(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], transform=no_transform(), cache_estimates=true, description=\"maximize\", verbosity=normal)\n</code></pre></p> <ul> <li>abstractions (list of AbstractionGenerator): abstraction generators</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> <li>axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#optimal_cost_partitioning_heuristic","title":"Optimal cost partitioning heuristic","text":"<p>Compute an optimal cost partitioning for each evaluated state. <pre><code>ocp(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], transform=no_transform(), cache_estimates=true, description=\"ocp\", verbosity=normal, lpsolver=cplex, allow_negative_costs=true)\n</code></pre></p> <ul> <li>abstractions (list of AbstractionGenerator): abstraction generators</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> <li>lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs<ul> <li><code>cplex</code>: commercial solver by IBM</li> <li><code>soplex</code>: open source solver by ZIB</li> </ul> </li> <li>allow_negative_costs (bool): use general instead of non-negative cost partitioning</li> </ul> <p>Note: to use an LP solver, you must build the planner with LP support. See build instructions.</p> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> <li>axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#post-hoc_optimization_heuristic","title":"Post-hoc optimization heuristic","text":"<p>Compute the maximum over multiple PhO heuristics precomputed offline. <pre><code>pho(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], transform=no_transform(), cache_estimates=true, description=\"pho\", verbosity=normal, saturated=true, orders=greedy_orders(), max_orders=infinity, max_size=infinity, max_time=200, diversify=true, samples=1000, max_optimization_time=2, random_seed=-1, lpsolver=cplex)\n</code></pre></p> <ul> <li>abstractions (list of AbstractionGenerator): abstraction generators</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> <li>saturated (bool): saturate costs</li> <li>orders (OrderGenerator): order generator</li> <li>max_orders (int [0, infinity]): maximum number of orders</li> <li>max_size (int [0, infinity]): maximum heuristic size in KiB</li> <li>max_time (double [0, infinity]): maximum time in seconds for finding orders</li> <li>diversify (bool): only keep orders that have a higher heuristic value than all previous orders for any of the samples</li> <li>samples (int [1, infinity]): number of samples for diversification</li> <li>max_optimization_time (double [0, infinity]): maximum time in seconds for optimizing each order with hill climbing</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs<ul> <li><code>cplex</code>: commercial solver by IBM</li> <li><code>soplex</code>: open source solver by ZIB</li> </ul> </li> </ul> <p>Note: to use an LP solver, you must build the planner with LP support. See build instructions.</p> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> <li>axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#saturated_cost_partitioning","title":"Saturated cost partitioning","text":"<p>Compute the maximum over multiple saturated cost partitioning heuristics using different orders. For details, see </p> <ul> <li>Jendrik Seipp, Thomas Keller and Malte Helmert. Saturated Cost Partitioning for Optimal Classical Planning. Journal of Artificial Intelligence Research 67:129-167. 2020.</li> </ul> <pre><code>scp(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], transform=no_transform(), cache_estimates=true, description=\"scp\", verbosity=normal, saturator=all, orders=greedy_orders(), max_orders=infinity, max_size=infinity, max_time=200, diversify=true, samples=1000, max_optimization_time=2, random_seed=-1)\n</code></pre> <ul> <li>abstractions (list of AbstractionGenerator): abstraction generators</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> <li>saturator ({all, perim, perimstar}): function that computes saturated cost functions<ul> <li><code>all</code>: preserve estimates of all states</li> <li><code>perim</code>: preserve estimates of states in perimeter around goal</li> <li><code>perimstar</code>: compute 'perim' first and then 'all' with remaining costs</li> </ul> </li> <li>orders (OrderGenerator): order generator</li> <li>max_orders (int [0, infinity]): maximum number of orders</li> <li>max_size (int [0, infinity]): maximum heuristic size in KiB</li> <li>max_time (double [0, infinity]): maximum time in seconds for finding orders</li> <li>diversify (bool): only keep orders that have a higher heuristic value than all previous orders for any of the samples</li> <li>samples (int [1, infinity]): number of samples for diversification</li> <li>max_optimization_time (double [0, infinity]): maximum time in seconds for optimizing each order with hill climbing</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul> <p>Difference to cegar(): The cegar() plugin computes a single saturated cost partitioning over Cartesian abstraction heuristics. In contrast, saturated_cost_partitioning() supports computing the maximum over multiple saturated cost partitionings using different heuristic orders, and it supports both Cartesian abstraction heuristics and pattern database heuristics. While cegar() interleaves abstraction computation with cost partitioning, saturated_cost_partitioning() computes all abstractions using the original costs.</p> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> <li>axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#online_saturated_cost_partitioning","title":"Online saturated cost partitioning","text":"<p>Compute the maximum over multiple saturated cost partitioning heuristics diversified during the search. For details, see </p> <ul> <li>Jendrik Seipp. Online Saturated Cost Partitioning for Classical Planning.  In Proceedings of the 31st International Conference on Automated Planning and Scheduling (ICAPS 2021), pp. 317-321. AAAI Press, 2021.</li> </ul> <pre><code>scp_online(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], transform=no_transform(), cache_estimates=true, description=\"scp_online\", verbosity=normal, saturator=all, orders=greedy_orders(), max_size=infinity, max_time=200, interval=10K, debug=false, random_seed=-1)\n</code></pre> <ul> <li>abstractions (list of AbstractionGenerator): abstraction generators</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> <li>saturator ({all, perim, perimstar}): function that computes saturated cost functions<ul> <li><code>all</code>: preserve estimates of all states</li> <li><code>perim</code>: preserve estimates of states in perimeter around goal</li> <li><code>perimstar</code>: compute 'perim' first and then 'all' with remaining costs</li> </ul> </li> <li>orders (OrderGenerator): order generator</li> <li>max_size (int [0, infinity]): maximum (estimated) heuristic size in KiB</li> <li>max_time (double [0, infinity]): maximum time in seconds for finding orders</li> <li>interval (int [1, infinity]): select every i-th evaluated state for online diversification</li> <li>debug (bool): print debug output</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> <li>axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: no</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#opportunistic_uniform_cost_partitioning","title":"(Opportunistic) uniform cost partitioning","text":"<ul> <li>Jendrik Seipp, Thomas Keller and Malte Helmert. A Comparison of Cost Partitioning Algorithms for Optimal Classical Planning.  In Proceedings of the Twenty-Seventh International Conference on Automated Planning and Scheduling (ICAPS 2017), pp. 259-268. AAAI Press, 2017.</li> </ul> <pre><code>ucp(abstractions=[projections(hillclimbing(max_time=60)), projections(systematic(2)), cartesian()], transform=no_transform(), cache_estimates=true, description=\"ucp\", verbosity=normal, orders=greedy_orders(), max_orders=infinity, max_size=infinity, max_time=200, diversify=true, samples=1000, max_optimization_time=2, random_seed=-1, opportunistic=false, debug=false)\n</code></pre> <ul> <li>abstractions (list of AbstractionGenerator): abstraction generators</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> <li>orders (OrderGenerator): order generator</li> <li>max_orders (int [0, infinity]): maximum number of orders</li> <li>max_size (int [0, infinity]): maximum heuristic size in KiB</li> <li>max_time (double [0, infinity]): maximum time in seconds for finding orders</li> <li>diversify (bool): only keep orders that have a higher heuristic value than all previous orders for any of the samples</li> <li>samples (int [1, infinity]): number of samples for diversification</li> <li>max_optimization_time (double [0, infinity]): maximum time in seconds for optimizing each order with hill climbing</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>opportunistic (bool): recalculate uniform cost partitioning after each considered abstraction</li> <li>debug (bool): print debugging messages</li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> <li>axioms: not supported (the heuristic supports them in theory, but none of the currently implemented abstraction generators do)</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#pattern_database_heuristics","title":"Pattern database heuristics","text":""},{"location":"search/Evaluator/#canonical_pdb","title":"Canonical PDB","text":"<p>The canonical pattern database heuristic is calculated as follows. For a given pattern collection C, the value of the canonical heuristic function is the maximum over all maximal additive subsets A in C, where the value for one subset S in A is the sum of the heuristic values for all patterns in S for a given state. <pre><code>cpdbs(patterns=systematic(1), max_time_dominance_pruning=infinity, transform=no_transform(), cache_estimates=true, description=\"cpdbs\", verbosity=normal)\n</code></pre></p> <ul> <li>patterns (PatternCollectionGenerator): pattern generation method</li> <li>max_time_dominance_pruning (double [0.0, infinity]): The maximum time in seconds spent on dominance pruning. Using 0.0 turns off dominance pruning. Dominance pruning excludes patterns and additive subsets that will never contribute to the heuristic value because there are dominating subsets in the collection.</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported</li> <li>axioms: not supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#ipdb","title":"iPDB","text":"<p>This approach is a combination of using the Canonical PDB heuristic over patterns computed with the Hill Climbing algorithm for pattern generation. It is a short-hand for the command-line option <code>cpdbs(hillclimbing())</code>. Both the heuristic and the pattern generation algorithm are described in the following paper:</p> <ul> <li>Patrik Haslum, Adi Botea, Malte Helmert, Blai Bonet and Sven Koenig. Domain-Independent Construction of Pattern Database Heuristics for Cost-Optimal Planning.  In Proceedings of the 22nd AAAI Conference on Artificial Intelligence (AAAI 2007), pp. 1007-1012. AAAI Press, 2007.</li> </ul> <p>For implementation notes, see:</p> <ul> <li>Silvan Sievers, Manuela Ortlieb and Malte Helmert. Efficient Implementation of Pattern Database Heuristics for Classical Planning.  In Proceedings of the Fifth Annual Symposium on Combinatorial Search (SoCS 2012), pp. 105-111. AAAI Press, 2012.</li> </ul> <p>See also Canonical PDB and Hill climbing for more details. <pre><code>ipdb(pdb_max_size=2000000, collection_max_size=20000000, num_samples=1000, min_improvement=10, max_time=infinity, random_seed=-1, max_time_dominance_pruning=infinity, transform=no_transform(), cache_estimates=true, description=\"cpdbs\", verbosity=normal)\n</code></pre></p> <ul> <li>pdb_max_size (int [1, infinity]): maximal number of states per pattern database </li> <li>collection_max_size (int [1, infinity]): maximal number of states in the pattern collection</li> <li>num_samples (int [1, infinity]): number of samples (random states) on which to evaluate each candidate pattern collection</li> <li>min_improvement (int [1, infinity]): minimum number of samples on which a candidate pattern collection must improve on the current one to be considered as the next pattern collection </li> <li>max_time (double [0.0, infinity]): maximum time in seconds for improving the initial pattern collection via hill climbing. If set to 0, no hill climbing is performed at all. Note that this limit only affects hill climbing. Use max_time_dominance_pruning to limit the time spent for pruning dominated patterns.</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>max_time_dominance_pruning (double [0.0, infinity]): The maximum time in seconds spent on dominance pruning. Using 0.0 turns off dominance pruning. Dominance pruning excludes patterns and additive subsets that will never contribute to the heuristic value because there are dominating subsets in the collection.</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note: The pattern collection created by the algorithm will always contain all patterns consisting of a single goal variable, even if this violates the pdb_max_size or collection_max_size limits.</p> <p>Note: This pattern generation method generates patterns optimized for use with the canonical pattern database heuristic.</p>"},{"location":"search/Evaluator/#implementation_notes","title":"Implementation notes","text":"<p>The following will very briefly describe the algorithm and explain the differences between the original implementation from 2007 and the new one in Fast Downward.</p> <p>The aim of the algorithm is to output a pattern collection for which the Canonical PDB yields the best heuristic estimates.</p> <p>The algorithm is basically a local search (hill climbing) which searches the \"pattern neighbourhood\" (starting initially with a pattern for each goal variable) for improving the pattern collection. This is done as described in the section \"pattern construction as search\" in the paper, except for the corrected search neighbourhood discussed below. For evaluating the neighbourhood, the \"counting approximation\" as introduced in the paper was implemented. An important difference however consists in the fact that this implementation computes all pattern databases for each candidate pattern rather than using A* search to compute the heuristic values only for the sample states for each pattern.</p> <p>Also the logic for sampling the search space differs a bit from the original implementation. The original implementation uses a random walk of a length which is binomially distributed with the mean at the estimated solution depth (estimation is done with the current pattern collection heuristic). In the Fast Downward implementation, also a random walk is used, where the length is the estimation of the number of solution steps, which is calculated by dividing the current heuristic estimate for the initial state by the average operator costs of the planning task (calculated only once and not updated during sampling!) to take non-unit cost problems into account. This yields a random walk of an expected lenght of np = 2 * estimated number of solution steps. If the random walk gets stuck, it is being restarted from the initial state, exactly as described in the original paper.</p> <p>The section \"avoiding redundant evaluations\" describes how the search neighbourhood of patterns can be restricted to variables that are relevant to the variables already included in the pattern by analyzing causal graphs. There is a mistake in the paper that leads to some relevant neighbouring patterns being ignored. See the errata for details. This mistake has been addressed in this implementation. The second approach described in the paper (statistical confidence interval) is not applicable to this implementation, as it doesn't use A* search but constructs the entire pattern databases for all candidate patterns anyway. The search is ended if there is no more improvement (or the improvement is smaller than the minimal improvement which can be set as an option), however there is no limit of iterations of the local search. This is similar to the techniques used in the original implementation as described in the paper.</p> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported</li> <li>axioms: not supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#pattern_database_heuristic","title":"Pattern database heuristic","text":"<p>Computes goal distance in state space abstractions based on projections. First used in domain-independent planning by:</p> <ul> <li>Stefan Edelkamp. Planning with Pattern Databases.  In Proceedings of the Sixth European Conference on Planning (ECP 2001), pp. 84-90. AAAI Press, 2001.</li> </ul> <p>For implementation notes, see:</p> <ul> <li>Silvan Sievers, Manuela Ortlieb and Malte Helmert. Efficient Implementation of Pattern Database Heuristics for Classical Planning.  In Proceedings of the Fifth Annual Symposium on Combinatorial Search (SoCS 2012), pp. 105-111. AAAI Press, 2012.</li> </ul> <pre><code>pdb(pattern=greedy(), transform=no_transform(), cache_estimates=true, description=\"pdb\", verbosity=normal)\n</code></pre> <ul> <li>pattern (PatternGenerator): pattern generation method</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported</li> <li>axioms: not supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#zero-one_pdb","title":"Zero-One PDB","text":"<p>The zero/one pattern database heuristic is simply the sum of the heuristic values of all patterns in the pattern collection. In contrast to the canonical pattern database heuristic, there is no need to check for additive subsets, because the additivity of the patterns is guaranteed by action cost partitioning. This heuristic uses the most simple form of action cost partitioning, i.e. if an operator affects more than one pattern in the collection, its costs are entirely taken into account for one pattern (the first one which it affects) and set to zero for all other affected patterns. <pre><code>zopdbs(patterns=systematic(1), transform=no_transform(), cache_estimates=true, description=\"zopdbs\", verbosity=normal)\n</code></pre></p> <ul> <li>patterns (PatternCollectionGenerator): pattern generation method</li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported</li> <li>axioms: not supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#potential_heuristics","title":"Potential heuristics","text":""},{"location":"search/Evaluator/#potential_heuristic_optimized_for_all_states","title":"Potential heuristic optimized for all states","text":"<p>The algorithm is based on</p> <ul> <li>Jendrik Seipp, Florian Pommerening and Malte Helmert. New Optimization Functions for Potential Heuristics.  In Proceedings of the 25th International Conference on Automated Planning and Scheduling (ICAPS 2015), pp. 193-201. AAAI Press, 2015.</li> </ul> <pre><code>all_states_potential(max_potential=1e8, lpsolver=cplex, transform=no_transform(), cache_estimates=true, description=\"all_states_potential\", verbosity=normal)\n</code></pre> <ul> <li>max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound <code>infinity</code> disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above.</li> <li>lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs<ul> <li><code>cplex</code>: commercial solver by IBM</li> <li><code>soplex</code>: open source solver by ZIB</li> </ul> </li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note: to use an LP solver, you must build the planner with LP support. See build instructions.</p> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported</li> <li>axioms: not supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#diverse_potential_heuristics","title":"Diverse potential heuristics","text":"<p>The algorithm is based on</p> <ul> <li>Jendrik Seipp, Florian Pommerening and Malte Helmert. New Optimization Functions for Potential Heuristics.  In Proceedings of the 25th International Conference on Automated Planning and Scheduling (ICAPS 2015), pp. 193-201. AAAI Press, 2015.</li> </ul> <pre><code>diverse_potentials(num_samples=1000, max_num_heuristics=infinity, max_potential=1e8, lpsolver=cplex, transform=no_transform(), cache_estimates=true, description=\"diverse_potentials\", verbosity=normal, random_seed=-1)\n</code></pre> <ul> <li>num_samples (int [0, infinity]): Number of states to sample</li> <li>max_num_heuristics (int [0, infinity]): maximum number of potential heuristics</li> <li>max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound <code>infinity</code> disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above.</li> <li>lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs<ul> <li><code>cplex</code>: commercial solver by IBM</li> <li><code>soplex</code>: open source solver by ZIB</li> </ul> </li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul> <p>Note: to use an LP solver, you must build the planner with LP support. See build instructions.</p> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported</li> <li>axioms: not supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#potential_heuristic_optimized_for_initial_state","title":"Potential heuristic optimized for initial state","text":"<p>The algorithm is based on</p> <ul> <li>Jendrik Seipp, Florian Pommerening and Malte Helmert. New Optimization Functions for Potential Heuristics.  In Proceedings of the 25th International Conference on Automated Planning and Scheduling (ICAPS 2015), pp. 193-201. AAAI Press, 2015.</li> </ul> <pre><code>initial_state_potential(max_potential=1e8, lpsolver=cplex, transform=no_transform(), cache_estimates=true, description=\"initial_state_potential\", verbosity=normal)\n</code></pre> <ul> <li>max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound <code>infinity</code> disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above.</li> <li>lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs<ul> <li><code>cplex</code>: commercial solver by IBM</li> <li><code>soplex</code>: open source solver by ZIB</li> </ul> </li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note: to use an LP solver, you must build the planner with LP support. See build instructions.</p> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported</li> <li>axioms: not supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/Evaluator/#sample-based_potential_heuristics","title":"Sample-based potential heuristics","text":"<p>Maximum over multiple potential heuristics optimized for samples. The algorithm is based on</p> <ul> <li>Jendrik Seipp, Florian Pommerening and Malte Helmert. New Optimization Functions for Potential Heuristics.  In Proceedings of the 25th International Conference on Automated Planning and Scheduling (ICAPS 2015), pp. 193-201. AAAI Press, 2015.</li> </ul> <pre><code>sample_based_potentials(num_heuristics=1, num_samples=1000, max_potential=1e8, lpsolver=cplex, transform=no_transform(), cache_estimates=true, description=\"sample_based_potentials\", verbosity=normal, random_seed=-1)\n</code></pre> <ul> <li>num_heuristics (int [0, infinity]): number of potential heuristics</li> <li>num_samples (int [0, infinity]): Number of states to sample</li> <li>max_potential (double [0.0, infinity]): Bound potentials by this number. Using the bound <code>infinity</code> disables the bounds. In some domains this makes the computation of weights unbounded in which case no weights can be extracted. Using very high weights can cause numerical instability in the LP solver, while using very low weights limits the choice of potential heuristics. For details, see the ICAPS paper cited above.</li> <li>lpsolver ({cplex, soplex}): external solver that should be used to solve linear programs<ul> <li><code>cplex</code>: commercial solver by IBM</li> <li><code>soplex</code>: open source solver by ZIB</li> </ul> </li> <li>transform (AbstractTask): Optional task transformation for the heuristic. Currently, adapt_costs() and no_transform() are available.</li> <li>cache_estimates (bool): cache heuristic estimates</li> <li>description (string): description used to identify evaluator in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul> <p>Note: to use an LP solver, you must build the planner with LP support. See build instructions.</p> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported</li> <li>axioms: not supported</li> </ul> <p>Properties:</p> <ul> <li>admissible: yes</li> <li>consistent: yes</li> <li>safe: yes</li> <li>preferred operators: no</li> </ul>"},{"location":"search/LabelReduction/","title":"LabelReduction","text":"<p>This page describes the current single 'option' for label reduction.</p>"},{"location":"search/LabelReduction/#exact_generalized_label_reduction","title":"Exact generalized label reduction","text":"<p>This class implements the exact generalized label reduction described in the following paper:</p> <ul> <li>Silvan Sievers, Martin Wehrle and Malte Helmert. Generalized Label Reduction for Merge-and-Shrink Heuristics.  In Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI 2014), pp. 2358-2366. AAAI Press, 2014.</li> </ul> <pre><code>exact(before_shrinking, before_merging, method=all_transition_systems_with_fixpoint, system_order=random, random_seed=-1)\n</code></pre> <ul> <li>before_shrinking (bool): apply label reduction before shrinking</li> <li>before_merging (bool): apply label reduction before merging</li> <li>method ({two_transition_systems, all_transition_systems, all_transition_systems_with_fixpoint}): Label reduction method. See the AAAI14 paper by Sievers et al. for explanation of the default label reduction method and the 'combinable relation' .Also note that you must set at least one of the options reduce_labels_before_shrinking or reduce_labels_before_merging in order to use the chosen label reduction configuration.<ul> <li><code>two_transition_systems</code>: compute the 'combinable relation' only for the two transition systems being merged next</li> <li><code>all_transition_systems</code>: compute the 'combinable relation' for labels once for every transition system and reduce labels</li> <li><code>all_transition_systems_with_fixpoint</code>: keep computing the 'combinable relation' for labels iteratively for all transition systems until no more labels can be reduced</li> </ul> </li> <li>system_order ({regular, reverse, random}): Order of transition systems for the label reduction methods that iterate over the set of all transition systems. Only useful for the choices all_transition_systems and all_transition_systems_with_fixpoint for the option label_reduction_method.<ul> <li><code>regular</code>: transition systems are considered in the order given in the planner input if atomic and in the order of their creation if composite.</li> <li><code>reverse</code>: inverse of regular</li> <li><code>random</code>: random order</li> </ul> </li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul>"},{"location":"search/LandmarkFactory/","title":"LandmarkFactory","text":"<p>A landmark factory specification is either a newly created instance or a landmark factory that has been defined previously. This page describes how one can specify a new landmark factory instance. For re-using landmark factories, see OptionSyntax#Landmark_Predefinitions.</p> <p>This feature type can be bound to variables using <code>let(variable_name, variable_definition, expression)</code> where <code>expression</code> can use <code>variable_name</code>. Predefinitions using <code>--evaluator</code>, <code>--heuristic</code>, and <code>--landmarks</code> are automatically transformed into <code>let</code>-expressions but are deprecated. (See search plugin syntax)</p>"},{"location":"search/LandmarkFactory/#exhaustive_landmarks","title":"Exhaustive landmarks","text":"<p>Exhaustively checks for each atom if it is a landmark.This check is done using relaxed planning. <pre><code>lm_exhaust(use_unary_relaxation=false, verbosity=normal)\n</code></pre></p> <ul> <li>use_unary_relaxation (bool): compute landmarks of the unary relaxation, i.e., landmarks for the delete relaxation of a task transformation such that each operator is split into one operator for each of its effects. This kind of landmarks was previously known as \"causal landmarks\". Setting the option to true can reduce the overall number of landmarks, which can make the search more memory-efficient but potentially less informative.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>conditional_effects: ignored, i.e. not supported</li> </ul>"},{"location":"search/LandmarkFactory/#hm_landmarks","title":"h^m landmarks","text":"<p>The landmark generation method introduced in the following paper</p> <ul> <li>Emil Keyder, Silvia Richter and Malte Helmert. Sound and Complete Landmarks for And/Or Graphs.  In Proceedings of the 19th European Conference on Artificial Intelligence (ECAI 2010), pp. 335-340. IOS Press, 2010.</li> </ul> <pre><code>lm_hm(m=2, conjunctive_landmarks=true, use_orders=true, verbosity=normal)\n</code></pre> <ul> <li>m (int): subset size (if unsure, use the default of 2)</li> <li>conjunctive_landmarks (bool): keep conjunctive landmarks</li> <li>use_orders (bool): use orders between landmarks</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>conditional_effects: ignored, i.e. not supported</li> </ul>"},{"location":"search/LandmarkFactory/#merged_landmarks","title":"Merged landmarks","text":"<p>Merges the landmarks and orderings from the parameter landmarks <pre><code>lm_merged(lm_factories, verbosity=normal)\n</code></pre></p> <ul> <li>lm_factories (list of LandmarkFactory): </li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Precedence: Fact landmarks take precedence over disjunctive landmarks, orderings take precedence in the usual manner (gn &gt; nat &gt; reas &gt; o_reas). </p> <p>Note: Does not currently support conjunctive landmarks</p> <p>Supported language features:</p> <ul> <li>conditional_effects: supported if all components support them</li> </ul>"},{"location":"search/LandmarkFactory/#hps_orders","title":"HPS orders","text":"<p>Adds reasonable orders described in the following paper</p> <ul> <li>J\u00f6rg Hoffmann, Julie Porteous and Laura Sebastia. Ordered Landmarks in Planning. Journal of Artificial Intelligence Research 22:215-278. 2004.</li> </ul> <pre><code>lm_reasonable_orders_hps(lm_factory, verbosity=normal)\n</code></pre> <ul> <li>lm_factory (LandmarkFactory): </li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Obedient-reasonable orders: Hoffmann et al. (2004) suggest obedient-reasonable orderings in addition to reasonable orders. Obedient-reasonable orders were later also used by the LAMA planner (Richter and Westphal, 2010). They are \"reasonable orders\" under the assumption that all (non-obedient) reasonable orders are actually \"natural\", i.e., every plan obeys the reasonable orders. We observed experimentally that obedient-reasonable orders have minimal effect on the performance of LAMA (B\u00fcchner et al., 2023) and decided to remove them in issue1089.</p> <p>Supported language features:</p> <ul> <li>conditional_effects: supported if subcomponent supports them</li> </ul>"},{"location":"search/LandmarkFactory/#rhw_landmarks","title":"RHW landmarks","text":"<p>The landmark generation method introduced by Richter, Helmert and Westphal (AAAI 2008). <pre><code>lm_rhw(disjunctive_landmarks=true, use_orders=true, verbosity=normal)\n</code></pre></p> <ul> <li>disjunctive_landmarks (bool): keep disjunctive landmarks</li> <li>use_orders (bool): use orders between landmarks</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>conditional_effects: supported</li> </ul>"},{"location":"search/LandmarkFactory/#zhugivan_landmarks","title":"Zhu/Givan landmarks","text":"<p>The landmark generation method introduced by Zhu &amp; Givan (ICAPS 2003 Doctoral Consortium). <pre><code>lm_zg(use_orders=true, verbosity=normal)\n</code></pre></p> <ul> <li>use_orders (bool): use orders between landmarks</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Supported language features:</p> <ul> <li>conditional_effects: We think they are supported, but this is not 100% sure.</li> </ul>"},{"location":"search/MergeScoringFunction/","title":"MergeScoringFunction","text":"<p>This page describes various merge scoring functions. A scoring function, given a list of merge candidates and a factored transition system, computes a score for each candidate based on this information and potentially some chosen options. Minimal scores are considered best. Scoring functions are currently only used within the score based filtering merge selector.</p>"},{"location":"search/MergeScoringFunction/#dfp_scoring","title":"DFP scoring","text":"<p>This scoring function computes the 'DFP' score as described in the paper \"Directed model checking with distance-preserving abstractions\" by Draeger, Finkbeiner and Podelski (SPIN 2006), adapted to planning in the following paper:</p> <ul> <li>Silvan Sievers, Martin Wehrle and Malte Helmert. Generalized Label Reduction for Merge-and-Shrink Heuristics.  In Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI 2014), pp. 2358-2366. AAAI Press, 2014.</li> </ul> <pre><code>dfp()\n</code></pre> <p>Note: To obtain the configurations called DFP-B-50K described in the paper, use the following configuration of the merge-and-shrink heuristic and adapt the tie-breaking criteria of <code>total_order</code> as desired: <pre><code>merge_and_shrink(\n   merge_strategy=merge_stateless(\n       merge_selector=score_based_filtering(\n           scoring_functions=[goal_relevance,dfp,\n                              total_order(atomic_ts_order=reverse_level,\n                                          product_ts_order=new_to_old,\n                                          atomic_before_product=true)])),\n   shrink_strategy=shrink_bisimulation(greedy=false),\n   label_reduction=exact(before_shrinking=true, before_merging=false),\n   max_states=50000,\n   threshold_before_merge=1)\n</code></pre></p>"},{"location":"search/MergeScoringFunction/#goal_relevance_scoring","title":"Goal relevance scoring","text":"<p>This scoring function assigns a merge candidate a value of 0 iff at least one of the two transition systems of the merge candidate is goal relevant in the sense that there is an abstract non-goal state. All other candidates get a score of positive infinity. <pre><code>goal_relevance()\n</code></pre></p>"},{"location":"search/MergeScoringFunction/#miasm","title":"MIASM","text":"<p>This scoring function favors merging transition systems such that in their product, there are many dead states, which can then be pruned without sacrificing information. In particular, the score it assigns to a product is the ratio of alive states to the total number of states. To compute this score, this class thus computes the product of all pairs of transition systems, potentially copying and shrinking the transition systems before if otherwise their product would exceed the specified size limits. A stateless merge strategy using this scoring function is called dyn-MIASM (nowadays also called sbMIASM for score-based MIASM) and is described in the following paper:</p> <ul> <li>Silvan Sievers, Martin Wehrle and Malte Helmert. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics.  In Proceedings of the 26th International Conference on Planning and Scheduling (ICAPS 2016), pp. 2358-2366. AAAI Press, 2016.</li> </ul> <pre><code>sf_miasm(shrink_strategy, max_states=-1, max_states_before_merge=-1, threshold_before_merge=-1, use_caching=true)\n</code></pre> <ul> <li>shrink_strategy (ShrinkStrategy): We recommend setting this to match the shrink strategy configuration given to <code>merge_and_shrink</code>, see note below.</li> <li>max_states (int [-1, infinity]): maximum transition system size allowed at any time point.</li> <li>max_states_before_merge (int [-1, infinity]): maximum transition system size allowed for two transition systems before being merged to form the synchronized product.</li> <li>threshold_before_merge (int [-1, infinity]): If a transition system, before being merged, surpasses this soft transition system size limit, the shrink strategy is called to possibly shrink the transition system.</li> <li>use_caching (bool): Cache scores for merge candidates. IMPORTANT! This only works under the assumption that the merge-and-shrink algorithm only uses exact label reduction and does not (non-exactly) shrink factors other than those being merged in the current iteration. In this setting, the MIASM score of a merge candidate is constant over merge-and-shrink iterations. If caching is enabled, only the scores for the new merge candidates need to be computed.</li> </ul> <p>Note: To obtain the configurations called dyn-MIASM described in the paper, use the following configuration of the merge-and-shrink heuristic and adapt the tie-breaking criteria of <code>total_order</code> as desired: <pre><code>merge_and_shrink(\n   merge_strategy=merge_stateless(\n       merge_selector=score_based_filtering(\n           scoring_functions=[\n               sf_miasm(shrink_strategy=shrink_bisimulation(greedy=false),\n                        max_states=50000,threshold_before_merge=1),\n               total_order(atomic_ts_order=reverse_level,\n                           product_ts_order=new_to_old,\n                           atomic_before_product=true)])),\n   shrink_strategy=shrink_bisimulation(greedy=false),\n   label_reduction=exact(before_shrinking=true,before_merging=false),\n   max_states=50000,\n   threshold_before_merge=1)\n</code></pre></p> <p>Note: Unless you know what you are doing, we recommend using the same options related to shrinking for <code>sf_miasm</code> as for <code>merge_and_shrink</code>, i.e. the options <code>shrink_strategy</code>, <code>max_states</code>, and <code>threshold_before_merge</code> should be set identically. Furthermore, as this scoring function maximizes the amount of possible pruning, merge-and-shrink should be configured to use full pruning, i.e. <code>prune_unreachable_states=true</code> and <code>prune_irrelevant_states=true</code> (the default).</p>"},{"location":"search/MergeScoringFunction/#single_random","title":"Single random","text":"<p>This scoring function assigns exactly one merge candidate a score of 0, chosen randomly, and infinity to all others. <pre><code>single_random(random_seed=-1)\n</code></pre></p> <ul> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul>"},{"location":"search/MergeScoringFunction/#total_order","title":"Total order","text":"<p>This scoring function computes a total order on the merge candidates, based on the specified options. The score for each merge candidate correponds to its position in the order. This scoring function is mainly intended as tie-breaking, and has been introduced in the following paper:</p> <ul> <li>Silvan Sievers, Martin Wehrle and Malte Helmert. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics.  In Proceedings of the 26th International Conference on Automated Planning and Scheduling (ICAPS 2016), pp. 294-298. AAAI Press, 2016.</li> </ul> <p>Furthermore, using the atomic_ts_order option, this scoring function, if used alone in a score based filtering merge selector, can be used to emulate the corresponding (precomputed) linear merge strategies reverse level/level (independently of the other options). <pre><code>total_order(atomic_ts_order=reverse_level, product_ts_order=new_to_old, atomic_before_product=false, random_seed=-1)\n</code></pre></p> <ul> <li>atomic_ts_order ({reverse_level, level, random}): The order in which atomic transition systems are considered when considering pairs of potential merges.<ul> <li><code>reverse_level</code>: the variable order of Fast Downward</li> <li><code>level</code>: opposite of reverse_level</li> <li><code>random</code>: a randomized order</li> </ul> </li> <li>product_ts_order ({old_to_new, new_to_old, random}): The order in which product transition systems are considered when considering pairs of potential merges.<ul> <li><code>old_to_new</code>: consider composite transition systems from oldest to most recent</li> <li><code>new_to_old</code>: opposite of old_to_new</li> <li><code>random</code>: a randomized order</li> </ul> </li> <li>atomic_before_product (bool): Consider atomic transition systems before composite ones iff true.</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul>"},{"location":"search/MergeSelector/","title":"MergeSelector","text":"<p>This page describes the available merge selectors. They are used to compute the next merge purely based on the state of the given factored transition system. They are used in the merge strategy of type 'stateless', but they can also easily be used in different 'combined' merged strategies.</p>"},{"location":"search/MergeSelector/#score_based_filtering_merge_selector","title":"Score based filtering merge selector","text":"<p>This merge selector has a list of scoring functions, which are used iteratively to compute scores for merge candidates, keeping the best ones (with minimal scores) until only one is left. <pre><code>score_based_filtering(scoring_functions)\n</code></pre></p> <ul> <li>scoring_functions (list of MergeScoringFunction): The list of scoring functions used to compute scores for candidates.</li> </ul>"},{"location":"search/MergeStrategy/","title":"MergeStrategy","text":"<p>This page describes the various merge strategies supported by the planner.</p>"},{"location":"search/MergeStrategy/#precomputed_merge_strategy","title":"Precomputed merge strategy","text":"<p>This merge strategy has a precomputed merge tree. Note that this merge strategy does not take into account the current state of the factored transition system. This also means that this merge strategy relies on the factored transition system being synchronized with this merge tree, i.e. all merges are performed exactly as given by the merge tree. <pre><code>merge_precomputed(merge_tree, verbosity=normal)\n</code></pre></p> <ul> <li>merge_tree (MergeTree): The precomputed merge tree.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note: An example of a precomputed merge startegy is a linear merge strategy, which can be obtained using: <pre><code>merge_strategy=merge_precomputed(merge_tree=linear(&lt;variable_order&gt;))\n</code></pre></p>"},{"location":"search/MergeStrategy/#merge_strategy_sccs","title":"Merge strategy SCCs","text":"<p>This merge strategy implements the algorithm described in the paper </p> <ul> <li>Silvan Sievers, Martin Wehrle and Malte Helmert. An Analysis of Merge Strategies for Merge-and-Shrink Heuristics.  In Proceedings of the 26th International Conference on Planning and Scheduling (ICAPS 2016), pp. 2358-2366. AAAI Press, 2016.</li> </ul> <p>In a nutshell, it computes the maximal strongly connected components (SCCs) of the causal graph, obtaining a partitioning of the task's variables. Every such partition is then merged individually, using the specified fallback merge strategy, considering the SCCs in a configurable order. Afterwards, all resulting composite abstractions are merged to form the final abstraction, again using the specified fallback merge strategy and the configurable order of the SCCs. <pre><code>merge_sccs(order_of_sccs=topological, merge_selector, verbosity=normal)\n</code></pre></p> <ul> <li>order_of_sccs ({topological, reverse_topological, decreasing, increasing}): how the SCCs should be ordered<ul> <li><code>topological</code>: according to the topological ordering of the directed graph where each obtained SCC is a 'supervertex'</li> <li><code>reverse_topological</code>: according to the reverse topological ordering of the directed graph where each obtained SCC is a 'supervertex'</li> <li><code>decreasing</code>: biggest SCCs first, using 'topological' as tie-breaker</li> <li><code>increasing</code>: smallest SCCs first, using 'topological' as tie-breaker</li> </ul> </li> <li>merge_selector (MergeSelector): the fallback merge strategy to use</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/MergeStrategy/#stateless_merge_strategy","title":"Stateless merge strategy","text":"<p>This merge strategy has a merge selector, which computes the next merge only depending on the current state of the factored transition system, not requiring any additional information. <pre><code>merge_stateless(merge_selector, verbosity=normal)\n</code></pre></p> <ul> <li>merge_selector (MergeSelector): The merge selector to be used.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note: Examples include the DFP merge strategy, which can be obtained using: <pre><code>merge_strategy=merge_stateless(\n   merge_selector=score_based_filtering(\n       scoring_functions=[goal_relevance,dfp,total_order(&lt;order_option&gt;))]))\n</code></pre> and the (dynamic/score-based) MIASM strategy, which can be obtained using: <pre><code>merge_strategy=merge_stateless(\n   merge_selector=score_based_filtering(\n       scoring_functions=[sf_miasm(&lt;shrinking_options&gt;),\n                          total_order(&lt;order_option&gt;)]))\n</code></pre></p>"},{"location":"search/MergeTree/","title":"MergeTree","text":"<p>This page describes the available merge trees that can be used to precompute a merge strategy, either for the entire task or a given subset of transition systems of a given factored transition system. Merge trees are typically used in the merge strategy of type 'precomputed', but they can also be used as fallback merge strategies in 'combined' merge strategies.</p>"},{"location":"search/MergeTree/#linear_merge_trees","title":"Linear merge trees","text":"<p>These merge trees implement several linear merge orders, which are described in the paper:</p> <ul> <li>Malte Helmert, Patrik Haslum and Joerg Hoffmann. Flexible Abstraction Heuristics for Optimal Sequential Planning.  In Proceedings of the Seventeenth International Conference on Automated Planning and Scheduling (ICAPS 2007), pp. 176-183. AAAI Press, 2007.</li> </ul> <pre><code>linear(variable_order=cg_goal_level, random_seed=-1, update_option=use_random)\n</code></pre> <ul> <li>variable_order ({cg_goal_level, cg_goal_random, goal_cg_level, random, level, reverse_level}): the order in which atomic transition systems are merged<ul> <li><code>cg_goal_level</code>: variables are prioritized first if they have an arc to a previously added variable, second if their goal value is defined and third according to their level in the causal graph</li> <li><code>cg_goal_random</code>: variables are prioritized first if they have an arc to a previously added variable, second if their goal value is defined and third randomly</li> <li><code>goal_cg_level</code>: variables are prioritized first if their goal value is defined, second if they have an arc to a previously added variable, and third according to their level in the causal graph</li> <li><code>random</code>: variables are ordered randomly</li> <li><code>level</code>: variables are ordered according to their level in the causal graph</li> <li><code>reverse_level</code>: variables are ordered reverse to their level in the causal graph</li> </ul> </li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>update_option ({use_first, use_second, use_random}): When the merge tree is used within another merge strategy, how should it be updated when a merge different to a merge from the tree is performed.<ul> <li><code>use_first</code>: the node representing the index that would have been merged earlier survives</li> <li><code>use_second</code>: the node representing the index that would have been merged later survives</li> <li><code>use_random</code>: a random node (of the above two) survives</li> </ul> </li> </ul>"},{"location":"search/OpenList/","title":"OpenList","text":"<p>This page describes different types of open lists.</p>"},{"location":"search/OpenList/#alternation_open_list","title":"Alternation open list","text":"<p>Alternates between several open lists. <pre><code>alt(sublists, boost=0)\n</code></pre></p> <ul> <li>sublists (list of OpenList): open lists between which this one alternates</li> <li>boost (int): boost value for contained open lists that are restricted to preferred successors</li> </ul>"},{"location":"search/OpenList/#epsilon-greedy_open_list","title":"Epsilon-greedy open list","text":"<p>Chooses an entry uniformly randomly with probability 'epsilon', otherwise it returns the minimum entry. The algorithm is based on</p> <ul> <li>Richard Valenzano, Nathan R. Sturtevant, Jonathan Schaeffer and Fan Xie. A Comparison of Knowledge-Based GBFS Enhancements and Knowledge-Free Exploration.  In Proceedings of the Twenty-Fourth International Conference on Automated Planning and Scheduling (ICAPS 2014), pp. 375-379. AAAI Press, 2014.</li> </ul> <pre><code>epsilon_greedy(eval, epsilon=0.2, random_seed=-1, pref_only=false)\n</code></pre> <ul> <li>eval (Evaluator): evaluator</li> <li>epsilon (double [0.0, 1.0]): probability for choosing the next entry randomly</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>pref_only (bool): insert only nodes generated by preferred operators</li> </ul>"},{"location":"search/OpenList/#pareto_open_list","title":"Pareto open list","text":"<p>Selects one of the Pareto-optimal (regarding the sub-evaluators) entries for removal. <pre><code>pareto(evals, state_uniform_selection=false, random_seed=-1, pref_only=false)\n</code></pre></p> <ul> <li>evals (list of Evaluator): evaluators</li> <li>state_uniform_selection (bool): When removing an entry, we select a non-dominated bucket and return its oldest entry. If this option is false, we select uniformly from the non-dominated buckets; if the option is true, we weight the buckets with the number of entries.</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>pref_only (bool): insert only nodes generated by preferred operators</li> </ul>"},{"location":"search/OpenList/#best-first_open_list","title":"Best-first open list","text":"<p>Open list that uses a single evaluator and FIFO tiebreaking. <pre><code>single(eval, pref_only=false)\n</code></pre></p> <ul> <li>eval (Evaluator): evaluator</li> <li>pref_only (bool): insert only nodes generated by preferred operators</li> </ul> <p>Implementation notes: Elements with the same evaluator value are stored in double-ended queues, called \"buckets\". The open list stores a map from evaluator values to buckets. Pushing and popping from a bucket runs in constant time. Therefore, inserting and removing an entry from the open list takes time O(log(n)), where n is the number of buckets.</p>"},{"location":"search/OpenList/#tie-breaking_open_list","title":"Tie-breaking open list","text":"<pre><code>tiebreaking(evals, unsafe_pruning=true, pref_only=false)\n</code></pre> <ul> <li>evals (list of Evaluator): evaluators</li> <li>unsafe_pruning (bool): allow unsafe pruning when the main evaluator regards a state a dead end</li> <li>pref_only (bool): insert only nodes generated by preferred operators</li> </ul>"},{"location":"search/OpenList/#type-based_open_list","title":"Type-based open list","text":"<p>Uses multiple evaluators to assign entries to buckets. All entries in a bucket have the same evaluator values. When retrieving an entry, a bucket is chosen uniformly at random and one of the contained entries is selected uniformly randomly. The algorithm is based on</p> <ul> <li>Fan Xie, Martin Mueller, Robert Holte and Tatsuya Imai. Type-Based Exploration with Multiple Search Queues for Satisficing Planning.  In Proceedings of the Twenty-Eigth AAAI Conference Conference on Artificial Intelligence (AAAI 2014), pp. 2395-2401. AAAI Press, 2014.</li> </ul> <pre><code>type_based(evaluators, random_seed=-1)\n</code></pre> <ul> <li>evaluators (list of Evaluator): Evaluators used to determine the bucket for each entry.</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul>"},{"location":"search/OrderGenerator/","title":"OrderGenerator","text":"<p>Order abstractions for saturated cost partitioning.</p>"},{"location":"search/OrderGenerator/#dynamic_greedy_orders","title":"Dynamic greedy orders","text":"<p>Order abstractions greedily by a given scoring function, dynamically recomputing the next best abstraction after each ordering step. <pre><code>dynamic_greedy_orders(scoring_function=max_heuristic_per_stolen_costs, random_seed=-1)\n</code></pre></p> <ul> <li>scoring_function ({max_heuristic, min_stolen_costs, max_heuristic_per_stolen_costs}): metric for ordering abstractions/landmarks<ul> <li><code>max_heuristic</code>: order by decreasing heuristic value for the given state</li> <li><code>min_stolen_costs</code>: order by increasing sum of costs stolen from other heuristics</li> <li><code>max_heuristic_per_stolen_costs</code>: order by decreasing ratio of heuristic value divided by sum of stolen costs</li> </ul> </li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul>"},{"location":"search/OrderGenerator/#cost_partitioning_heuristics","title":"Cost Partitioning Heuristics","text":""},{"location":"search/OrderGenerator/#greedy_orders","title":"Greedy orders","text":"<p>Order abstractions greedily by a given scoring function. <pre><code>greedy_orders(scoring_function=max_heuristic_per_stolen_costs, random_seed=-1)\n</code></pre></p> <ul> <li>scoring_function ({max_heuristic, min_stolen_costs, max_heuristic_per_stolen_costs}): metric for ordering abstractions/landmarks<ul> <li><code>max_heuristic</code>: order by decreasing heuristic value for the given state</li> <li><code>min_stolen_costs</code>: order by increasing sum of costs stolen from other heuristics</li> <li><code>max_heuristic_per_stolen_costs</code>: order by decreasing ratio of heuristic value divided by sum of stolen costs</li> </ul> </li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul>"},{"location":"search/OrderGenerator/#random_orders","title":"Random orders","text":"<p>Shuffle abstractions randomly. <pre><code>random_orders(random_seed=-1)\n</code></pre></p> <ul> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul>"},{"location":"search/PatternCollectionGenerator/","title":"PatternCollectionGenerator","text":"<p>This page describes generators for collections of patterns.</p>"},{"location":"search/PatternCollectionGenerator/#combo","title":"Combo","text":"<pre><code>combo(max_states=1000000, verbosity=normal)\n</code></pre> <ul> <li>max_states (int [1, infinity]): maximum abstraction size for combo strategy</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/PatternCollectionGenerator/#disjoint_cegar","title":"Disjoint CEGAR","text":"<p>This pattern collection generator uses the CEGAR algorithm to compute a pattern for the planning task. See below for a description of the algorithm and some implementation notes. The original algorithm (called single CEGAR) is described in the paper </p> <ul> <li>Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning.  In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019), pp. 362-367. AAAI Press, 2019.</li> </ul> <pre><code>disjoint_cegar(max_pdb_size=1000000, max_collection_size=10000000, max_time=infinity, use_wildcard_plans=true, random_seed=-1, verbosity=normal)\n</code></pre> <ul> <li>max_pdb_size (int [1, infinity]): maximum number of states per pattern database (ignored for the initial collection consisting of a singleton pattern for each goal variable)</li> <li>max_collection_size (int [1, infinity]): maximum number of states in the pattern collection (ignored for the initial collection consisting of a singleton pattern for each goal variable)</li> <li>max_time (double [0.0, infinity]): maximum time in seconds for this pattern collection generator (ignored for computing the initial collection consisting of a singleton pattern for each goal variable)</li> <li>use_wildcard_plans (bool): if true, compute wildcard plans which are sequences of sets of operators that induce the same transition; otherwise compute regular plans which are sequences of single operators</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/PatternCollectionGenerator/#short_description_of_the_cegar_algorithm","title":"Short description of the CEGAR algorithm","text":"<p>The CEGAR algorithm computes a pattern collection for a given planning task and a given (sub)set of its goals in a randomized order as follows. Starting from the pattern collection consisting of a singleton pattern for each goal variable, it repeatedly attempts to execute an optimal plan of each pattern in the concrete task, collects reasons why this is not possible (so-called flaws) and refines the pattern in question by adding a variable to it. Further parameters allow blacklisting a (sub)set of the non-goal variables which are then never added to the collection, limiting PDB and collection size, setting a time limit and switching between computing regular or wildcard plans, where the latter are sequences of parallel operators inducing the same abstract transition.</p>"},{"location":"search/PatternCollectionGenerator/#implementation_notes_about_the_cegar_algorithm","title":"Implementation notes about the CEGAR algorithm","text":"<p>The following describes differences of the implementation to the original implementation used and described in the paper.</p> <p>Conceptually, there is one larger difference which concerns the computation of (regular or wildcard) plans for PDBs. The original implementation used an enforced hill-climbing (EHC) search with the PDB as the perfect heuristic, which ensured finding strongly optimal plans, i.e., optimal plans with a minimum number of zero-cost operators, in domains with zero-cost operators. The original implementation also slightly modified EHC to search for a best-improving successor, chosen uniformly at random among all best-improving successors.</p> <p>In contrast, the current implementation computes a plan alongside the computation of the PDB itself. A modification to Dijkstra's algorithm for computing the PDB values stores, for each state, the operator leading to that state (in a regression search). This generating operator is updated only if the algorithm found a cheaper path to the state. After Dijkstra finishes, the plan computation starts at the initial state and iteratively follows the generating operator, computes all operators of the same cost inducing the same transition, until reaching a goal. This constitutes a wildcard plan. It is turned into a regular one by randomly picking a single operator for each transition. </p> <p>Note that this kind of plan extraction does not consider all successors of a state uniformly at random but rather uses the previously deterministically chosen generating operator to settle on one successor state, which is biased by the number of operators leading to the same successor from the given state. Further note that in the presence of zero-cost operators, this procedure does not guarantee that the computed plan is strongly optimal because it does not minimize the number of used zero-cost operators leading to the state when choosing a generating operator. Experiments have shown (issue1007) that this speeds up the computation significantly while not having a strongly negative effect on heuristic quality due to potentially computing worse plans.</p> <p>Two further changes fix bugs of the original implementation to match the description in the paper. The first bug fix is to raise a flaw for all goal variables of the task if the plan for a PDB can be executed on the concrete task but does not lead to a goal state. Previously, such flaws would not have been raised because all goal variables are part of the collection from the start on and therefore not considered. This means that the original implementation accidentally disallowed merging patterns due to goal violation flaws. The second bug fix is to actually randomize the order of parallel operators in wildcard plan steps.</p>"},{"location":"search/PatternCollectionGenerator/#genetic_algorithm_patterns","title":"Genetic algorithm patterns","text":"<p>The following paper describes the automated creation of pattern databases with a genetic algorithm. Pattern collections are initially created with a bin-packing algorithm. The genetic algorithm is used to optimize the pattern collections with an objective function that estimates the mean heuristic value of the the pattern collections. Pattern collections with higher mean heuristic estimates are more likely selected for the next generation.</p> <ul> <li>Stefan Edelkamp. Automated Creation of Pattern Database Search Heuristics.  In Proceedings of the 4th Workshop on Model Checking and Artificial Intelligence (!MoChArt 2006), pp. 35-50. AAAI Press, 2007.</li> </ul> <pre><code>genetic(pdb_max_size=50000, num_collections=5, num_episodes=30, mutation_probability=0.01, disjoint=false, random_seed=-1, verbosity=normal)\n</code></pre> <ul> <li>pdb_max_size (int [1, infinity]): maximal number of states per pattern database </li> <li>num_collections (int [1, infinity]): number of pattern collections to maintain in the genetic algorithm (population size)</li> <li>num_episodes (int [0, infinity]): number of episodes for the genetic algorithm</li> <li>mutation_probability (double [0.0, 1.0]): probability for flipping a bit in the genetic algorithm</li> <li>disjoint (bool): consider a pattern collection invalid (giving it very low fitness) if its patterns are not disjoint</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note: This pattern generation method uses the zero/one pattern database heuristic.</p>"},{"location":"search/PatternCollectionGenerator/#implementation_notes","title":"Implementation notes","text":"<p>The standard genetic algorithm procedure as described in the paper is implemented in Fast Downward. The implementation is close to the paper.</p> <ul> <li>InitializationIn Fast Downward bin-packing with the next-fit strategy is used. A bin corresponds to a pattern which contains variables up to <code>pdb_max_size</code>. With this method each variable occurs exactly in one pattern of a collection. There are <code>num_collections</code> collections created.</li> <li>MutationWith probability <code>mutation_probability</code> a bit is flipped meaning that either a variable is added to a pattern or deleted from a pattern.</li> <li>RecombinationRecombination isn't implemented in Fast Downward. In the paper recombination is described but not used.</li> <li>EvaluationFor each pattern collection the mean heuristic value is computed. For a single pattern database the mean heuristic value is the sum of all pattern database entries divided through the number of entries. Entries with infinite heuristic values are ignored in this calculation. The sum of these individual mean heuristic values yield the mean heuristic value of the collection.</li> <li>SelectionThe higher the mean heuristic value of a pattern collection is, the more likely this pattern collection should be selected for the next generation. Therefore the mean heuristic values are normalized and converted into probabilities and Roulette Wheel Selection is used.</li> </ul> <p>Supported language features:</p> <ul> <li>action costs: supported</li> <li>conditional effects: not supported</li> <li>axioms: not supported</li> </ul>"},{"location":"search/PatternCollectionGenerator/#hill_climbing","title":"Hill climbing","text":"<p>This algorithm uses hill climbing to generate patterns optimized for the Canonical PDB heuristic. It it described in the following paper:</p> <ul> <li>Patrik Haslum, Adi Botea, Malte Helmert, Blai Bonet and Sven Koenig. Domain-Independent Construction of Pattern Database Heuristics for Cost-Optimal Planning.  In Proceedings of the 22nd AAAI Conference on Artificial Intelligence (AAAI 2007), pp. 1007-1012. AAAI Press, 2007.</li> </ul> <p>For implementation notes, see:</p> <ul> <li>Silvan Sievers, Manuela Ortlieb and Malte Helmert. Efficient Implementation of Pattern Database Heuristics for Classical Planning.  In Proceedings of the Fifth Annual Symposium on Combinatorial Search (SoCS 2012), pp. 105-111. AAAI Press, 2012.</li> </ul> <pre><code>hillclimbing(pdb_max_size=2000000, collection_max_size=20000000, num_samples=1000, min_improvement=10, max_time=infinity, random_seed=-1, verbosity=normal)\n</code></pre> <ul> <li>pdb_max_size (int [1, infinity]): maximal number of states per pattern database </li> <li>collection_max_size (int [1, infinity]): maximal number of states in the pattern collection</li> <li>num_samples (int [1, infinity]): number of samples (random states) on which to evaluate each candidate pattern collection</li> <li>min_improvement (int [1, infinity]): minimum number of samples on which a candidate pattern collection must improve on the current one to be considered as the next pattern collection </li> <li>max_time (double [0.0, infinity]): maximum time in seconds for improving the initial pattern collection via hill climbing. If set to 0, no hill climbing is performed at all. Note that this limit only affects hill climbing. Use max_time_dominance_pruning to limit the time spent for pruning dominated patterns.</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note: The pattern collection created by the algorithm will always contain all patterns consisting of a single goal variable, even if this violates the pdb_max_size or collection_max_size limits.</p> <p>Note: This pattern generation method generates patterns optimized for use with the canonical pattern database heuristic.</p>"},{"location":"search/PatternCollectionGenerator/#implementation_notes_1","title":"Implementation notes","text":"<p>The following will very briefly describe the algorithm and explain the differences between the original implementation from 2007 and the new one in Fast Downward.</p> <p>The aim of the algorithm is to output a pattern collection for which the Canonical PDB yields the best heuristic estimates.</p> <p>The algorithm is basically a local search (hill climbing) which searches the \"pattern neighbourhood\" (starting initially with a pattern for each goal variable) for improving the pattern collection. This is done as described in the section \"pattern construction as search\" in the paper, except for the corrected search neighbourhood discussed below. For evaluating the neighbourhood, the \"counting approximation\" as introduced in the paper was implemented. An important difference however consists in the fact that this implementation computes all pattern databases for each candidate pattern rather than using A* search to compute the heuristic values only for the sample states for each pattern.</p> <p>Also the logic for sampling the search space differs a bit from the original implementation. The original implementation uses a random walk of a length which is binomially distributed with the mean at the estimated solution depth (estimation is done with the current pattern collection heuristic). In the Fast Downward implementation, also a random walk is used, where the length is the estimation of the number of solution steps, which is calculated by dividing the current heuristic estimate for the initial state by the average operator costs of the planning task (calculated only once and not updated during sampling!) to take non-unit cost problems into account. This yields a random walk of an expected lenght of np = 2 * estimated number of solution steps. If the random walk gets stuck, it is being restarted from the initial state, exactly as described in the original paper.</p> <p>The section \"avoiding redundant evaluations\" describes how the search neighbourhood of patterns can be restricted to variables that are relevant to the variables already included in the pattern by analyzing causal graphs. There is a mistake in the paper that leads to some relevant neighbouring patterns being ignored. See the errata for details. This mistake has been addressed in this implementation. The second approach described in the paper (statistical confidence interval) is not applicable to this implementation, as it doesn't use A* search but constructs the entire pattern databases for all candidate patterns anyway. The search is ended if there is no more improvement (or the improvement is smaller than the minimal improvement which can be set as an option), however there is no limit of iterations of the local search. This is similar to the techniques used in the original implementation as described in the paper.</p>"},{"location":"search/PatternCollectionGenerator/#manual_patterns","title":"Manual patterns","text":"<pre><code>manual_patterns(patterns, verbosity=normal)\n</code></pre> <ul> <li>patterns (list of list of int): list of patterns (which are lists of variable numbers of the planning task).</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/PatternCollectionGenerator/#multiple_cegar","title":"Multiple CEGAR","text":"<p>This pattern collection generator implements the multiple CEGAR algorithm described in the paper</p> <ul> <li>Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning.  In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019), pp. 362-367. AAAI Press, 2019.</li> </ul> <p>It is an instantiation of the 'multiple algorithm framework'. To compute a pattern in each iteration, it uses the CEGAR algorithm restricted to a single goal variable. See below for descriptions of the algorithms. <pre><code>multiple_cegar(use_wildcard_plans=true, max_pdb_size=1M, max_collection_size=10M, pattern_generation_max_time=infinity, total_max_time=100.0, stagnation_limit=20.0, blacklist_trigger_percentage=0.75, enable_blacklist_on_stagnation=true, random_seed=-1, verbosity=normal)\n</code></pre></p> <ul> <li>use_wildcard_plans (bool): if true, compute wildcard plans which are sequences of sets of operators that induce the same transition; otherwise compute regular plans which are sequences of single operators</li> <li>max_pdb_size (int [1, infinity]): maximum number of states for each pattern database, computed by compute_pattern (possibly ignored by singleton patterns consisting of a goal variable)</li> <li>max_collection_size (int [1, infinity]): maximum number of states in all pattern databases of the collection (possibly ignored, see max_pdb_size)</li> <li>pattern_generation_max_time (double [0.0, infinity]): maximum time in seconds for each call to the algorithm for computing a single pattern</li> <li>total_max_time (double [0.0, infinity]): maximum time in seconds for this pattern collection generator. It will always execute at least one iteration, i.e., call the algorithm for computing a single pattern at least once.</li> <li>stagnation_limit (double [1.0, infinity]): maximum time in seconds this pattern generator is allowed to run without generating a new pattern. It terminates prematurely if this limit is hit unless enable_blacklist_on_stagnation is enabled.</li> <li>blacklist_trigger_percentage (double [0.0, 1.0]): percentage of total_max_time after which blacklisting is enabled</li> <li>enable_blacklist_on_stagnation (bool): if true, blacklisting is enabled when stagnation_limit is hit for the first time (unless it was already enabled due to blacklist_trigger_percentage) and pattern generation is terminated when stagnation_limit is hit for the second time. If false, pattern generation is terminated already the first time stagnation_limit is hit.</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/PatternCollectionGenerator/#short_description_of_the_cegar_algorithm_1","title":"Short description of the CEGAR algorithm","text":"<p>The CEGAR algorithm computes a pattern collection for a given planning task and a given (sub)set of its goals in a randomized order as follows. Starting from the pattern collection consisting of a singleton pattern for each goal variable, it repeatedly attempts to execute an optimal plan of each pattern in the concrete task, collects reasons why this is not possible (so-called flaws) and refines the pattern in question by adding a variable to it. Further parameters allow blacklisting a (sub)set of the non-goal variables which are then never added to the collection, limiting PDB and collection size, setting a time limit and switching between computing regular or wildcard plans, where the latter are sequences of parallel operators inducing the same abstract transition.</p>"},{"location":"search/PatternCollectionGenerator/#implementation_notes_about_the_cegar_algorithm_1","title":"Implementation notes about the CEGAR algorithm","text":"<p>The following describes differences of the implementation to the original implementation used and described in the paper.</p> <p>Conceptually, there is one larger difference which concerns the computation of (regular or wildcard) plans for PDBs. The original implementation used an enforced hill-climbing (EHC) search with the PDB as the perfect heuristic, which ensured finding strongly optimal plans, i.e., optimal plans with a minimum number of zero-cost operators, in domains with zero-cost operators. The original implementation also slightly modified EHC to search for a best-improving successor, chosen uniformly at random among all best-improving successors.</p> <p>In contrast, the current implementation computes a plan alongside the computation of the PDB itself. A modification to Dijkstra's algorithm for computing the PDB values stores, for each state, the operator leading to that state (in a regression search). This generating operator is updated only if the algorithm found a cheaper path to the state. After Dijkstra finishes, the plan computation starts at the initial state and iteratively follows the generating operator, computes all operators of the same cost inducing the same transition, until reaching a goal. This constitutes a wildcard plan. It is turned into a regular one by randomly picking a single operator for each transition. </p> <p>Note that this kind of plan extraction does not consider all successors of a state uniformly at random but rather uses the previously deterministically chosen generating operator to settle on one successor state, which is biased by the number of operators leading to the same successor from the given state. Further note that in the presence of zero-cost operators, this procedure does not guarantee that the computed plan is strongly optimal because it does not minimize the number of used zero-cost operators leading to the state when choosing a generating operator. Experiments have shown (issue1007) that this speeds up the computation significantly while not having a strongly negative effect on heuristic quality due to potentially computing worse plans.</p> <p>Two further changes fix bugs of the original implementation to match the description in the paper. The first bug fix is to raise a flaw for all goal variables of the task if the plan for a PDB can be executed on the concrete task but does not lead to a goal state. Previously, such flaws would not have been raised because all goal variables are part of the collection from the start on and therefore not considered. This means that the original implementation accidentally disallowed merging patterns due to goal violation flaws. The second bug fix is to actually randomize the order of parallel operators in wildcard plan steps.</p>"},{"location":"search/PatternCollectionGenerator/#short_description_of_the_multiple_algorithm_framework","title":"Short description of the 'multiple algorithm framework'","text":"<p>This algorithm is a general framework for computing a pattern collection for a given planning task. It requires as input a method for computing a single pattern for the given task and a single goal of the task. The algorithm works as follows. It first stores the goals of the task in random order. Then, it repeatedly iterates over all goals and for each goal, it uses the given method for computing a single pattern. If the pattern is new (duplicate detection), it is kept for the final collection. The algorithm runs until reaching a given time limit. Another parameter allows exiting early if no new patterns are found for a certain time ('stagnation'). Further parameters allow enabling blacklisting for the given pattern computation method after a certain time to force some diversification or to enable said blacklisting when stagnating.</p>"},{"location":"search/PatternCollectionGenerator/#implementation_note_about_the_multiple_algorithm_framework","title":"Implementation note about the 'multiple algorithm framework'","text":"<p>A difference compared to the original implementation used in the paper is that the original implementation of stagnation in the multiple CEGAR/RCG algorithms started counting the time towards stagnation only after having generated a duplicate pattern. Now, time towards stagnation starts counting from the start and is reset to the current time only when having found a new pattern or when enabling blacklisting.</p>"},{"location":"search/PatternCollectionGenerator/#multiple_random_patterns","title":"Multiple random patterns","text":"<p>This pattern collection generator implements the 'multiple randomized causal graph' (mRCG) algorithm described in experiments of the paper</p> <ul> <li>Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning.  In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019), pp. 362-367. AAAI Press, 2019.</li> </ul> <p>It is an instantiation of the 'multiple algorithm framework'. To compute a pattern in each iteration, it uses the random pattern algorithm, called 'single randomized causal graph' (sRCG) in the paper. See below for descriptions of the algorithms. <pre><code>random_patterns(bidirectional=true, max_pdb_size=1M, max_collection_size=10M, pattern_generation_max_time=infinity, total_max_time=100.0, stagnation_limit=20.0, blacklist_trigger_percentage=0.75, enable_blacklist_on_stagnation=true, random_seed=-1, verbosity=normal)\n</code></pre></p> <ul> <li>bidirectional (bool): this option decides if the causal graph is considered to be directed or undirected selecting predecessors of already selected variables. If true (default), it is considered to be undirected (precondition-effect edges are bidirectional). If false, it is considered to be directed (a variable is a neighbor only if it is a predecessor.</li> <li>max_pdb_size (int [1, infinity]): maximum number of states for each pattern database, computed by compute_pattern (possibly ignored by singleton patterns consisting of a goal variable)</li> <li>max_collection_size (int [1, infinity]): maximum number of states in all pattern databases of the collection (possibly ignored, see max_pdb_size)</li> <li>pattern_generation_max_time (double [0.0, infinity]): maximum time in seconds for each call to the algorithm for computing a single pattern</li> <li>total_max_time (double [0.0, infinity]): maximum time in seconds for this pattern collection generator. It will always execute at least one iteration, i.e., call the algorithm for computing a single pattern at least once.</li> <li>stagnation_limit (double [1.0, infinity]): maximum time in seconds this pattern generator is allowed to run without generating a new pattern. It terminates prematurely if this limit is hit unless enable_blacklist_on_stagnation is enabled.</li> <li>blacklist_trigger_percentage (double [0.0, 1.0]): percentage of total_max_time after which blacklisting is enabled</li> <li>enable_blacklist_on_stagnation (bool): if true, blacklisting is enabled when stagnation_limit is hit for the first time (unless it was already enabled due to blacklist_trigger_percentage) and pattern generation is terminated when stagnation_limit is hit for the second time. If false, pattern generation is terminated already the first time stagnation_limit is hit.</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/PatternCollectionGenerator/#short_description_of_the_random_pattern_algorithm","title":"Short description of the random pattern algorithm","text":"<p>The random pattern algorithm computes a pattern for a given planning task and a single goal of the task as follows. Starting with the given goal variable, the algorithm executes a random walk on the causal graph. In each iteration, it selects a random causal graph neighbor of the current variable. It terminates if no neighbor fits the pattern due to the size limit or if the time limit is reached.</p>"},{"location":"search/PatternCollectionGenerator/#implementation_notes_about_the_random_pattern_algorithm","title":"Implementation notes about the random pattern algorithm","text":"<p>In the original implementation used in the paper, the algorithm selected a random neighbor and then checked if selecting it would violate the PDB size limit. If so, the algorithm would not select it and terminate. In the current implementation, the algorithm instead loops over all neighbors of the current variable in random order and selects the first one not violating the PDB size limit. If no such neighbor exists, the algorithm terminates.</p>"},{"location":"search/PatternCollectionGenerator/#short_description_of_the_multiple_algorithm_framework_1","title":"Short description of the 'multiple algorithm framework'","text":"<p>This algorithm is a general framework for computing a pattern collection for a given planning task. It requires as input a method for computing a single pattern for the given task and a single goal of the task. The algorithm works as follows. It first stores the goals of the task in random order. Then, it repeatedly iterates over all goals and for each goal, it uses the given method for computing a single pattern. If the pattern is new (duplicate detection), it is kept for the final collection. The algorithm runs until reaching a given time limit. Another parameter allows exiting early if no new patterns are found for a certain time ('stagnation'). Further parameters allow enabling blacklisting for the given pattern computation method after a certain time to force some diversification or to enable said blacklisting when stagnating.</p>"},{"location":"search/PatternCollectionGenerator/#implementation_note_about_the_multiple_algorithm_framework_1","title":"Implementation note about the 'multiple algorithm framework'","text":"<p>A difference compared to the original implementation used in the paper is that the original implementation of stagnation in the multiple CEGAR/RCG algorithms started counting the time towards stagnation only after having generated a duplicate pattern. Now, time towards stagnation starts counting from the start and is reset to the current time only when having found a new pattern or when enabling blacklisting.</p>"},{"location":"search/PatternCollectionGenerator/#sys-scp_patterns","title":"Sys-SCP patterns","text":"<p>Systematically generate larger (interesting) patterns but only keep a pattern if it's useful under a saturated cost partitioning. For details, see</p> <ul> <li>Jendrik Seipp. Pattern Selection for Optimal Classical Planning with Saturated Cost Partitioning.  In Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI 2019), pp. 5621-5627. IJCAI, 2019.</li> </ul> <pre><code>sys_scp(max_pattern_size=infinity, max_pdb_size=2M, max_collection_size=20M, max_patterns=infinity, max_time=100, max_time_per_restart=10, max_evaluations_per_restart=infinity, max_total_evaluations=infinity, saturate=true, create_complete_transition_system=false, pattern_type=interesting_non_negative, ignore_useless_patterns=false, store_dead_ends=true, order=cg_down, random_seed=-1, verbosity=normal)\n</code></pre> <ul> <li>max_pattern_size (int [1, infinity]): maximum number of variables per pattern</li> <li>max_pdb_size (int [1, infinity]): maximum number of states in a PDB</li> <li>max_collection_size (int [1, infinity]): maximum number of states in the pattern collection</li> <li>max_patterns (int [1, infinity]): maximum number of patterns</li> <li>max_time (double [0.0, infinity]): maximum time in seconds for generating patterns</li> <li>max_time_per_restart (double [0.0, infinity]): maximum time in seconds for each restart</li> <li>max_evaluations_per_restart (int [0, infinity]): maximum pattern evaluations per the inner loop</li> <li>max_total_evaluations (int [0, infinity]): maximum total pattern evaluations</li> <li>saturate (bool): only select patterns useful in saturated cost partitionings</li> <li>create_complete_transition_system (bool): create explicit transition system (necessary for tasks with conditional effects)</li> <li>pattern_type ({naive, interesting_general, interesting_non_negative}): type of patterns<ul> <li><code>naive</code>: all patterns up to the given size</li> <li><code>interesting_general</code>: only consider the union of two disjoint patterns if the union has more information than the individual patterns under a general cost partitioning</li> <li><code>interesting_non_negative</code>: like interesting_general, but considering non-negative cost partitioning</li> </ul> </li> <li>ignore_useless_patterns (bool): ignore patterns that induce no transitions with positive finite cost</li> <li>store_dead_ends (bool): store dead ends in dead end tree (used to prune the search later)</li> <li>order ({random, states_up, states_down, ops_up, ops_down, cg_up, cg_down}): order in which to consider patterns of the same size (based on states in projection, active operators or position of the pattern variables in the partial ordering of the causal graph)<ul> <li><code>random</code>: order randomly</li> <li><code>states_up</code>: order by increasing number of abstract states</li> <li><code>states_down</code>: order by decreasing number of abstract states</li> <li><code>ops_up</code>: order by increasing number of active operators</li> <li><code>ops_down</code>: order by decreasing number of active operators</li> <li><code>cg_up</code>: use lexicographical order</li> <li><code>cg_down</code>: use reverse lexicographical order</li> </ul> </li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/PatternCollectionGenerator/#systematically_generated_patterns","title":"Systematically generated patterns","text":"<p>Generates all (interesting) patterns with up to pattern_max_size variables. For details, see</p> <ul> <li>Florian Pommerening, Gabriele Roeger and Malte Helmert. Getting the Most Out of Pattern Databases for Classical Planning.  In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI 2013), pp. 2357-2364. AAAI Press, 2013.</li> </ul> <p>The pattern_type=interesting_general setting was introduced in</p> <ul> <li>Florian Pommerening, Thomas Keller, Valentina Halasi, Jendrik Seipp, Silvan Sievers and Malte Helmert. Dantzig-Wolfe Decomposition for Cost Partitioning.  In Proceedings of the 31st International Conference on Automated Planning and Scheduling (ICAPS 2021), pp. 271-280. AAAI Press, 2021.</li> </ul> <pre><code>systematic(pattern_max_size=1, pattern_type=interesting_non_negative, verbosity=normal)\n</code></pre> <ul> <li>pattern_max_size (int [1, infinity]): max number of variables per pattern</li> <li>pattern_type ({naive, interesting_general, interesting_non_negative}): type of patterns<ul> <li><code>naive</code>: all patterns up to the given size</li> <li><code>interesting_general</code>: only consider the union of two disjoint patterns if the union has more information than the individual patterns under a general cost partitioning</li> <li><code>interesting_non_negative</code>: like interesting_general, but considering non-negative cost partitioning</li> </ul> </li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/PatternGenerator/","title":"PatternGenerator","text":"<p>This page describes generators for single patterns.</p>"},{"location":"search/PatternGenerator/#cegar","title":"CEGAR","text":"<p>This pattern generator uses the CEGAR algorithm restricted to a random single goal of the task to compute a pattern. See below for a description of the algorithm and some implementation notes. The original algorithm (called single CEGAR) is described in the paper </p> <ul> <li>Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning.  In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019), pp. 362-367. AAAI Press, 2019.</li> </ul> <pre><code>cegar_pattern(max_pdb_size=1000000, max_time=infinity, use_wildcard_plans=true, random_seed=-1, verbosity=normal)\n</code></pre> <ul> <li>max_pdb_size (int [1, infinity]): maximum number of states in the final pattern database (possibly ignored by a singleton pattern consisting of a single goal variable)</li> <li>max_time (double [0.0, infinity]): maximum time in seconds for the pattern generation</li> <li>use_wildcard_plans (bool): if true, compute wildcard plans which are sequences of sets of operators that induce the same transition; otherwise compute regular plans which are sequences of single operators</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/PatternGenerator/#short_description_of_the_cegar_algorithm","title":"Short description of the CEGAR algorithm","text":"<p>The CEGAR algorithm computes a pattern collection for a given planning task and a given (sub)set of its goals in a randomized order as follows. Starting from the pattern collection consisting of a singleton pattern for each goal variable, it repeatedly attempts to execute an optimal plan of each pattern in the concrete task, collects reasons why this is not possible (so-called flaws) and refines the pattern in question by adding a variable to it. Further parameters allow blacklisting a (sub)set of the non-goal variables which are then never added to the collection, limiting PDB and collection size, setting a time limit and switching between computing regular or wildcard plans, where the latter are sequences of parallel operators inducing the same abstract transition.</p>"},{"location":"search/PatternGenerator/#implementation_notes_about_the_cegar_algorithm","title":"Implementation notes about the CEGAR algorithm","text":"<p>The following describes differences of the implementation to the original implementation used and described in the paper.</p> <p>Conceptually, there is one larger difference which concerns the computation of (regular or wildcard) plans for PDBs. The original implementation used an enforced hill-climbing (EHC) search with the PDB as the perfect heuristic, which ensured finding strongly optimal plans, i.e., optimal plans with a minimum number of zero-cost operators, in domains with zero-cost operators. The original implementation also slightly modified EHC to search for a best-improving successor, chosen uniformly at random among all best-improving successors.</p> <p>In contrast, the current implementation computes a plan alongside the computation of the PDB itself. A modification to Dijkstra's algorithm for computing the PDB values stores, for each state, the operator leading to that state (in a regression search). This generating operator is updated only if the algorithm found a cheaper path to the state. After Dijkstra finishes, the plan computation starts at the initial state and iteratively follows the generating operator, computes all operators of the same cost inducing the same transition, until reaching a goal. This constitutes a wildcard plan. It is turned into a regular one by randomly picking a single operator for each transition. </p> <p>Note that this kind of plan extraction does not consider all successors of a state uniformly at random but rather uses the previously deterministically chosen generating operator to settle on one successor state, which is biased by the number of operators leading to the same successor from the given state. Further note that in the presence of zero-cost operators, this procedure does not guarantee that the computed plan is strongly optimal because it does not minimize the number of used zero-cost operators leading to the state when choosing a generating operator. Experiments have shown (issue1007) that this speeds up the computation significantly while not having a strongly negative effect on heuristic quality due to potentially computing worse plans.</p> <p>Two further changes fix bugs of the original implementation to match the description in the paper. The first bug fix is to raise a flaw for all goal variables of the task if the plan for a PDB can be executed on the concrete task but does not lead to a goal state. Previously, such flaws would not have been raised because all goal variables are part of the collection from the start on and therefore not considered. This means that the original implementation accidentally disallowed merging patterns due to goal violation flaws. The second bug fix is to actually randomize the order of parallel operators in wildcard plan steps.</p>"},{"location":"search/PatternGenerator/#greedy","title":"Greedy","text":"<pre><code>greedy(max_states=1000000, verbosity=normal)\n</code></pre> <ul> <li>max_states (int [1, infinity]): maximal number of abstract states in the pattern database.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/PatternGenerator/#manual_pattern","title":"Manual pattern","text":"<pre><code>manual_pattern(pattern, verbosity=normal)\n</code></pre> <ul> <li>pattern (list of int): list of variable numbers of the planning task that should be used as pattern.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/PatternGenerator/#random_pattern","title":"Random pattern","text":"<p>This pattern generator implements the 'single randomized causal graph' algorithm described in experiments of the the paper</p> <ul> <li>Alexander Rovner, Silvan Sievers and Malte Helmert. Counterexample-Guided Abstraction Refinement for Pattern Selection in Optimal Classical Planning.  In Proceedings of the 29th International Conference on Automated Planning and Scheduling (ICAPS 2019), pp. 362-367. AAAI Press, 2019.</li> </ul> <p>See below for a description of the algorithm and some implementation notes. <pre><code>random_pattern(max_pdb_size=1000000, max_time=infinity, bidirectional=true, random_seed=-1, verbosity=normal)\n</code></pre></p> <ul> <li>max_pdb_size (int [1, infinity]): maximum number of states in the final pattern database (possibly ignored by a singleton pattern consisting of a single goal variable)</li> <li>max_time (double [0.0, infinity]): maximum time in seconds for the pattern generation</li> <li>bidirectional (bool): this option decides if the causal graph is considered to be directed or undirected selecting predecessors of already selected variables. If true (default), it is considered to be undirected (precondition-effect edges are bidirectional). If false, it is considered to be directed (a variable is a neighbor only if it is a predecessor.</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/PatternGenerator/#short_description_of_the_random_pattern_algorithm","title":"Short description of the random pattern algorithm","text":"<p>The random pattern algorithm computes a pattern for a given planning task and a single goal of the task as follows. Starting with the given goal variable, the algorithm executes a random walk on the causal graph. In each iteration, it selects a random causal graph neighbor of the current variable. It terminates if no neighbor fits the pattern due to the size limit or if the time limit is reached.</p>"},{"location":"search/PatternGenerator/#implementation_notes_about_the_random_pattern_algorithm","title":"Implementation notes about the random pattern algorithm","text":"<p>In the original implementation used in the paper, the algorithm selected a random neighbor and then checked if selecting it would violate the PDB size limit. If so, the algorithm would not select it and terminate. In the current implementation, the algorithm instead loops over all neighbors of the current variable in random order and selects the first one not violating the PDB size limit. If no such neighbor exists, the algorithm terminates.</p>"},{"location":"search/PruningMethod/","title":"PruningMethod","text":"<p>This page describes available pruning and reordering methods for applicable operators.</p>"},{"location":"search/PruningMethod/#atom-centric_stubborn_sets","title":"Atom-centric stubborn sets","text":"<p>Stubborn sets are a state pruning method which computes a subset of applicable actions in each state such that completeness and optimality of the overall search is preserved. Previous stubborn set implementations mainly track information about actions. In contrast, this implementation focuses on atomic propositions (atoms), which often speeds up the computation on IPC benchmarks. For details, see</p> <ul> <li>Gabriele Roeger, Malte Helmert, Jendrik Seipp and Silvan Sievers. An Atom-Centric Perspective on Stubborn Sets.  In Proceedings of the 13th Annual Symposium on Combinatorial Search (SoCS 2020), pp. 57-65. AAAI Press, 2020.</li> </ul> <pre><code>atom_centric_stubborn_sets(use_sibling_shortcut=true, atom_selection_strategy=quick_skip, verbosity=normal)\n</code></pre> <ul> <li>use_sibling_shortcut (bool): use variable-based marking in addition to atom-based marking</li> <li>atom_selection_strategy ({fast_downward, quick_skip, static_small, dynamic_small}): Strategy for selecting unsatisfied atoms from action preconditions or the goal atoms. All strategies use the fast_downward strategy for breaking ties.<ul> <li><code>fast_downward</code>: select the atom (v, d) with the variable v that comes first in the Fast Downward variable ordering (which is based on the causal graph)</li> <li><code>quick_skip</code>: if possible, select an unsatisfied atom whose producers are already marked</li> <li><code>static_small</code>: select the atom achieved by the fewest number of actions</li> <li><code>dynamic_small</code>: select the atom achieved by the fewest number of actions that are not yet part of the stubborn set</li> </ul> </li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method (<code>null</code>). We recommend using at most normal verbosity for running experiments.</p>"},{"location":"search/PruningMethod/#limited_pruning","title":"Limited pruning","text":"<p>Limited pruning applies another pruning method and switches it off after a fixed number of expansions if the pruning ratio is below a given value. The pruning ratio is the sum of all pruned operators divided by the sum of all operators before pruning, considering all previous expansions. <pre><code>limited_pruning(pruning, min_required_pruning_ratio=0.2, expansions_before_checking_pruning_ratio=1000, verbosity=normal)\n</code></pre></p> <ul> <li>pruning (PruningMethod): the underlying pruning method to be applied</li> <li>min_required_pruning_ratio (double [0.0, 1.0]): disable pruning if the pruning ratio is lower than this value after 'expansions_before_checking_pruning_ratio' expansions</li> <li>expansions_before_checking_pruning_ratio (int [0, infinity]): number of expansions before deciding whether to disable pruning</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method (<code>null</code>). We recommend using at most normal verbosity for running experiments.</p> <p>Example: To use atom centric stubborn sets and limit them, use <pre><code>pruning=limited_pruning(pruning=atom_centric_stubborn_sets(),min_required_pruning_ratio=0.2,expansions_before_checking_pruning_ratio=1000)\n</code></pre> in an eager search such as astar.</p>"},{"location":"search/PruningMethod/#no_pruning","title":"No pruning","text":"<p>This is a skeleton method that does not perform any pruning, i.e., all applicable operators are applied in all expanded states.  <pre><code>null(verbosity=normal)\n</code></pre></p> <ul> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method (<code>null</code>). We recommend using at most normal verbosity for running experiments.</p>"},{"location":"search/PruningMethod/#stubbornsetsec","title":"StubbornSetsEC","text":"<p>Stubborn sets represent a state pruning method which computes a subset of applicable operators in each state such that completeness and optimality of the overall search is preserved. As stubborn sets rely on several design choices, there are different variants thereof. The variant 'StubbornSetsEC' resolves the design choices such that the resulting pruning method is guaranteed to strictly dominate the Expansion Core pruning method. For details, see</p> <ul> <li>Martin Wehrle, Malte Helmert, Yusra Alkhazraji and Robert Mattmueller. The Relative Pruning Power of Strong Stubborn Sets and Expansion Core.  In Proceedings of the 23rd International Conference on Automated Planning and Scheduling (ICAPS 2013), pp. 251-259. AAAI Press, 2013.</li> </ul> <pre><code>stubborn_sets_ec(verbosity=normal)\n</code></pre> <ul> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method (<code>null</code>). We recommend using at most normal verbosity for running experiments.</p>"},{"location":"search/PruningMethod/#stubborn_sets_simple","title":"Stubborn sets simple","text":"<p>Stubborn sets represent a state pruning method which computes a subset of applicable operators in each state such that completeness and optimality of the overall search is preserved. As stubborn sets rely on several design choices, there are different variants thereof. This stubborn set variant resolves the design choices in a straight-forward way. For details, see the following papers: </p> <ul> <li> <p>Yusra Alkhazraji, Martin Wehrle, Robert Mattmueller and Malte Helmert. A Stubborn Set Algorithm for Optimal Planning.  In Proceedings of the 20th European Conference on Artificial Intelligence (ECAI 2012), pp. 891-892. IOS Press, 2012.</p> </li> <li> <p>Martin Wehrle and Malte Helmert. Efficient Stubborn Sets: Generalized Algorithms and Selection Strategies.  In Proceedings of the 24th International Conference on Automated Planning  and Scheduling (ICAPS 2014), pp. 323-331. AAAI Press, 2014.</p> </li> </ul> <pre><code>stubborn_sets_simple(verbosity=normal)\n</code></pre> <ul> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note on verbosity parameter: Setting verbosity to verbose or higher enables time measurements in each call to prune_operators for a given state. This induces a significant overhead, up to 30% in configurations like blind search with the no pruning method (<code>null</code>). We recommend using at most normal verbosity for running experiments.</p>"},{"location":"search/SearchAlgorithm/","title":"SearchAlgorithm","text":"<p>This page describes the supported search algorithms.</p>"},{"location":"search/SearchAlgorithm/#a_search_eager","title":"A* search (eager)","text":"<p>A* is a special case of eager best first search that uses g+h as f-function. We break ties using the evaluator. Closed nodes are re-opened. <pre><code>astar(eval, lazy_evaluator=&lt;none&gt;, pruning=null(), cost_type=normal, bound=infinity, max_time=infinity, description=\"astar\", verbosity=normal)\n</code></pre></p> <ul> <li>eval (Evaluator): evaluator for h-value</li> <li>lazy_evaluator (Evaluator): An evaluator that re-evaluates a state before it is expanded.</li> <li>pruning (PruningMethod): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered.</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>lazy_evaluator: When a state s is taken out of the open list, the lazy evaluator h re-evaluates s. If h(s) changes (for example because h is path-dependent), s is not expanded, but instead reinserted into the open list. This option is currently only present for the A* algorithm.</p>"},{"location":"search/SearchAlgorithm/#equivalent_statements_using_general_eager_search","title":"Equivalent statements using general eager search","text":"<pre><code>--search \"astar(evaluator)\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"let(h, evaluator, \n              eager(tiebreaking([sum([g(), h]), h], unsafe_pruning=false),\n                    reopen_closed=true, f_eval=sum([g(), h])))\"\n</code></pre>"},{"location":"search/SearchAlgorithm/#breadth-first_search","title":"Breadth-first search","text":"<p>Breadth-first graph search. <pre><code>brfs(single_plan=true, write_plan=true, pruning=null(), description=\"brfs\", verbosity=normal)\n</code></pre></p> <ul> <li>single_plan (bool): Stop search after finding the first (shortest) plan.</li> <li>write_plan (bool): Store the necessary information during search for writing plans once they're found.</li> <li>pruning (PruningMethod): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/SearchAlgorithm/#depth-first_search","title":"Depth-first search","text":"<p>This is a depth-first tree search that avoids running in cycles by skipping states s that are already visited earlier on the path to s. Doing so, the search becomes complete. <pre><code>dfs(single_plan=false, cost_type=normal, bound=infinity, max_time=infinity, description=\"dfs\", verbosity=normal)\n</code></pre></p> <ul> <li>single_plan (bool): stop after finding the first plan</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/SearchAlgorithm/#exhaustive_search","title":"Exhaustive search","text":"<p>Dump the reachable state space. <pre><code>dump_reachable_search_space()\n</code></pre></p>"},{"location":"search/SearchAlgorithm/#eager_best-first_search","title":"Eager best-first search","text":"<pre><code>eager(open, reopen_closed=false, f_eval=&lt;none&gt;, preferred=[], pruning=null(), cost_type=normal, bound=infinity, max_time=infinity, description=\"eager\", verbosity=normal)\n</code></pre> <ul> <li>open (OpenList): open list</li> <li>reopen_closed (bool): reopen closed nodes</li> <li>f_eval (Evaluator): set evaluator for jump statistics. (Optional; if no evaluator is used, jump statistics will not be displayed.)</li> <li>preferred (list of Evaluator): use preferred operators of these evaluators</li> <li>pruning (PruningMethod): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered.</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/SearchAlgorithm/#greedy_search_eager","title":"Greedy search (eager)","text":"<pre><code>eager_greedy(evals, preferred=[], boost=0, pruning=null(), cost_type=normal, bound=infinity, max_time=infinity, description=\"eager_greedy\", verbosity=normal)\n</code></pre> <ul> <li>evals (list of Evaluator): evaluators</li> <li>preferred (list of Evaluator): use preferred operators of these evaluators</li> <li>boost (int): boost value for preferred operator open lists</li> <li>pruning (PruningMethod): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered.</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Open list: In most cases, eager greedy best first search uses an alternation open list with one queue for each evaluator. If preferred operator evaluators are used, it adds an extra queue for each of these evaluators that includes only the nodes that are generated with a preferred operator. If only one evaluator and no preferred operator evaluator is used, the search does not use an alternation open list but a standard open list with only one queue.</p> <p>Closed nodes: Closed node are not re-opened</p>"},{"location":"search/SearchAlgorithm/#equivalent_statements_using_general_eager_search_1","title":"Equivalent statements using general eager search","text":"<pre><code>--search \"let(h2, eval2, eager_greedy([eval1, h2], preferred=[h2], boost=100))\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"let(h1, eval1, let(h2, eval2,\n              eager(alt([single(h1), single(h1, pref_only=true), \n                         single(h2), single(h2, pref_only=true)], boost=100),\n                    preferred=[h2])))\"\n</code></pre> <pre><code>--search \"eager_greedy([eval1, eval2])\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"eager(alt([single(eval1), single(eval2)]))\"\n</code></pre> <pre><code>--search \"let(h1, eval1, eager_greedy([h1], preferred=[h1]))\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"let(h1, eval1, eager(alt([single(h1), single(h1, pref_only=true)]),\n                               preferred=[h1]))\"\n</code></pre> <pre><code>--search \"eager_greedy([eval1])\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"eager(single(eval1))\"\n</code></pre>"},{"location":"search/SearchAlgorithm/#eager_weighted_a_search","title":"Eager weighted A* search","text":"<pre><code>eager_wastar(evals, preferred=[], reopen_closed=true, boost=0, w=1, pruning=null(), cost_type=normal, bound=infinity, max_time=infinity, description=\"eager_wastar\", verbosity=normal)\n</code></pre> <ul> <li>evals (list of Evaluator): evaluators</li> <li>preferred (list of Evaluator): use preferred operators of these evaluators</li> <li>reopen_closed (bool): reopen closed nodes</li> <li>boost (int): boost value for preferred operator open lists</li> <li>w (int): evaluator weight</li> <li>pruning (PruningMethod): Pruning methods can prune or reorder the set of applicable operators in each state and thereby influence the number and order of successor states that are considered.</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Open lists and equivalent statements using general eager search: See corresponding notes for \"(Weighted) A* search (lazy)\"</p> <p>Note: Eager weighted A search uses an alternation open list while A search uses a tie-breaking open list. Consequently, </p> <pre><code>--search \"eager_wastar([h()], w=1)\"\n</code></pre> <p>is not equivalent to</p> <pre><code>--search \"astar(h())\"\n</code></pre>"},{"location":"search/SearchAlgorithm/#lazy_enforced_hill-climbing","title":"Lazy enforced hill-climbing","text":"<pre><code>ehc(h, preferred_usage=prune_by_preferred, preferred=[], cost_type=normal, bound=infinity, max_time=infinity, description=\"ehc\", verbosity=normal)\n</code></pre> <ul> <li>h (Evaluator): heuristic</li> <li>preferred_usage ({prune_by_preferred, rank_preferred_first}): preferred operator usage<ul> <li><code>prune_by_preferred</code>: prune successors achieved by non-preferred operators</li> <li><code>rank_preferred_first</code>: first insert successors achieved by preferred operators, then those by non-preferred operators</li> </ul> </li> <li>preferred (list of Evaluator): use preferred operators of these evaluators</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/SearchAlgorithm/#ida_search","title":"IDA* search","text":"<p>IDA* search with an optional g-value cache. <pre><code>idastar(eval, initial_f_limit=0, cache_size=0, single_plan=true, cost_type=normal, bound=infinity, max_time=infinity, description=\"idastar\", verbosity=normal)\n</code></pre></p> <ul> <li>eval (Evaluator): evaluator for h-value. Make sure to use cache_estimates=false.</li> <li>initial_f_limit (int [0, infinity]): initial depth limit</li> <li>cache_size (int [0, infinity]): maximum number of states to cache. For cache_size=infinity the cache fills up until approaching the memory limit, at which point the current number of states becomes the maximum cache size.</li> <li>single_plan (bool): stop after finding the first plan</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/SearchAlgorithm/#iterative_deepening_search","title":"Iterative deepening search","text":"<pre><code>ids(single_plan=true, cost_type=normal, bound=infinity, max_time=infinity, description=\"ids\", verbosity=normal)\n</code></pre> <ul> <li>single_plan (bool): stop after finding the first (shortest) plan</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/SearchAlgorithm/#iterated_search","title":"Iterated search","text":"<pre><code>iterated(algorithm_configs, pass_bound=true, repeat_last=false, continue_on_fail=false, continue_on_solve=true, cost_type=normal, bound=infinity, max_time=infinity, description=\"iterated\", verbosity=normal)\n</code></pre> <ul> <li>algorithm_configs (list of SearchAlgorithm): list of search algorithms for each phase</li> <li>pass_bound (bool): use the bound of iterated search as a bound for its component search algorithms, unless these already have a lower bound set. The iterated search bound is tightened whenever a component finds a cheaper plan.</li> <li>repeat_last (bool): repeat last phase of search</li> <li>continue_on_fail (bool): continue search after no solution found</li> <li>continue_on_solve (bool): continue search after solution found</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Note 1: We don't cache heuristic values between search iterations at the moment. If you perform a LAMA-style iterative search, heuristic values and other per-state information will be computed multiple times.</p> <p>Note 2: The configuration</p> <pre><code>--search \"iterated([lazy_wastar([ipdb()],w=10), lazy_wastar([ipdb()],w=5),\n                    lazy_wastar([ipdb()],w=3), lazy_wastar([ipdb()],w=2),\n                    lazy_wastar([ipdb()],w=1)])\"\n</code></pre> <p>would perform the preprocessing phase of the ipdb heuristic 5 times (once before each iteration).</p> <p>To avoid this, use heuristic predefinition, which avoids duplicate preprocessing, as follows:</p> <pre><code>\"let(h,ipdb(),iterated([lazy_wastar([h],w=10), lazy_wastar([h],w=5),\n                        lazy_wastar([h],w=3), lazy_wastar([h],w=2),\n                        lazy_wastar([h],w=1)]))\"\n</code></pre>"},{"location":"search/SearchAlgorithm/#iterated_width_search","title":"Iterated width search","text":"<pre><code>iw(width=2, cost_type=normal, bound=infinity, max_time=infinity, description=\"iw\", verbosity=normal)\n</code></pre> <ul> <li>width (int [1, 2]): maximum conjunction size</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul>"},{"location":"search/SearchAlgorithm/#lazy_best-first_search","title":"Lazy best-first search","text":"<pre><code>lazy(open, reopen_closed=false, preferred=[], randomize_successors=false, preferred_successors_first=false, random_seed=-1, cost_type=normal, bound=infinity, max_time=infinity, description=\"lazy\", verbosity=normal)\n</code></pre> <ul> <li>open (OpenList): open list</li> <li>reopen_closed (bool): reopen closed nodes</li> <li>preferred (list of Evaluator): use preferred operators of these evaluators</li> <li>randomize_successors (bool): randomize the order in which successors are generated</li> <li>preferred_successors_first (bool): consider preferred operators first</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Successor ordering: When using randomize_successors=true and preferred_successors_first=true, randomization happens before preferred operators are moved to the front.</p>"},{"location":"search/SearchAlgorithm/#greedy_search_lazy","title":"Greedy search (lazy)","text":"<pre><code>lazy_greedy(evals, boost=1000, reopen_closed=false, preferred=[], randomize_successors=false, preferred_successors_first=false, random_seed=-1, cost_type=normal, bound=infinity, max_time=infinity, description=\"lazy_greedy\", verbosity=normal)\n</code></pre> <ul> <li>evals (list of Evaluator): evaluators</li> <li>boost (int): boost value for alternation queues that are restricted to preferred operator nodes</li> <li>reopen_closed (bool): reopen closed nodes</li> <li>preferred (list of Evaluator): use preferred operators of these evaluators</li> <li>randomize_successors (bool): randomize the order in which successors are generated</li> <li>preferred_successors_first (bool): consider preferred operators first</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Successor ordering: When using randomize_successors=true and preferred_successors_first=true, randomization happens before preferred operators are moved to the front.</p> <p>Open lists: In most cases, lazy greedy best first search uses an alternation open list with one queue for each evaluator. If preferred operator evaluators are used, it adds an extra queue for each of these evaluators that includes only the nodes that are generated with a preferred operator. If only one evaluator and no preferred operator evaluator is used, the search does not use an alternation open list but a standard open list with only one queue.</p>"},{"location":"search/SearchAlgorithm/#equivalent_statements_using_general_lazy_search","title":"Equivalent statements using general lazy search","text":"<pre><code>--search \"let(h2, eval2, lazy_greedy([eval1, h2], preferred=[h2], boost=100))\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"let(h1, eval1, let(h2, eval2,\n              lazy(alt([single(h1), single(h1, pref_only=true),\n                        single(h2), single(h2, pref_only=true)], boost=100),\n                   preferred=[h2])))\"\n</code></pre> <pre><code>--search \"lazy_greedy([eval1, eval2], boost=100)\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"lazy(alt([single(eval1), single(eval2)], boost=100))\"\n</code></pre> <pre><code>--search \"let(h1, eval1, lazy_greedy([h1], preferred=[h1]))\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"let(h1, eval1,\n              lazy(alt([single(h1), single(h1, pref_only=true)], boost=1000),\n                   preferred=[h1]))\"\n</code></pre> <pre><code>--search \"lazy_greedy([eval1])\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"lazy(single(eval1))\"\n</code></pre>"},{"location":"search/SearchAlgorithm/#weighted_a_search_lazy","title":"(Weighted) A* search (lazy)","text":"<p>Weighted A* is a special case of lazy best first search. <pre><code>lazy_wastar(evals, preferred=[], reopen_closed=true, boost=1000, w=1, randomize_successors=false, preferred_successors_first=false, random_seed=-1, cost_type=normal, bound=infinity, max_time=infinity, description=\"lazy_wastar\", verbosity=normal)\n</code></pre></p> <ul> <li>evals (list of Evaluator): evaluators</li> <li>preferred (list of Evaluator): use preferred operators of these evaluators</li> <li>reopen_closed (bool): reopen closed nodes</li> <li>boost (int): boost value for preferred operator open lists</li> <li>w (int): evaluator weight</li> <li>randomize_successors (bool): randomize the order in which successors are generated</li> <li>preferred_successors_first (bool): consider preferred operators first</li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>cost_type ({normal, one, plusone}): Operator cost adjustment type. No matter what this setting is, axioms will always be considered as actions of cost 0 by the heuristics that treat axioms as actions.<ul> <li><code>normal</code>: all actions are accounted for with their real cost</li> <li><code>one</code>: all actions are accounted for as unit cost</li> <li><code>plusone</code>: all actions are accounted for as their real cost + 1 (except if all actions have original cost 1, in which case cost 1 is used). This is the behaviour known for the heuristics of the LAMA planner. This is intended to be used by the heuristics, not search algorithms, but is supported for both.</li> </ul> </li> <li>bound (int): exclusive depth bound on g-values. Cutoffs are always performed according to the real cost, regardless of the cost_type parameter</li> <li>max_time (double): maximum time in seconds the search is allowed to run for. The timeout is only checked after each complete search step (usually a node expansion), so the actual runtime can be arbitrarily longer. Therefore, this parameter should not be used for time-limiting experiments. Timed-out searches are treated as failed searches, just like incomplete search algorithms that exhaust their search space.</li> <li>description (string): description used to identify search algorithm in logs</li> <li>verbosity ({silent, normal, verbose, debug}): Option to specify the verbosity level.<ul> <li><code>silent</code>: only the most basic output</li> <li><code>normal</code>: relevant information to monitor progress</li> <li><code>verbose</code>: full output</li> <li><code>debug</code>: like verbose with additional debug output</li> </ul> </li> </ul> <p>Successor ordering: When using randomize_successors=true and preferred_successors_first=true, randomization happens before preferred operators are moved to the front.</p> <p>Open lists: In the general case, it uses an alternation open list with one queue for each evaluator h that ranks the nodes by g + w * h. If preferred operator evaluators are used, it adds for each of the evaluators another such queue that only inserts nodes that are generated by preferred operators. In the special case with only one evaluator and no preferred operator evaluators, it uses a single queue that is ranked by g + w * h. </p>"},{"location":"search/SearchAlgorithm/#equivalent_statements_using_general_lazy_search_1","title":"Equivalent statements using general lazy search","text":"<pre><code>--search \"let(h1, eval1,\n              lazy_wastar([h1, eval2], w=2, preferred=h1, bound=100, boost=500))\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"let(h1, eval1, let(h2, eval2,\n              lazy(alt([single(sum([g(), weight(h1, 2)])),\n                        single(sum([g(), weight(h1, 2)]), pref_only=true),\n                        single(sum([g(), weight(h2, 2)])),\n                        single(sum([g(), weight(h2, 2)]), pref_only=true)],\n                       boost=500),\n                    preferred=h1, reopen_closed=true, bound=100)))\"\n</code></pre> <pre><code>--search \"lazy_wastar([eval1, eval2], w=2, bound=100)\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"lazy(alt([single(sum([g(), weight(eval1, 2)])),\n                    single(sum([g(), weight(eval2, 2)]))], boost=1000),\n               reopen_closed=true, bound=100)\"\n</code></pre> <pre><code>--search \"lazy_wastar([eval1, eval2], bound=100, boost=0)\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"lazy(alt([single(sum([g(), eval1])), single(sum([g(), eval2]))])\n               reopen_closed=true, bound=100)\"\n</code></pre> <pre><code>--search \"lazy_wastar(eval1, w=2)\"\n</code></pre> <p>is equivalent to</p> <pre><code>--search \"lazy(single(sum([g(), weight(eval1, 2)])), reopen_closed=true)\"\n</code></pre>"},{"location":"search/ShrinkStrategy/","title":"ShrinkStrategy","text":"<p>This page describes the various shrink strategies supported by the planner.</p>"},{"location":"search/ShrinkStrategy/#bismulation_based_shrink_strategy","title":"Bismulation based shrink strategy","text":"<p>This shrink strategy implements the algorithm described in the paper:</p> <ul> <li>Raz Nissim, Joerg Hoffmann and Malte Helmert. Computing Perfect Heuristics in Polynomial Time: On Bisimulation and Merge-and-Shrink Abstractions in Optimal Planning..  In Proceedings of the Twenty-Second International Joint Conference on Artificial Intelligence (IJCAI 2011), pp. 1983-1990. AAAI Press, 2011.</li> </ul> <pre><code>shrink_bisimulation(greedy=false, at_limit=return)\n</code></pre> <ul> <li>greedy (bool): use greedy bisimulation</li> <li>at_limit ({return, use_up}): what to do when the size limit is hit<ul> <li><code>return</code>: stop without refining the equivalence class further</li> <li><code>use_up</code>: continue refining the equivalence class until the size limit is hit</li> </ul> </li> </ul> <p>shrink_bisimulation(greedy=true): Combine this with the merge-and-shrink options max_states=infinity and threshold_before_merge=1 and with the linear merge strategy reverse_level to obtain the variant 'greedy bisimulation without size limit', called M&amp;S-gop in the IJCAI 2011 paper. When we last ran experiments on interaction of shrink strategies with label reduction, this strategy performed best when used with label reduction before shrinking (and no label reduction before merging).</p> <p>shrink_bisimulation(greedy=false): Combine this with the merge-and-shrink option max_states=N (where N is a numerical parameter for which sensible values include 1000, 10000, 50000, 100000 and 200000) and with the linear merge strategy reverse_level to obtain the variant 'exact bisimulation with a size limit', called DFP-bop in the IJCAI 2011 paper. When we last ran experiments on interaction of shrink strategies with label reduction, this strategy performed best when used with label reduction before shrinking (and no label reduction before merging).</p>"},{"location":"search/ShrinkStrategy/#f-preserving_shrink_strategy","title":"f-preserving shrink strategy","text":"<p>This shrink strategy implements the algorithm described in the paper:</p> <ul> <li>Malte Helmert, Patrik Haslum and Joerg Hoffmann. Flexible Abstraction Heuristics for Optimal Sequential Planning.  In Proceedings of the Seventeenth International Conference on Automated Planning and Scheduling (ICAPS 2007), pp. 176-183. AAAI Press, 2007.</li> </ul> <pre><code>shrink_fh(shrink_f=high, shrink_h=low, random_seed=-1)\n</code></pre> <ul> <li>shrink_f ({high, low}): in which direction the f based shrink priority is ordered<ul> <li><code>high</code>: prefer shrinking states with high value</li> <li><code>low</code>: prefer shrinking states with low value</li> </ul> </li> <li>shrink_h ({high, low}): in which direction the h based shrink priority is ordered<ul> <li><code>high</code>: prefer shrinking states with high value</li> <li><code>low</code>: prefer shrinking states with low value</li> </ul> </li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul> <p>Note: The strategy first partitions all states according to their combination of f- and h-values. These partitions are then sorted, first according to their f-value, then according to their h-value (increasing or decreasing, depending on the chosen options). States sorted last are shrinked together until reaching max_states.</p> <p>shrink_fh(): Combine this with the merge-and-shrink option max_states=N (where N is a numerical parameter for which sensible values include 1000, 10000, 50000, 100000 and 200000) and the linear merge startegy cg_goal_level to obtain the variant 'f-preserving shrinking of transition systems', called HHH in the IJCAI 2011 paper. Also see bisimulation based shrink strategy. When we last ran experiments on interaction of shrink strategies with label reduction, this strategy performed best when used with label reduction before merging (and no label reduction before shrinking). We also recommend using full pruning with this shrink strategy, because both distances from the initial state and to the goal states must be computed anyway, and because the existence of only one dead state causes this shrink strategy to always use the map-based approach for partitioning states rather than the more efficient vector-based approach.</p>"},{"location":"search/ShrinkStrategy/#random","title":"Random","text":"<pre><code>shrink_random(random_seed=-1)\n</code></pre> <ul> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul>"},{"location":"search/SubtaskGenerator/","title":"SubtaskGenerator","text":"<p>This page describes different subtask (abstraction) generators. They are used by the additive cartesian cegar heuristic .</p>"},{"location":"search/SubtaskGenerator/#abstraction_by_goals","title":"Abstraction by goals","text":"<p>For each goal atom of the original task one subproblem is generated having only the atom as its goal. <pre><code>goals(order=hadd_down, random_seed=-1)\n</code></pre></p> <ul> <li>order ({original, random, hadd_up, hadd_down}): ordering of goal or landmark facts<ul> <li><code>original</code>: according to their (internal) variable index</li> <li><code>random</code>: according to a random permutation</li> <li><code>hadd_up</code>: according to their h^add value, lowest first</li> <li><code>hadd_down</code>: according to their h^add value, highest first </li> </ul> </li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> </ul>"},{"location":"search/SubtaskGenerator/#abstraction_by_landmarks","title":"Abstraction by landmarks","text":"<p>For each fact landmark of the delete relaxation of the original task one subproblem is generated having only the landmark as goal. This is a generalization of abstractions by goals. <pre><code>landmarks(order=hadd_down, random_seed=-1, combine_facts=true)\n</code></pre></p> <ul> <li>order ({original, random, hadd_up, hadd_down}): ordering of goal or landmark facts<ul> <li><code>original</code>: according to their (internal) variable index</li> <li><code>random</code>: according to a random permutation</li> <li><code>hadd_up</code>: according to their h^add value, lowest first</li> <li><code>hadd_down</code>: according to their h^add value, highest first </li> </ul> </li> <li>random_seed (int [-1, infinity]): Set to -1 (default) to use the global random number generator. Set to any other value to use a local random number generator with the given seed.</li> <li>combine_facts (bool): combine landmark facts with domain abstraction</li> </ul>"},{"location":"search/SubtaskGenerator/#no_abstraction","title":"No abstraction","text":"<p>Copies of the original task are used as subproblems. <pre><code>original(copies=1)\n</code></pre></p> <ul> <li>copies (int [1, infinity]): number of task copies</li> </ul>"}]}